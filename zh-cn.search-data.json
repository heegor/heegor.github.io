{"/about/":{"data":{"":"Paul Zeng\n毕业于211大学计算机专业，现居住于上海 熟悉主流的分布式系统框架，熟悉高并发高可用的系统设计 熟悉软件开发流程，熟悉从软件开发、测试、CI/CD到线上监控的一整套体系 多年技术团队管理经验，异地团队协作经验 多年SaaS平台开发与架构经验 多年物流领域企业级软件、分布式系统开发与架构经验 多年人力资源行业分布式系统开发经验 外企工作经验，创业公司工作经验 技术栈：\n编程语言：Java, Python, C#, C, VB 框架：Spring Boot, Spring Cloud, Spring, Hibernate, Mybatis 中间件：RabbitMQ, Kafka, Redis, Elastic Search 服务发现与治理：Zookeeper, Dubbo, Nacos 数据库：PostgreSQL, MySQL, SQL Server 容器：Kubernetes, Docker 负载均衡：Nginx，HAProxy 运维发布：Ansible, Terrform 公有云平台：AliCloud "},"title":"关于我"},"/blog/2018/06/bubble-sort/":{"data":{"基本思路#基本思路":"假设按照从小到大排列，总共有n个元素\n从第一个元素开始至第n-1个元素，依次比较当前元素与它后面相邻元素的大小，如果前面一个比后面一个大，交换两个元素的位置。第一遍处理之后，最后一个元素就是当前循环中最大的一个。 重复上面的步骤，第二遍处理第一至第n-2个元素，第三遍处理第一至第n-3个元素……直到仅剩一个元素。 ","性能#性能":"时间复杂度：最好的情况O(n),最差的情况O(n2)， 平均O(n2)\n空间复杂度：O(1)","改进后的思路#改进后的思路":"上面的基本思路中需要进行n-1轮的比较。但是存在一种可能，在其中的某一轮之后，该数组就已经是有序的了，也就意味着后面就不需要再进行额外的比较和交换。可以设置一个标志位，用来表示当前这一轮是否存在元素交换，如果没有的话，就结束整个排序过程","示例代码#示例代码":"未改进的冒泡算法。更多详情可点击链接参考示例代码\nprivate static int[] bubbleSort(int[] unsortedArray) { int temp; for (int round = 0; round \u003c unsortedArray.length - 1; round ++) { // Should have N - 1 rounds for (int j = 0; j \u003c unsortedArray.length - 1 - round; j ++) { if (unsortedArray[j] \u003e unsortedArray[j + 1]) { temp = unsortedArray[j]; unsortedArray[j] = unsortedArray[j + 1]; unsortedArray[j + 1] = temp; } } } return unsortedArray; } 用测试用例，有如下的输出。进行了10轮比较，即使后面几轮数组的顺序没有任何的改变\nBefore sort: 1, 2, 9, 6, 0, 4, 8, 5, 7, 3 After round 1: 1, 2, 6, 0, 4, 8, 5, 7, 3, 9\nAfter round 2: 1, 2, 0, 4, 6, 5, 7, 3, 8, 9\nAfter round 3: 1, 0, 2, 4, 5, 6, 3, 7, 8, 9\nAfter round 4: 0, 1, 2, 4, 5, 3, 6, 7, 8, 9\nAfter round 5: 0, 1, 2, 4, 3, 5, 6, 7, 8, 9\nAfter round 6: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter round 7: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter round 8: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter round 9: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter sort: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n改进后的示例代码。更多详情可点击链接参考示例代码\nprivate static int[] bubbleSortWithFlag(int[] unsortedArray) { int temp; boolean swapFlag; for (int round = 0; round \u003c unsortedArray.length - 1; round ++) { // Should have at least N - 1 rounds swapFlag = false; for (int j = 0; j \u003c unsortedArray.length - 1 - round; j ++) { if (unsortedArray[j] \u003e unsortedArray[j + 1]) { temp = unsortedArray[j]; unsortedArray[j] = unsortedArray[j + 1]; unsortedArray[j + 1] = temp; swapFlag = true; } } if (!swapFlag) { // End the process if there is no swap happens break; } } return unsortedArray; } 用测试用例有如下的输出，可以看到仅仅进行了6轮\nBefore sort: 1, 2, 9, 6, 0, 4, 8, 5, 7, 3 After round 1: 1, 2, 6, 0, 4, 8, 5, 7, 3, 9\nAfter round 2: 1, 2, 0, 4, 6, 5, 7, 3, 8, 9\nAfter round 3: 1, 0, 2, 4, 5, 6, 3, 7, 8, 9\nAfter round 4: 0, 1, 2, 4, 5, 3, 6, 7, 8, 9\nAfter round 5: 0, 1, 2, 4, 3, 5, 6, 7, 8, 9\nAfter round 6: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter sort: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9","算法思路#算法思路":"算法思路"},"title":"排序算法 - 冒泡排序(Bubble Sort)"},"/blog/2018/06/connect-remote-jmx-with-ssh/":{"data":{"java应用开启jmx#Java应用开启JMX":"在日常工作中，可以使用一些监控数据的图形展示工具（比如Grafana等）来查看服务器上面JVM的使用情况，比如内存或者CPU的占用情况。但是，在需要解决实际问题的时候，比如CPU或者内存占用过高，还是需要连接到远程的服务器，查看JVM的具体运行情况来分析问题产生的原因。\n通常情况下，我们是通过开启远程服务器上的JMX，使用JVisualVM或JConsole客户端，远程连接到服务器上。然而，在实际的生产环境中，Java应用服务器并没有直接暴露在公网，必须通过跳板机来连接。\n网上查了一些资料，多数比较麻烦，有些还需要借助第三方工具。后来找到一个简便的方法，在使用JVisualVM或JConsole客户端的时候，通过指定socks代理的方式来连接远程服务器。下面是具体的步骤。\nJava应用开启JMX在应用启动命令里面添加下面的参数。指定JMX端口为18888\n-Dcom.sun.management.jmxremote.port=18888 -Dcom.sun.management.jmxremote.rmi.port=18888 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false","jconsole客户端#JConsole客户端":"如果使用jconsole客户端连接。可以直接指定需要连接的服务\njconsole -J-DsocksProxyHost=localhost -J-DsocksProxyPort=10099 service:jmx:rmi:///jndi/rmi://10.10.3.11:18888/jmxrmi ","jvisualvm客户端#JVisualVM客户端":"如果使用jvisualvm客户端连接，先启动指定代理服务器的参数来启动jvisualvm\njvisualvm -J-DsocksProxyHost=localhost -J-DsocksProxyPort=10099 然后在jvm里面先添加remote host，再添加类似下面的JMX连接\nservice:jmx:rmi:///jndi/rmi://10.10.3.11:18888/jmxrmi\n双击左边添加好的JMX连接，就可以连上服务器并监控JVM的实际状况了","指定本地socks代理的端口和跳板机#指定本地socks代理的端口和跳板机":"在命令行中执行下面的命令开启端口转发\nssh -N -D 10099 my-bastion 注意：\n上述例子中的 my-bastion 是跳板机别名，在 ~/.ssh/config中配置。 10099 是绑定的本地端口号 ssh命令帮助文档中对两个参数的解释: -N Do not execute a remote command. This is useful for just forwarding ports. -D [bind_address:]port Specifies a local “dynamic” application-level port forwarding. ","用工具连接远程jvm#用工具连接远程jvm":""},"title":"通过SSH和JMX远程监控Java服务"},"/blog/2018/06/grep-cmd-display-lines/":{"data":{"":"在Linux/Unix系统中使用grep命令的时候，有时候我们想要把匹配文本的前后几行的信息也同时显示出来。这可以通过设置一些参数来达到目的。\ngrep的帮助文档中有这几个参数：\n-A num, –after-context=num Print num lines of trailing context after each match.\n-B num, –before-context=num Print num lines of leading context before each match.\n-C num, –context=num Print num lines of leading and trailing context surrounding each match.\n-A 表示同时输出匹配行的后面几行\ngrep -A 5 word /home/test/a.log -B 表示同时输出匹配行的前面几行\ngrep -B 5 word /home/test/a.log -C 表示同时输出匹配行的前面几行和后面几行\ngrep -C5 word /home/test/a.log "},"title":"如何控制grep命令显示在相关文本前后的行数"},"/blog/2018/06/inputstream-serialize/":{"data":{"":"InputStream本身是不支持序列化的，但是在实际开发的过程中有时会需要将输入流通过socket传输，比如RMI的远程调用。\n在Serializable的Java文档文档中有下面的描述：\nClasses that require special handling during the serialization and deserialization process must implement special methods with these exact signatures:\nprivate void writeObject(java.io.ObjectOutputStream out) throws IOException private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException; private void readObjectNoData() throws ObjectStreamException; 对于这个场景，序列化的类只需实现writeObject与readObject这两个方法就足够了。readObjectNoData这个方法只是在特定的情况下才需要用，对于简单的应用场景来说，可以不用实现。 为了实现输入流的序列化，需要新建一个继承于Serializable接口的实体类，序列化的时候将输入流转成字节数组（writeObject方法），反序列化则将字节流转成输入流（readObject方法）。值得注意的是，这里要用到transient关键字来修饰不可序列化的InputStream私有字段。 示例代码： ```java public class SerializableStream implements Serializable { private final static int LENGTH = 1024; private transient InputStream inputStream; public SerializableStream(InputStream is) { this.inputStream = is; } public InputStream getInputStream() { return inputStream; } private void writeObject(ObjectOutputStream oos) throws Exception { oos.defaultWriteObject(); byte[] buff = new byte[LENGTH]; int tmp; while ((tmp = inputStream.read(buff, 0, LENGTH)) != -1) { oos.write(buff, 0, tmp); } } private void readObject(ObjectInputStream ois) throws Exception { ois.defaultReadObject(); byte[] buf = new byte[LENGTH]; ByteArrayOutputStream bos = new ByteArrayOutputStream(); int tmp; while ((tmp = ois.read(buf, 0, LENGTH)) != -1) { bos.write(buf, 0, tmp); } inputStream = new ByteArrayInputStream(bos.toByteArray()); } } "},"title":"实现InputStream的序列化"},"/blog/2018/06/redis-data-migration/":{"data":{"在旧的redis服务器上关闭aof#在旧的Redis服务器上关闭AOF":"如果原有旧的Redis服务器不需要一直开启AOF，可通过以下命令关闭\nredis-cli -h old_redis_ip -p old_redis_port config set appendonly no ","在旧的redis服务器上开启aof#在旧的Redis服务器上开启AOF":"把一台Redis上的数据，迁移到另外一台Redis服务器上，有很多种方式。其中一个简便的方法是，利用Redis自带的命令行工具redis-cli，实现数据的无缝迁移。\n在旧的Redis服务器上开启AOF执行下面的命令，检查AOF是否开启。返回yes表示开启，no表示关闭\nredis-cli -h old_redis_ip -p old_redis_port config get appendonly 如果未开启，执行下面的命令开启AOF\nredis-cli -h old_redis_ip -p old_redis_port config set appendonly yes ","复制aof文件#复制AOF文件":"默认生成的AOF文件名是appendonly.aof。到Redis数据目录可以看到appendonly.aof文件，复制该文件到新的Redis服务器上。\n如果不知道Redis数据目录或者改过AOF的文件名，可以查看Redis的配置文件中的配置:\n# The name of the append only file (default: \"appendonly.aof\") appendfilename \"appendonly.aof\" # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the 'dbfilename' configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. dir /var/lib/redis ","将aof文件中的数据导入到新的redis服务器#将AOF文件中的数据导入到新的Redis服务器":"执行下面的命令，将AOF文件中的数据导入\nredis-cli -h new_redis_ip -p new_redis_port --pipe \u003c appendonly.aof "},"title":"使用redis-cli与AOF迁移数据"},"/blog/2018/06/set-postgres-default-schema/":{"data":{"":"查看当前的schema\nSHOW search_path; 设置默认schema，仅对当前连接有效\nSET search_path TO your_schema; 设置默认schema，数据库级别，修改之后的所有连接都有效\nALTER database \"your_database\" SET search_path TO your_schema; "},"title":"设置Postgres数据库的默认schema"},"/blog/2018/06/simple-selection-sort/":{"data":{"基本思路#基本思路":"基本思路假设按照从小到大排列，总共有n个元素\n第一轮，找出数组中最小的元素，与第一个元素交换 第二轮，找出剩余元素中最小的元素，与第二个元素交换 第三轮，找出剩余元素中最小的元素，与第三个元素交换 如此重复上述步骤，直至处理完所有元素 ","性能#性能":"时间复杂度：O(n2)\n空间复杂度：O(1)","示例代码#示例代码":"更多详情可点击链接参考示例代码\nprivate static int[] selectionSort(int[] unsortedArray) { int minIndex; for (int round = 0; round \u003c unsortedArray.length; round ++) { // Should have N rounds minIndex = round; for (int j = round + 1; j \u003c unsortedArray.length; j ++) { if (unsortedArray[minIndex] \u003e unsortedArray[j]) { minIndex = j; } } if (minIndex != round) { int temp = unsortedArray[minIndex]; unsortedArray[minIndex] = unsortedArray[round]; unsortedArray[round] = temp; } } return unsortedArray; } 跑一下测试数据，可以看到类似于下面的结果\nBefore sort: 3, 2, 9, 6, 0, 4, 8, 5, 7, 1 After round 1: 0, 2, 9, 6, 3, 4, 8, 5, 7, 1\nAfter round 2: 0, 1, 9, 6, 3, 4, 8, 5, 7, 2\nAfter round 3: 0, 1, 2, 6, 3, 4, 8, 5, 7, 9\nAfter round 4: 0, 1, 2, 3, 6, 4, 8, 5, 7, 9\nAfter round 5: 0, 1, 2, 3, 4, 6, 8, 5, 7, 9\nAfter round 6: 0, 1, 2, 3, 4, 5, 8, 6, 7, 9\nAfter round 7: 0, 1, 2, 3, 4, 5, 6, 8, 7, 9\nAfter round 8: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter round 9: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter round 10: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter sort: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"},"title":"排序算法 - （简单）选择排序 (Selection Sort）"},"/blog/2018/06/ubuntu-screenshot-shortcut/":{"data":{"":"Ubuntu 16.04系统自带了截屏工具，可以实现窗口截屏、区域截屏等。默认的快捷键是：\nPrint 全屏截图 Ctrl + Print 全屏截图并保存到剪贴板 Alt + Print 窗口截图 Ctrl + Alt + Print 窗口截图并保存到剪贴板 Shift + Print 区域截图 Ctrl + Shift + Print 区域截图并保存到剪贴板 Ctrl + Shift + Alt + R 录制屏幕短视频 "},"title":"Ubuntu 16.04系统自带截屏工具快捷键"},"/blog/2018/07/docker-mino-cluster/":{"data":{"":"Minio是一个简单易用的轻量级对象存储服务，同时它也支持集群环境。使用Minio的docker镜像可以快速地搭建集群环境。\n下面是docker-compose.yml文件的示例。分布式的Minio服务至少需要4个节点，所以在docker-compose.yml文件中，至少要配置4个服务。每个服务的command配置必须一样，保证集群环境正常运行。\nversion: '3' services: minio-node1: image: minio/minio hostname: minio-node1 ports: - \"29001:9000\" volumes: - ./node1/data:/data env_file: ./key.env command: server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data minio-node2: image: minio/minio hostname: minio-node2 ports: - \"29002:9000\" volumes: - ./node2/data:/data env_file: ./key.env command: server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data minio-node3: image: minio/minio hostname: minio-node3 ports: - \"29003:9000\" volumes: - ./node3/data:/data env_file: ./key.env command: server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data minio-node4: image: minio/minio hostname: minio-node4 ports: - \"29004:9000\" volumes: - ./node4/data:/data env_file: ./key.env command: server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data 上面的配置中env_file指定的加载环境变量文件key.env，这里是为了设置登录minio的用户名密码。下面的key.env示例：\nMINIO_ACCESS_KEY=testkey MINIO_SECRET_KEY=testpassword 通过上述的docker-compose.yml文件，就可以启动一个minio的集群环境。可以做一些测试，通过浏览器访问 http://localhost:29001 ，新建bucket并上传一个文件，然后在 http://localhost:29002 上面也可以正常访问。同时，可以特地停掉或者启用其中一些服务，用来测试minio集群环境的高可用性。\n如果其中某一个节点服务不可用，这就意味着无法向该节点发起请求来操作对象。比如上述的节点1挂掉， 就无法通过浏览器来访问 http://localhost:29001。 从高可用和负载均衡角度来讲，必须通过负载均衡器来转发请求到各个节点，而不是直接访问某个节点的服务。可以在nginx上做个简单的配置来实现。\n下面是nginx配置的示例。配置完重启nginx服务后，就可以使用 http://localhost:29000 来访问和操作对象\nupstream minio_servers { server 127.0.0.1:29001; server 127.0.0.1:29002; server 127.0.0.1:29003; server 127.0.0.1:29004; } server { listen 29000; server_name localhost; location / { proxy_set_header Host $http_host; proxy_pass http://minio_servers; } } "},"title":"Docker Compose创建minio集群"},"/blog/2018/07/force-date-use-locale/":{"data":{"":"在Linux，Unix或者MacOS的命令行输入date命令，可以获取到当前的系统时间。默认情况下，date命令是按照当前系统的locale的时间格式来输出的。\n比如下面的命令输出当前是星期几，在不同的locale中可以看到有不同的输出\ndate +%a 下面是locale为zh_CN的输出：\n三 下面是locale为en_US的输出：\nWed 如果当前系统的locale是zh_CN，但是想让date输出的星期几是英文而不是中文，有没有简单的办法呢？答案是有。可以通过指定locale临时环境变量来让date命令输出所期望的格式。这个临时环境变量的设置，仅对当前的命令有效，不会影响到其他地方的locale值\n首先我们可以运行下面的命令来列出当前系统安装了哪些locale。这一步有一定的必要，因为在不同的系统下面，locale名称可能不同。比如，Ubuntu下面叫做zh_CN.utf8，而MacOS下面叫做zh_CN.UTF-8。如果locale名称没用对，那么看到的就不是所期望的结果。\nlocale -a 知道locale的具体名称之后，可以用类似下面的命令来指定locale并按照指定格式输出。\nLC_ALL=zh_CN.UTF-8 date LC_ALL=zh_CN.UTF-8 date +%a LC_ALL=en_US.UTF-8 date LC_ALL=en_US.UTF-8 date +%a 上面的命令分别有如下的输出:\n2018年 7月 4日 星期三 20时33分41秒 CST 三 Wed Jul 4 20:33:41 CST 2018 Wed "},"title":"date命令按指定locale所对应的日期格式输出"},"/blog/2018/07/insertion-sort/":{"data":{"基本思路#基本思路":"基本思路假设按照从小到大排列，总共有n个元素。\n整个数组从逻辑上会被分成两个部分，左边部分是有序的序列，右边部分是待排序的元素。当然，刚开始左边的有序序列仅有一个元素，即第一个元素 将右边待排序元素的第一个元素，与左边有序序列进行比较。比较的时候，是从有序序列的末端（即有序序列最大的一个数）开始进行比较，如果比它大或者与之相等则直接插在其后面，否则一直往前面找，直到找到该插入的位置。插入的时候，需要把所插入位置右边的所有元素往右移。 重复上面的步骤，直到所有待排序的元素处理完毕 ","性能#性能":"平均需要n2/4次比较， n2/4次交换；最差情况n2次比较，n2次交换；最好情况n-1次比较，0次交换\n时间复杂度：平均O(n2)，最坏O(n2)，最好O(n)\n空间复杂度: O(1)","示例代码#示例代码":"更多详情可点击链接参考示例代码\nprivate static int[] insertionSort(int[] unsortedArray) { int insertIndex; for (int splitter = 1; splitter \u003c unsortedArray.length; splitter ++) { // Should have N - 1 rounds // Get the insert index insertIndex = splitter; for (int j = splitter -1; j \u003e= 0; j --) { if (unsortedArray[j] \u003e unsortedArray[splitter]) { insertIndex = j; continue; } else { break; } } // Move the item to right int temp = unsortedArray[splitter]; for (int mov = splitter; mov \u003e insertIndex; mov --) { unsortedArray[mov] = unsortedArray[mov - 1]; } unsortedArray[insertIndex] = temp; } return unsortedArray; } 用测试用例，有如下的输出。\nBefore sort: 3, 2, 9, 6, 0, 4, 8, 5, 7, 1\nAfter round 1: 2, 3, 9, 6, 0, 4, 8, 5, 7, 1\nAfter round 2: 2, 3, 9, 6, 0, 4, 8, 5, 7, 1\nAfter round 3: 2, 3, 6, 9, 0, 4, 8, 5, 7, 1\nAfter round 4: 0, 2, 3, 6, 9, 4, 8, 5, 7, 1\nAfter round 5: 0, 2, 3, 4, 6, 9, 8, 5, 7, 1\nAfter round 6: 0, 2, 3, 4, 6, 8, 9, 5, 7, 1\nAfter round 7: 0, 2, 3, 4, 5, 6, 8, 9, 7, 1\nAfter round 8: 0, 2, 3, 4, 5, 6, 7, 8, 9, 1\nAfter round 9: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nAfter sort: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"},"title":"排序算法 - （直接）插入排序 （Insertion Sort)"},"/blog/2018/07/shell-translate-character/":{"data":{"":"在写shell脚本的时候，可能需要将特定的英文字符转换大小写。可以借助tr命令来实现这个功能。\n（1）tr的下面这个命令表示把string1替换成string2\ntr string1 string2 运行下面的命令\necho 'this is a pen' | tr 'a' 'A' 可以看到输出结果中把a换成了A\nthis is A pen （2）同时，tr命令也支持指定一个字符的范围，在这个范围内分别作替换\ntr 'c1-c2' 'c3-c4' 比如，如果只需要把从a到h的字符，替换成大写，那么可以用下面的命令\ntr 'a-h' 'A-H' 运行下面的命令\necho 'this is a pen' | tr 'a-h' 'A-H' 可以看到输出结果中把从a到h的字符全部换成了大写：\ntHis is A pEn 如果要把所有字符转成大写，那么只需要把范围指定成a-z即可。运行下面的命令\necho 'this is a pen' | tr 'a-z' 'A-Z' 可以看输出结果：\nTHIS IS A PEN "},"title":"shell中用tr命令转换字符大小写"},"/blog/2018/11/nginx-setting-for-long-polling/":{"data":{"":"对于需要用到长轮询的web项目，可以在Nginx做一些配置来支持请求转发。分别在http与server块中加入下面的配置：\nhttp { map $http_upgrade $connection_upgrade { default upgrade; '' close; } } server { location /your-api-url/ { proxy_pass http://127.0.0.1:9000/your-api-url/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_buffering off; proxy_ignore_client_abort off; } } "},"title":"配置Nginx支持长轮询"},"/blog/2018/12/excel-trouble-shooting-zip-file/":{"data":{"":"在生产环境中，某个结果集导出的excel文件用Microsoft Excel无法打开，看到如下错误：\n最开始怀疑是在生成文件的时候，文件损坏掉了，但是重新生成多次，得到的结果都是一样的。在相同的界面，导出其他结果集所生成的文件却都是可以成功打开的，这样就可以排除代码功能方面的问题。如果和代码无关，那么就可能和数据有关系。根据出错提示给出的文件地址“C:\\Users\\ZHANGZ~1\\AppData\\Local\\Temp\\error083200_01.xml”, 打开该临时文件，可以看到下面的信息\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"true\"?\u003e @namespace html url(http://www.w3.org/1999/xhtml); :root { font:small Verdana; font-weight: bold; padding: 2em; padding-left:4em; } * { display: block; padding-left: 2em; } html|style { display: none; } html|span, html|a { display: inline; padding: 0; font-weight: normal; text-decoration: none; } html|span.block { display: block; } *[html|hidden], span.block[html|hidden] { display: none; } .expand { display: block; } .expand:before { content: '+'; color: red; position: absolute; left: -1em; } .collapse { display: block; } .collapse:before { content: '-'; color: red; position: absolute; left:-1em; } \u003crecoveryLog xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\"\u003e \u003clogFileName\u003eerror084360_01.xml\u003c/logFileName\u003e \u003csummary\u003eErrors were detected in file 'C:\\Users\\fieldeng\\Downloads\\test_zh_142053.xlsx'\u003c/summary\u003e \u003cadditionalInfo\u003e \u003cinfo\u003eExcel completed file level validation and repair. Some parts of this workbook may have been repaired or discarded.\u003c/info\u003e \u003c/additionalInfo\u003e \u003cremovedParts\u003e \u003cremovedPart\u003eReplaced Part: /xl/worksheets/sheet1.xml part with XML error. 超出当前范围。 Line 478, column 0.\u003c/removedPart\u003e \u003c/removedParts\u003e \u003c/recoveryLog\u003e 由文件内容可以估计是某个字段的值超过长度限制，但是依然无法有效地定位到真正出错的地方。后来发现excel文件实际上就是个zip压缩包，于是改一下扩展名，解压后看到一些目录和文件，一切就豁然开朗了。文件解压后，找到/xl/worksheets/sheet1.xml文件，用文本编辑器打开，跳转到478行，果然看到一个超长的字符串。这个超长的字符串是在代码里面拼接N个字段生成的，结果超出了xml文件能够接受的长度。定位到出错的地方，优化一下代码，就把解决问题了。"},"title":"记一次打开Excel文件错误的排查"},"/blog/2018/12/hibernate-criteria-builder-time-range/":{"data":{"":"现有系统中原先在设计数据库字段的时候，把日期与时间分别存入两个不同的字段，但是这两个字段在数据库中都是以timestamp类型来保存。这样的话，如果需要在where条件中把这两个字段与某个特定的时间做比较，则需要分别截取有效的信息。对于日期字段仅仅取出日期的值，把时间舍弃；对于时间字段仅仅取出时间的值，把日期舍弃。\n举个例子，假设数据库中有两个字段：returnSlaDate存的是物品归还截止日期，returnSlaTime存的是物品归还截止时间。实际在保存的时候，数据库中returnSlaDate字段的值可能会是 2018-12-31 00:00:00 ，其中 00:00:00 是没有用的，在与特定时间做比较的时候，需要舍弃；returnSlaTime字段的值可能会是 1970-01-01 17:59:59 ，其中 1970-01-01 是没有用的，在与特定时间做比较的时候，需要舍弃。\n假设数据库中有另外一个字段actualReturnDate，它表示物品实际归还时间（仅仅一个字段表示，包含有效的日期与时间）。如果现在有个需求，要在系统中查出来物品未按时归还的记录，需要怎么处理呢？直接用SQL写会相对简单，如果用hibernate的criteria builder则需要用as关键字做一下转换。下面是示例代码：\n// 转换截止日期字段成java.sql.Date类型，这样可以仅取出日期的值 Expression returnSlaDate = pTimeSchedule.get(\"returnSlaDate\").as(java.sql.Date.class); // 转换截止时间字段成java.sql.Time类型，这样可以仅取出时间的值 Expression returnSlaTime = pTimeSchedule.get(\"returnSlaTime\").as(java.sql.Time.class); // 对实际归还时间做与上面一样的处理 Expression actualReturnDate = pTimeSchedule.get(\"actualReturnDate\").as(java.sql.Date.class); Expression actualReturnTime = pTimeSchedule.get(\"actualReturnDate\").as(java.sql.Time.class); // 在where语句中，筛选出实际归还日期大于截止日期，或者实际归还日期等于截止日期且归还时间大于截止时间 orFilter.add(builder.or( builder.greaterThan(actualReturnDate, returnSlaDate), builder.and( builder.equal(actualReturnDate, returnSlaDate), builder.greaterThan(actualReturnTime, returnSlaTime) ) )); 打出hibernate的日志，可以看到转换之后的SQL语句\n( cast(generatedAlias0.actualReturnDate as date)\u003ecast(generatedAlias0.timeSchedule.returnSlaDate as date) ) or ( ( cast(generatedAlias0.actualReturnDate as date)=cast(generatedAlias0.timeSchedule.returnSlaDate as date) ) and ( cast(generatedAlias0.actualReturnDate as time)\u003ecast(generatedAlias0.returnSlaTime as time) ) ) "},"title":"Hibernate中用criteria builder处理日期与时间分开的字段"},"/blog/2019/12/incident-caused-by-app/":{"data":{"总结#总结":"做的对的地方：\n文件存储服务做了兼容，支持多种方式，出了问题，有个备选方案 app版本可以控制最低支持的版本，有强制升级机制 需要改进的地方：\n发现app上面bug的时候，没有考虑周全，以为只是小问题，太疏忽 服务之间耦合性有点高，容错性不够。一个服务挂了，可能导致雪崩 minio存储的时候，需要指定子路径。不能放在同一个文件夹下面，要分散到多个子文件夹中。 没有服务降级机制，如果minio挂了，自动启用本地磁盘，不需要重启服务器 minio 当初建机器的时候，没有使用lv等方式，不方便扩展磁盘，如果存在磁盘不足的情况，那么扩容就不方便 配置文件的修改，需要重启服务，造成短时间内不可用 ","时间线#时间线":" 网页上面发现关联了几千个图片，后来发现是app的bug，会不断地上传图片，修复app 过了几天，先是minio集群爆了，十几分钟后其他服务挂了 释放数据库死锁，其他服务恢复 升级minio集群配置，文件存储服务恢复 强制让app客户端升级到最新版本，文件存储服务压力减小 手动写脚本直接处理minio中的文件，释放minio空间。 ","过程#过程":"过程由于一些历史原因，以及与原先代码的兼容性，临时文件存储在minio中。\n某天，生产环境突发事故，minio集群的CPU与内存爆了，只能重启集群。过了十来分钟，很多服务都不可用，健康检查都不通过。日志中的错误信息显示，这些服务都是数据库拿不到连接。需要事先处理数据库连接的问题，于是连接到数据库查死锁，终止导致死锁的sql进程，再重启来恢复这些服务。\n由于前不久minio集群挂掉，很容易就想到是由于minio的原因。其他服务通过RPC调用一个文件存储服务来操作minio中的数据，当minio集群挂掉的时候，文件存储服务访问minio一直想访问minio直到超时。在这个期间，其他服务如果有事务调用文件存储服务来操作minio中文件，那么这个事务就不会被提交，一会占着数据库连接。\nminio集群的硬件资源如果不升级，迟早CPU与内存还会再次爆掉。幸运的是，文件存储服务，当初做了兼容，支持两种临时文件存储方式，一个是本地磁盘，另外一个是minio，修改配置文件可以方便的切换。于是先切换成本地磁盘方式，然后升级minio集群的CPU与内存配置，重启minio集群。接着，修改文件存储服务的配置文件，切换回minio的方式。至此，所有的服务都慢慢恢复正常了。\n接着，细究这个事故的根源，联想到几天前发现app上面的bug，会一直在后台不断地上传图片。当时由于app出了紧急修复的版本，就没有当回事了。没想到过了几天，问题彻底暴露出来了。未升级app到最新版本的用户，在这几天内依然不停地上传文件。访问量的增大，minio集群原先的配置已经扛不住了。幸运的是，之前app实现了一个版本强制升级更新的机制，可以直接在后台修改当前所支持的最小版本，这样就让用户强制更新到最新的版本，避免了继续不停地传文件。\n这段时间大概几十万个文件，约200多G的大小。这些文件都上传到同一个bucket中，由于minio的内部实现是一个bucket采用文件夹形式保存，当一个bucket文件夹中的文件数量过多，已经无法列出某个文件夹下面的文件，总是超时。文件存储服务中的归档删除机制失效，导致空间无法释放，逐渐变小。如果没空间，又会导致服务不可用。幸运的是，有办法获取到具体的文件名，只能手动写脚本直接处理文件，释放空间。"},"title":"复盘 - 手机app上一行代码导致的生产事故"},"/blog/2019/12/pg-recreate-pglogical-slave/":{"data":{"从库上创建pglogical扩展#从库上创建pglogical扩展":" mydb=# CREATE EXTENSION pglogical; ","从库上创建逻辑复制节点#从库上创建逻辑复制节点":" -- host 填的是subscriber的IP mydb=# SELECT pglogical.create_node(node_name := 'subscriber', dsn := 'host=10.1.10.22 port=5432 dbname=mydb'); ","从库上创建逻辑复制订阅端#从库上创建逻辑复制订阅端":" -- host 填的是provider的IP mydb=# SELECT pglogical.create_subscription( subscription_name := 'subscriber', provider_dsn := 'host=10.1.10.6 port=5432 dbname=mydb'); ","从库中删除数据库再创建一个空的数据库#从库中删除数据库，再创建一个空的数据库":"《Postgres 9.x 升级至 10.x》一文中提到了使用pglogical逻辑复制升级。基于这种方式的升级有个缺点，就是主库的DDL发生改变的话，那么从库的复制就会有影响，可能需要重建从库来解决。\n重建从库的步骤与之前创建逻辑复制有点类似，但是由于之前已经做过一些操作，所以相比之下，少了一些步骤。\n从库中删除数据库，再创建一个空的数据库由于表结构的改变，原先的数据都不能用了，需要重新同步。创建新的空数据库是最快的方式","从库中导入最新的表结构#从库中导入最新的表结构":"在 provider 上导出结构数据\nsudo -iu postgres pg_dumpall --schema-only -f dump.sql 在 subscriber 上导入结构数据\nsudo -iu postgres psql -f dump.sql ","在主库上检查复制状态#在主库上检查复制状态":" select * from pg_stat_replication; "},"title":"重建基于pglogical逻辑复制的从库"},"/blog/2019/12/pg-upgrade-version/":{"data":{"pg_upgrade升级#pg_upgrade升级":"事前准备\nexport LC_CTYPE=en_US.UTF-8 export LC_ALL=en_US.UTF-8 apt update # 安装pg 10 apt install postgresql-10 # 安装索引检查插件 apt install postgresql-10-amcheck 停止服务\nservice postgresql@9.5-main stop service postgresql@10-main stop 检查当前的postgres集群\nuser@ubuntu:~# pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.5 main 5432 down postgres /var/lib/postgresql/9.5/main /var/log/postgresql/postgresql-%d.csv 10 main 5433 down postgres /var/lib/postgresql/10/main /var/log/postgresql/postgresql-10-main.log 根据上面输出停掉pg 10的集群\nuser@ubuntu:~# pg_dropcluster --stop 10 main 升级9.x的集群\nuser@ubuntu:~# pg_upgradecluster --method upgrade --link 9.5 main Finding the real data directory for the source cluster ok Finding the real data directory for the target cluster ok Performing Consistency Checks ----------------------------- Checking cluster versions ok Checking database user is the install user ok Checking database connection settings ok Checking for prepared transactions ok Checking for reg* data types in user tables ok Checking for contrib/isn with bigint-passing mismatch ok Checking for invalid \"unknown\" user columns ok Checking for roles starting with \"pg_\" ok Creating dump of global objects ok Creating dump of database schemas ok Checking for presence of required libraries ok Checking database user is the install user ok Checking for prepared transactions ok If pg_upgrade fails after this point, you must re-initdb the new cluster before continuing. Performing Upgrade ------------------ Analyzing all rows in the new cluster ok Freezing all rows in the new cluster ok Deleting files from new pg_xact ok Copying old pg_clog to new server ok Setting next transaction ID and epoch for new cluster ok Deleting files from new pg_multixact/offsets ok Copying old pg_multixact/offsets to new server ok Deleting files from new pg_multixact/members ok Copying old pg_multixact/members to new server ok Setting next multixact ID and offset for new cluster ok Resetting WAL archives ok Setting frozenxid and minmxid counters in new cluster ok Restoring global objects in the new cluster ok Restoring database schemas in the new cluster ok Adding \".old\" suffix to old global/pg_control ok If you want to start the old cluster, you will need to remove the \".old\" suffix from /var/lib/postgresql/9.5/main/global/pg_control.old. Because \"link\" mode was used, the old cluster cannot be safely started once the new cluster has been started. Linking user relation files ok Setting next OID for new cluster ok Sync data directory to disk ok Creating script to analyze new cluster ok Creating script to delete old cluster ok Checking for hash indexes ok Upgrade Complete ---------------- Optimizer statistics are not transferred by pg_upgrade so, once you start the new server, consider running: ./analyze_new_cluster.sh Running this script will delete the old cluster's data files: ./delete_old_cluster.sh pg_upgrade output scripts are in /var/log/postgresql/pg_upgradecluster-9.5-10-main.yo8D Re-enabling connections to the old cluster... Copying old configuration files... Copying old start.conf... Copying old pg_ctl.conf... Disabling automatic startup of old cluster... Configuring old cluster to use a different port (5433)... Success. Please check that the upgraded cluster works. If it does, you can remove the old cluster with pg_dropcluster 9.5 main Ver Cluster Port Status Owner Data directory Log file 9.5 main 5433 down postgres /var/lib/postgresql/9.5/main /var/log/postgresql/postgresql-%d.csv Ver Cluster Port Status Owner Data directory Log file 10 main 5432 down postgres /var/lib/postgresql/10/main /var/log/postgresql/postgresql-%d.csv 复制pg的配置到pg 10上\ncp postgresql.conf /etc/postgresql/10/main/postgresql.conf 重启pg 10\nservice postgresql@10-main start 移除pg 9 集群\npg_dropcluster --stop 9.5 main 查看当前的集群\npg_lsclusters Ver Cluster Port Status Owner Data directory Log file 10 main 5432 online postgres /var/lib/postgresql/10/main /var/log/postgresql/postgresql-%d.csv 执行vacuum analyze\nsudo -iu postgres psql -c 'vacuum analyze' ","前提条件#前提条件":"所有表都必须有主键 可以用下面的语句来检查\nSELECT table_name FROM information_schema.tables WHERE (table_catalog, table_schema, table_name) NOT IN (SELECT table_catalog, table_schema, table_name FROM information_schema.table_constraints WHERE constraint_type = 'PRIMARY KEY') AND table_schema IN ('myschema') super user无密码访问provider和subscriber 修改配置文件\n# prodvider 上配置允许 super user 从 subscriber 上访问 replication。 # 假如 subscriber IP 是 10.1.10.15，则 provider 的 pg_hba.conf 中应包含以下配置 host all postgres 10.1.10.15/32 trust host replication postgres 10.1.10.15/32 trust # subscriber 上允许 super user 访问本地的 postgresql， # 假如 subscriber IP 是 10.1.10.6，pg_hba.conf 中应包含以下配置 host all postgres 10.1.10.6/32 trust subscriber必须拥有和provider一样的表结构 在 provider 上导出结构数据\nsudo -iu postgres pg_dumpall --schema-only -f dump.sql 在 subscriber 上导入结构数据\nsudo -iu postgres psql -f dump.sql ","升级#升级":"一次性同步所有sequence数据，provider 上执行 mydb=# SELECT pglogical.replication_set_add_all_sequences('default', ARRAY['public', 'mydb', 'monitoring', 'authenticator'], true); 升级完成后需drop replication subscribe端的操作 subscriber端删除订阅\nmydb=# select * from pglogical.drop_subscription('subscriber'); subscriber端删除逻辑复制节点\nmydb=# select * from pglogical.drop_node('subscriber'); provider端的操作 provider端删除逻辑复制节点\nmydb=# select * from pglogical.drop_node('provider'); ","搭建逻辑复制#搭建逻辑复制":"主库上的操作 provider安装pglogical apt install postgresql-9.5-pglogical/xenial-pgdg provider上，连到对应的数据库，创建pglogical扩展 mydb=# CREATE EXTENSION pglogical; 创建逻辑复制节点 -- host 填的是provider的IP mydb=# SELECT pglogical.create_node(node_name := 'provider', dsn := 'host=10.1.10.6 port=5432 dbname=mydb'); 添加所有表到需要逻辑复制的集合中 mydb=# SELECT pglogical.replication_set_add_all_tables('default', ARRAY['public', 'mydb', 'monitoring', 'authenticator']); 如果replication_set_add_all_tables 出现 deadlock, 可尝试逐个表添加\npostgres@provider:~$ for i in `psql mydb -c '\\d' | grep table | cut -d '|' -f 2`; do psql mydb -c \"select pglogical.replication_set_add_table('default', '$i')\"; done 从库上的操作 安装的 pg 10.x 作为从库，和逻辑复制的subscriber\n从库上安装postgresql-10 subscriber安装pglogical apt install postgresql-10-pglogical/xenial-pgdg 修改subscriber配置, 重启PostgreSQL shared_preload_libraries = 'pglogical' subscriber上，连到对应的数据库，创建pglogical扩展 mydb=# CREATE EXTENSION pglogical; 创建逻辑复制节点 -- host 填的是subscriber的IP mydb=# SELECT pglogical.create_node(node_name := 'subscriber', dsn := 'host=10.1.10.15 port=5432 dbname=mydb'); 创建逻辑复制订阅端 -- host 填的是provider的IP mydb=# SELECT pglogical.create_subscription( subscription_name := 'subscriber', provider_dsn := 'host=10.1.10.6 port=5432 dbname=mydb'); ","逻辑复制升级#逻辑复制升级":"目前主要有两种升级方式，它们分别使用于不同的场景。\n升级方式 优点 缺点 pglogical逻辑复制升级 停机时间短 需提前准备从库，并搭建replication，在replication期间，需考虑DDL语句带来的影响。 pg_upgrade升级 不需要提前准备replication 升级完成后需检查index是否正常，并执行vacuum analyze，对于数据量较大的库，这可能耗时较长 逻辑复制升级"},"title":"Postgres 9.x 升级至 10.x"},"/blog/2020/01/mac-check-nearby-wifi-channel/":{"data":{"":"信道，也称作通道或频段，是以无线信号作为传输载体的数据信号传送通道。2.4G频段的工作频率为2.4-2.4835GHz，这83.5MHz频带划分为13个信道，各信道中心频率相差5MHz，向上向下分别扩展11MHz，信道带宽22MHz。中国采用欧洲/ETSI标准，使用1-13信道。\n相近无线路由器采用相同或重叠信道会形成信道竞争关系，相互影响无线链路质量，为了有效避免信道重叠造成的相互干扰，相近无线路由器应选择互不重叠的信道工作。\n早期无线路由器出厂时预设相同的信道（大多为6），因用户很少会修改信道，从而导致相互影响的情况。随着无线应用的迅速普及，无线路由器增加了信道自动选择功能，在设备启动时检测周围无线信道分布情况，选择最佳信道工作。\n但是不要过分依赖路由器的自动选择，路由器没有那么智能。可以根据附近的wifi所使用的信道，手工选择一个不一样的。\n在mac系统中，可以使用下面的命令来查看附近wifi使用信道的情况\nsudo /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport -s 参考：\nhttps://service.tp-link.com.cn/detail_article_3272.html http://www.voidcn.com/article/p-njamfbdk-dq.html "},"title":"Mac 检查附近wifi所使用的信道"},"/blog/2020/01/mac-shell-support-map/":{"data":{"":"Mac自带的bash是3.x版本的，shell中的declare命令不支持-A这个参数，会报下面的错误：\ndeclare: -A: invalid option declare: usage: declare [-afFirtx] [-p] [name[=value] ...] 这个参数从bash 4.x开始支持，需要升级至4.x以上的版本\n# 安装最新版本的bash brew install bash # 新版本的bash安装路径是 /usr/share/bin/bash, 而之前系统自带的是 /bin/bash # 需要把新版本的shell添加至信任列表中 sudo bash -c 'echo /usr/local/bin/bash \u003e\u003e /etc/shells' # 如果需要的话，修改默认shell为新版本的bash chsh -s /usr/local/bin/bash 需要注意的是，升级完之后，如果shell脚本需要用新版本的bash来执行，必须在相关的shell脚本开头的部分，将 #!/bin/bash 替换成 #!/usr/local/bin/bash， 否则还是用旧版本的bash来执行。\n那为什么不执行类似下面的命令，删除原先的bash，并给新版本的bash建立一个链接呢？这个是由于MacOS有系统完整性保护机制（System Integrity Protection，SIP），它会阻止所有用户（包括root）修改 /bin 下面目录的内容。当然，也有办法绕过这保护机制，嫌麻烦的话，就不要去动它了。\nsudo rm /bin/bash sudo ln -s /usr/local/bin/bash /bin/bash 参考文章：\nhttps://itnext.io/upgrading-bash-on-macos-7138bd1066ba "},"title":"Mac下shell命令支持map"},"/blog/2020/01/manage-distribution-session-by-id/":{"data":{"参考资料#参考资料":" https://www.infoq.cn/article/Next-Generation-Session-Management-with-Spring-Session ","如何解决#如何解决":"比较合适的解决方案是，vaadin界面不能自己生成session id，而是要复用在新界面登录之后所生成的session id。当vaadin界面有请求的时候，根据请求中的session id查询服务器上是否有对应的session，如果有则返回对应的session；如果没有，则新建一个以该session id为主键的session。换句话说，新老界面都应该要使用相同session id，一旦登录之后，在当前用户这次登录的有效生命周期内，session id保持不变。这样就不会存在上面说的，由于session id的变化而导致被强制登出的问题。\n具体实现的关键是用到HttpServletRequesWrapper类，它能够快速提供HttpServletRequest的自定义实现。\n|----------------------| | (I) ServletRequest | |----------------------| | | ------------------------------------------- | | | | |--------------------------| |-----------------------------| | (I) HttpServletRequest | | (C) ServletRequestWrapper | |--------------------------| |-----------------------------| | | | | ------------------------------------------- | | |---------------------------------| | (C) HttpServletRequestWrapper | |---------------------------------| 如下的代码是从 Tomcat 抽取出来的，展现了HttpServletRequesWrapper类是如何运行的。\npublic class HttpServletRequestWrapper extends ServletRequestWrapper implements HttpServletRequest { public HttpServletRequestWrapper(HttpServletRequest request) { super(request); } private HttpServletRequest _getHttpServletRequest() { return (HttpServletRequest) super.getRequest(); } public HttpSession getSession(boolean create) { return this._getHttpServletRequest().getSession(create); } public HttpSession getSession() { return this._getHttpServletRequest().getSession(); } // 为了保证可读性，其他的方法删减掉了 } 我们所需要做的事情，就是重写getSession这个方法，获取Cookie中的JESSIONID，来获取或者新建session。这里由于vaadin框架里面的一些实现，把session所保存的状态放入外部存储不是一个合适的选择，所以就新建了个MySessionContext用于存放，当然还需要额外的代码来清除MySessionContext中过期的session信息。\npublic class MyHttpServletRequestWrapper extends HttpServletRequestWrapper { public MyHttpServletRequestWrapper(HttpServletRequest request) { super(request); } @Override public HttpSession getSession(boolean create) { ... // 获取请求中的session id，用于获取已有的session或者新建session String requestedSessionId = getRequestedSessionId(); if(requestedSessionId != null) { // 根据指定的session id，获取已有的session HttpSession session = MySessionContext.getSession(requestedSessionId); if (session != null) { return session; } } if(!create) { return null; } // 新建session，用指定的session id作为key保存 return MySessionContext.addSession(requestedSessionId, createNewSession()); } @Override public HttpSession getSession() { return getSession(true); } @Override public String getRequestedSessionId() { // 读取Cookie中JSESSIONID的值，为了方便阅读，省略具体实现 ... } // 新建session private HttpSession createNewSession() { return (HttpServletRequest)this.getRequest().getSession(true); } } 通过filter来使用包装类\npublic class MyFilter implements Filter { /* * 这个方法创建了我们上文所述的封装请求对象, 然后调用其余的 filter 链。 * 这里，当这个filter后面的应用代码执行时，如果要获得session的话，将 * 会使用我们上面所写的方式来获得 */ protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { MyHttpServletRequestWrapper wrappedRequest = new MyHttpServletRequestWrapper(request); filterChain.doFilter(wrappedRequest, strategyResponse); } } 在web.xml中启用filter\n\u003cfilter\u003e \u003cfilter-name\u003eMyFilter\u003c/filter-name\u003e \u003cfilter-class\u003enet.zengxi.filter.MyFilter\u003c/filter-class\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003eMyFilter\u003c/filter-name\u003e \u003curl-pattern\u003e/module/*\u003c/url-pattern\u003e \u003c/filter-mapping\u003e ","背景#背景":"背景由于历史原因，原先的界面是用vaadin框架来实现。但是这个框架不适合互联网的分布式系统，正在逐步用目前主流的前端框架重写各个模块，把旧的vaadin页面替换掉。在替换过程中，新老界面并存。\nvaadin界面的servlet，每次都会判断请求中的session id值，如果在服务器中找不到对应这个id的session，就会重新生成一个。由于session id是在新界面登录的时候生成的，当点击链接从新界面跳转到vaadin界面的时候，vaadin服务会发现没有这个session id，就会重新生成一个新的session。换句话说，新老界面会有各自的session id。当然，分布式系统本来就有这个问题，可以采用分布式session的来解决。\n原先开发人员的解决方案是:\n把session信息存入redis缓存，session id作为key 每次跳转到vaadin界面后，用新生成的session id替换掉旧的session id，同时在redis里面把session信息从旧的key，复制到新的key这边。 但是这种解决方案存在一个问题，主要是由上面解决方案的第2点引起的。由于每次从新界面跳转到vaadin界面都会生成新的session id，如果打开两个浏览器页面，分别跳转到新的界面，那么这个就会导致第一个跳转的那个浏览器页面中的session id被覆盖。vaadin框架是有状态的，它在客户端与服务器端保持一个长连接，并检测session id的有效性。session id的变化，导致长连接的登录信息失效，被弹回到登录界面。从用户体验上来讲，就是被强制登出。\n从另外一个角度说，原先开发人员的解决方案是不合理的，它也不是一种标准的分布式session的解决方案。"},"title":"根据ID来管理分布式session - 新老界面session不一致导致强制登出问题的修复"},"/blog/2020/01/postgres-frequently-used-commands/":{"data":{"":" 原作者：廖学强 原文链接：点击这里 查看帮助命令\nDB=# help --总的帮助 DB=# \\h --SQL commands级的帮助 DB=# \\? --psql commands级的帮助 按列显示，类似mysql的\\G\nDB=# \\x Expanded display is on. 查看DB安装目录(最好root用户执行)\nfind / -name initdb 查看有多少DB实例在运行(最好root用户执行)\nfind / -name postgresql.conf 查看DB版本\ncat $PGDATA/PG_VERSION psql --version DB=# show server_version; DB=# select version(); 查看DB实例运行状态\npg_ctl status 查看所有数据库\npsql –l --查看5432端口下面有多少个DB psql –p XX –l --查看XX端口下面有多少个DB DB=# \\l DB=# select * from pg_database; 创建数据库\ncreatedb database_name DB=# \\h create database --创建数据库的帮助命令 DB=# create database database_name 进入某个数据库\npsql –d dbname DB=# \\c dbname 查看当前数据库\nDB=# \\c DB=# select current_database(); 查看数据库文件目录\nDB=# show data_directory; cat $PGDATA/postgresql.conf |grep data_directory cat /etc/init.d/postgresql|grep PGDATA= lsof |grep 5432得出第二列的PID号再ps –ef|grep PID 查看表空间\nselect * from pg_tablespace; 查看语言\nselect * from pg_language; 查询所有schema，必须到指定的数据库下执行\nselect * from information_schema.schemata; SELECT nspname FROM pg_namespace; \\dnS 查看表名\nDB=# \\dt --只能查看到当前数据库下public的表名 DB=# SELECT tablename FROM pg_tables WHERE tablename NOT LIKE 'pg%' AND tablename NOT LIKE 'sql_%' ORDER BY tablename; DB=# SELECT * FROM information_schema.tables WHERE table_name='ff_v3_ff_basic_af'; 查看表结构\nDB=# \\d tablename DB=# select * from information_schema.columns where table_schema='public' and table_name='XX'; 查看索引\nDB=# \\di DB=# select * from pg_index; 查看视图\nDB=# \\dv DB=# select * from pg_views where schemaname = 'public'; DB=# select * from information_schema.views where table_schema = 'public'; 查看触发器\nDB=# select * from information_schema.triggers; 查看序列\nDB=# select * from information_schema.sequences where sequence_schema = 'public'; 查看约束\nDB=# select * from pg_constraint where contype = 'p' DB=# select a.relname as table_name,b.conname as constraint_name,b.contype as constraint_type from pg_class a,pg_constraint b where a.oid = b.conrelid and a.relname = 'cc'; 查看XX数据库的大小\nSELECT pg_size_pretty(pg_database_size('XX')) As fulldbsize; 查看所有数据库的大小\nselect pg_database.datname, pg_size_pretty (pg_database_size(pg_database.datname)) AS size from pg_database; 查看各数据库数据创建时间：\nselect datname,(pg_stat_file(format('%s/%s/PG_VERSION',case when spcname='pg_default' then 'base' else 'pg_tblspc/'||t2.oid||'/PG_11_201804061/' end, t1.oid))).* from pg_database t1,pg_tablespace t2 where t1.dattablespace=t2.oid; 按占空间大小，顺序查看所有表的大小\nselect relname, pg_size_pretty(pg_relation_size(relid)) from pg_stat_user_tables where schemaname='public' order by pg_relation_size(relid) desc; 按占空间大小，顺序查看索引大小\nselect indexrelname, pg_size_pretty(pg_relation_size(relid)) from pg_stat_user_indexes where schemaname='public' order by pg_relation_size(relid) desc; 查看参数文件\nDB=# show config_file; DB=# show hba_file; DB=# show ident_file; 查看当前会话的参数值\nDB=# show all; 查看参数值\nselect * from pg_file_settings 查看某个参数值,比如参数work_mem\nDB=# show work_mem 修改某个参数值,比如参数work_mem\nDB=# alter system set work_mem='8MB' --使用alter system命令将修改postgresql.auto.conf文件，而不是postgresql.conf，这样可以很好的保护postgresql.conf文件，加入你使用很多alter system命令后搞的一团糟，那么你只需要删除postgresql.auto.conf，再执行pg_ctl reload加载postgresql.conf文件即可实现参数的重新加载。 查看是否归档\nDB=# show archive_mode; 查看运行日志的相关配置，运行日志包括Error信息，定位慢查询SQL，数据库的启动关闭信息，checkpoint过于频繁等的告警信息。\nshow logging_collector;--启动日志收集 show log_directory;--日志输出路径 show log_filename;--日志文件名 show log_truncate_on_rotation;--当生成新的文件时如果文件名已存在，是否覆盖同名旧文件名 show log_statement;--设置日志记录内容 show log_min_duration_statement;--运行XX毫秒的语句会被记录到日志中，-1表示禁用这个功能，0表示记录所有语句，类似mysql的慢查询配置 查看wal日志的配置，wal日志就是redo重做日志\n存放在data_directory/pg_wal目录 查看当前用户\nDB=# \\c DB=# select current_user; 查看所有用户\nDB=# select * from pg_user; DB=# select * from pg_shadow; 查看所有角色\nDB=# \\du DB=# select * from pg_roles; 查询用户XX的权限，必须到指定的数据库下执行\nselect * from information_schema.table_privileges where grantee='XX'; 创建用户XX，并授予超级管理员权限\ncreate user XXX SUPERUSER PASSWORD '123456' 创建角色，赋予了login权限，则相当于创建了用户，在pg_user可以看到这个角色\ncreate role \"user1\" superuser;--pg_roles有user1，pg_user和pg_shadow没有user1 alter role \"user1\" login;--pg_user和pg_shadow也有user1了 授权\nDB=# \\h grant GRANT ALL PRIVILEGES ON schema schemaname TO dbuser; grant ALL PRIVILEGES on all tables in schema fds to dbuser; GRANT ALL ON tablename TO user; GRANT ALL PRIVILEGES ON DATABASE dbname TO dbuser; grant select on all tables in schema public to dbuser;--给用户读取public这个schema下的所有表 GRANT create ON schema schemaname TO dbuser;--给用户授予在schema上的create权限，比如create table、create view等 GRANT USAGE ON schema schemaname TO dbuser; grant select on schema public to dbuser;--报错ERROR: invalid privilege type SELECT for schema --USAGE：对于程序语言来说，允许使用指定的程序语言创建函数;对于Schema来说，允许查找该Schema下的对象;对于序列来说，允许使用currval和nextval函数;对于外部封装器来说，允许使用外部封装器来创建外部服务器;对于外部服务器来说，允许创建外部表。 查看表上存在哪些索引以及大小\nselect relname,n.amname as index_type from pg_class m,pg_am n where m.relam = n.oid and m.oid in (select b.indexrelid from pg_class a,pg_index b where a.oid = b.indrelid and a.relname = 'cc'); SELECT c.relname,c2.relname, c2.relpages*8 as size_kb FROM pg_class c, pg_class c2, pg_index i WHERE c.relname ='cc' AND c.oid =i.indrelid AND c2.oid =i.indexrelid ORDER BY c2.relname; 查看索引定义\nselect b.indexrelid from pg_class a,pg_index b where a.oid = b.indrelid and a.relname = 'cc'; select pg_get_indexdef(b.indexrelid); 查看过程函数定义\nselect oid,* from pg_proc where proname = 'insert_platform_action_exist'; --oid = 24610 select * from pg_get_functiondef(24610); 查看表大小(不含索引等信息)\nselect pg_relation_size('cc'); --368640 byte select pg_size_pretty(pg_relation_size('cc')) --360 kB 查看表所对应的数据文件路径与大小\nSELECT pg_relation_filepath(oid), relpages FROM pg_class WHERE relname = 'empsalary'; posegresql查询当前lsn\n1、用到哪些方法：\napple=# select proname from pg_proc where proname like 'pg_%_lsn'; proname --------------------------------- pg_current_wal_flush_lsn pg_current_wal_insert_lsn pg_current_wal_lsn pg_last_wal_receive_lsn pg_last_wal_replay_lsn 2、查询当前的lsn值：\napple=# select pg_current_wal_lsn(); pg_current_wal_lsn -------------------------- 0/45000098 3、查询当前lsn对应的日志文件\nselect pg_walfile_name('0/1732DE8'); 4、查询当前lsn在日志文件中的偏移量\nSELECT * FROM pg_walfile_name_offset(pg_current_wal_lsn()); 切换pg_wal日志\nselect pg_switch_wal(); 清理pg_wal日志\npg_archivecleanup /postgresql/pgsql/data/pg_wal 000000010000000000000005 表示删除000000010000000000000005之前的所有日志 --pg_wal日志没有设置保留周期的参数，即没有类似mysql的参数expire_logs_days，pg_wal日志永久保留，除非sql脚步删除几天前或pg-rman备份时候设置保留策略 查询有哪些slot，任意一个数据库下都可以查，查询的结果都一样\nselect * from pg_replication_slots; 启动时间\nselect statement_timestamp()-pg_postmaster_start_time() AS up_time; 查看有几个从库\nselect * from pg_stat_replication; 主从延迟，主库上执行\nselect pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_flush_lsn(),write_lsn)) delay_wal_size,* from pg_stat_replication ; – 手动激活从库为主库 – 激活位点最新的库为主库\npg_ctl promote -D $PGDATA 查看活跃连接数\nselect count(*) from pg_stat_activity where query \u003c\u003e'IDLE'; 类似 mysql source xx.sql\n\\i xx.sql 杀掉某连接\nselect pg_cancel_backend(pid); — session 还在，transaction 回滚, pid 来自 pg_stat_activity select pg_terminate_backend(pid); — session 消失，transaction 回滚, pid 来自 pg_stat_activity "},"title":"转: Postgres数据库DBA常用命令"},"/blog/2020/01/quartz-job-issue-improvement/":{"data":{"解决方案#解决方案":"最终的解决方案，总结如下：\n升级所有应用的quartz scheduler库至2.3.1版本 不同的应用，分别赋予不同的scheduler name；同一个应用中，如果同时有集群模式与单机模式，需要使用不同的scheduler，并赋予不同的name值 对于同一个应用，某个任务仅需要任意一个节点执行的，使用JobStoreCMT的cluster模式。同时需要保证不同节点instanceId不同， 比如将org.quartz.scheduler.instanceId的值设置为AUTO 对于同一个应用，某个任务需要所有节点都执行的，使用基于内存的RAMJobStore org.quartz.threadPool.threadCount 设置成与任务数一致。避免因线程数不够，任务无法执行 job detail赋予正确的group名称 如果job不允许并发，则在job对应的类上添加@DisallowConcurrentExecution 注解 如果job对应的类上面有autowire的需求，可以自定义一个job factory，继承SpringBeanJobFactory，并调用AutowireCapableBeanFactory的autowireBean，来避免Job类里面@Autowired无法注入的问题。同时在配置文件中使用自定义的job factory \u003cproperty name=\"jobFactory\" ref=\"myCustomizedJobFactory\" /\u003e ","遇到的问题与原因分析#遇到的问题与原因分析":"遇到的问题与原因分析生产环境中遇到的问题：\n服务在启动过程中，不时地卡住，后来发生的越来越频繁。看日志分析，卡在初始化quartz job store的时候 服务在运行过程中，不时地出现定时任务不被触发的情况 通过分析，得知问题产生的原因：\n目前代码中用的是Quartz scheduler 1.8.3版本，定时框架采用的是行锁，通过执行下面的SQL来锁住特定的记录。在分布式的系统的情况下，节点越多越容易发生锁等待，甚至死锁。Quartz scheduler 的 2.x 版本做了改进，在QRTZ_LOCKS表中多加了一个字段 SCHED_NAME。这有一个好处就是，可以给不同的应用分配不同的scheduler name，这样定时框架在调度的时候，不同的应用分别去尝试锁定不同的行，而不像之前锁的时同一个行，避免死锁的发生。 SELECT * FROM QRTZ_LOCKS WHERE LOCK_NAME = $1 FOR UPDATE; org.quartz.threadPool.threadCount 值设置太小。Quartz scheduler的线程池大小不足，这个也有可能导致定时任务在排队，无法被触发。 另外，在研究现有代码过程中，还发现另外3个问题：\ngroup未正确赋值。Quartz中实际上是把job name与group的组合作为一个唯一标识的key，用它来触发和调度一个任务。job name相同，group不同，被当做是不同的任务。如果同一个应用多个节点，需要分成不同的组来分别执行不同的定时任务（比如其中一个组仅统计某个时间段出国的旅游人数，另外一个组仅统计在国内的旅游人数），那就必须给不同的组赋予不同的group值。否则，可能导致其中的一个任务没有执行，因为他们被当做是同一个任务。 应用中的instanceId被写死在配置文件中。由于一个应用往往有多个节点，这个就导致集群中有多个节点的instanceId是相同。然而同一个Quartz scheduler的集群中，任意节点的instanceId必须保证唯一。 目前的系统有个需求，某个任务必须在某个服务的所有节点上执行，比如定时从数据库或者其他地方同步某些配置项到内存中。由于Quartz框架不支持这个功能，原先的代码对job detail等类进行扩展，添加了一个属性，用来表示该任务是在该应用的所有节点上或仅仅选择一台执行。为了支持这个功能，代码改动的比较多，甚至也有可能是因为这些改动，直接或者间接导致前面的那些问题。在网上搜索了一下，发现也有一些人有类似的需求，他们在某网站上面提问，使用Quartz框架时怎样才能支持任务在集群的所有节点上执行。后来仔细想想，Quartz框架支持集群模式与基于内存的RAMJobStore单机模式这两种，如果需要在所有节点上执行，其实使用基于内存的RAMJobStore单机模式就可以了，没有必要再通过扩展集群模式来支持这个功能。 "},"title":"Quartz job使用过程中的发现问题与改进"},"/blog/2020/04/docker-hub-mirror/":{"data":{"docker-hub-镜像测速#Docker Hub 镜像测速":"使用镜像前后，可使用 time 统计所花费的总时间。测速前先移除本地的镜像！\ndocker rmi node:latest time docker pull node:latest 输出结果\nPulling repository node ... real 0m30s user 0m0.129s sys 0m0.103s ","macos#macOS":"在任务栏点击 Docker Desktop 应用图标 -\u003e Perferences，在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件。修改完成之后，点击 Apply \u0026 Restart 按钮，Docker 就会重启并应用配置的镜像地址了。\n{ \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://registry.docker-cn.com\" ] } ","ubuntu-1604debian-8centos-7#Ubuntu 16.04+、Debian 8+、CentOS 7":"国内访问Docker Hub速度比较感人，这个时候需要配置国内的镜像，来加速下载。由于镜像服务可能出现宕机，建议同时配置多个镜像。\nUbuntu 16.04+、Debian 8+、CentOS 7新建或者修改 /etc/docker/daemon.json，写入如下内容\n{ \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://registry.docker-cn.com\" ] } 重启服务\nsudo systemctl daemon-reload sudo systemctl restart docker ","windows-10#Windows 10":"在任务栏托盘 Docker 图标内右键菜单选择 Settings，打开配置窗口后在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件，之后点击 Apply \u0026 Restart 保存后 Docker 就会重启并应用配置的镜像地址了。\n{ \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://registry.docker-cn.com\" ] } ","其他镜像#其他镜像":" 腾讯云 - https://mirror.ccs.tencentyun.com 七牛云 - https://reg-mirror.qiniu.com 中科大 - https://docker.mirrors.ustc.edu.cn ","参考链接#参考链接":" https://yeasy.gitbooks.io/docker_practice/install/mirror.html ","检查加速器是否生效#检查加速器是否生效":"执行下面命令\ndocker info 如果从结果中看到了如下内容，说明配置成功\nRegistry Mirrors: https://hub-mirror.c.163.com/ https://registry.docker-cn.com/ "},"title":"Docker Hub国内镜像加速"},"/blog/2020/04/modify-apine-mirror/":{"data":{"":"docker使用alpine作为基础可以减少image的大小，但是如果编写的dockerfile中需要安装一些软件，在编译image过程中，可能速度会很慢甚至卡住。\nAlpine 的源文件为/etc/apk/repositories。默认的配置类似：\nhttp://dl-cdn.alpinelinux.org/alpine/v3.11/main http://dl-cdn.alpinelinux.org/alpine/v3.11/community 这个时候就需要在dockerfile中添加下面的命令，将安装包路径指向国内的镜像。\n# 使用阿里云的镜像源 sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories 国内的其他一些镜像源\n# 中国科技大学 sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories # 清华大学 sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories "},"title":"修改Alpine镜像源"},"/blog/2020/04/pg_close_session_remove_db/":{"data":{"":"Postgres删除数据库的时候，报错：有其他用户正在使用该数据库，无法删除。这时，需要关闭这个数据库的相关的连接，然后再删除数据库\n可以执行下面的命令来关闭连接：\nSELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='要删除的数据库名称' AND pid\u003c\u003epg_backend_pid(); "},"title":"Postgres关闭某个数据库关联的session"},"/blog/2020/05/mac_write_iso_into_udisk/":{"data":{"":"使用MacOS自带的dd命令，就可以将ISO镜像写入到U盘。这就可以利用这个命令来制作安装windows，Linux等系统用U盘\n通过下面的命令，找出U盘挂载的路径\ndiskutil list 将U盘取消挂载，在下面命令中将N替换为所对应的挂载盘：\ndiskutil unmountDisk /dev/disk[N] 将内容写入U盘。下面的命令中 rdisk 的 r 可以加快写入速度\nsudo dd if=iso路径 of=/dev/rdisk[N] bs=1m 弹出磁盘\ndiskutil eject /dev/disk[N] "},"title":"MacOS中通过ISO镜像制作U盘安装盘"},"/blog/2020/05/manjaro_chrome_default_browser/":{"data":{"":"安装完 Manjaro，一般会自带 Firefox浏览器。如果自己想再安装 chrome，并且设置成默认浏览器，则需要两个步骤：\n在 Default Applications 中选择 Chrome 为默认的浏览器。除了这一步还不够，打开 chrome 依然有提示说“chrome 不是默认浏览器”，这就需要下面的第二步来解决。 在 File Association 中找到 html 项， 选择使用 Chrome 打开该类型的文件。 "},"title":"Manjaro设置chrome为默认浏览器"},"/blog/2020/05/manjaro_install_vmware/":{"data":{"":"安装VMware workstation\nyay -S vmware-workstation 启动时候如果报错：Please make sure that the kernel module `vmmon’ is loaded. 则需要重新安装一下linux-headers，加载一下vmmon模块\n# 先查看内核。返回值版本号格式为: A.B.C-D-MANJARO。示例： 5.2.8-1-MANJARO， uname -r # 安装 linux-headers。根据上面的内核版本来选择安装包，安装包名字为：linuxAB-headers sudo pacman -S linux52-headers # 加载vmmon模块 sudo modprobe -a vmw_vmci vmmon 如果需要虚拟机要访问网络，则需要执行下面命令来启动服务\nsystemctl start vmware-networks # 或者，设置开机启动 sudo systemctl enable --now vmware-networks.service 如果需要虚拟机要支持USB接口，则需要执行下面命令来启动服务\nsystemctl start vmware-usbarbitrator # 或者，设置开机启动 sudo systemctl enable --now vmware-usbarbitrator.service 如果需要虚拟机要支持网络共享，则需要执行下面命令来启动服务\nsystemctl start vmware-hostd # 或者，设置开机启动 sudo systemctl enable --now vmware-hostd.service 参考链接：\nhttps://wiki.manjaro.org/index.php?title=VMware "},"title":"Manjaro安装VMware Workstation"},"/blog/2020/05/spring_quartz_customize_scheduler_name/":{"data":{"":"当前项目使用quartz与spring来做基于数据库的集群化任务调度，但是在实际使用过程发现同一个scheduler中，不同group之间任务调度可能会相互跑串。当前项目中使用的 quartz-scheduler 版本 2.3.1， spring 版本 3.2.18.RELEASE。\n举个例子，配置是这样的, 下面示例中隐去不重要的配置\n\u003cbean id=\"my-cluster-scheduler\" class=\"org.springframework.scheduling.quartz.SchedulerFactoryBean\" lazy-init=\"false\"\u003e ... \u003cproperty name=\"quartzProperties\"\u003e \u003cprops\u003e \u003cprop key=\"org.quartz.jobStore.isClustered\"\u003etrue\u003c/prop\u003e \u003cprop key=\"org.quartz.jobStore.class\"\u003eorg.quartz.impl.jdbcjobstore.JobStoreCMT\u003c/prop\u003e \u003c/props\u003e ... \u003c/property\u003e \u003cproperty name=\"jobDetails\"\u003e \u003clist\u003e \u003cref bean=\"myTestJobDetailBean\"/\u003e \u003c/list\u003e \u003c/property\u003e \u003cproperty name=\"triggers\"\u003e \u003clist\u003e \u003cref bean=\"myTestJobTrigger\"/\u003e \u003c/list\u003e \u003c/property\u003e \u003c/bean\u003e \u003cbean id=\"myTestJobTrigger\" class=\"org.springframework.scheduling.quartz.CronTriggerFactoryBean\"\u003e \u003cproperty name=\"jobDetail\" ref=\"myTestJobDetailBean\"/\u003e \u003cproperty name=\"cronExpression\" value=\"${my.test.job.cron.expression}\"/\u003e \u003cproperty name=\"group\" value=\"${{my.test.job.group}\"/\u003e \u003c/bean\u003e \u003cbean id=\"myTestJobDetailBean\" class=\"org.springframework.scheduling.quartz.JobDetailFactoryBean\"\u003e \u003cproperty name=\"jobClass\" value=\"net.zengxi.job.MyTestJob\"/\u003e \u003cproperty name=\"durability\" value=\"true\"/\u003e \u003cproperty name=\"group\" value=\"${my.test.job.group}\"/\u003e \u003cproperty name=\"name\" value=\"myTestJob\"/\u003e \u003c/bean\u003e 在配置文件中，通过${my.test.job.group}来指定group的名字。在部署的时候，部署了4台机器。机器1与2是一组，设置的值是group1；机器3与4是一组，设置的值是group2。按照正常情况下，两个分组不会相互干扰。调度任务的时候，group1的trigger，会从机器1与2里面选择一台机器来执行任务，group2的trigger会从3与4里面选择一台。但是，实际跑下来的结果是，偶尔会发现任务跑串了。比如，group2的trigger在调度任务的时候，居然从另外一个分组的机器1与2（期望的是3或者4）里面选择一台机器执行任务。这样在日志里面看到机器1与2把同一个任务执行了两遍，而机器3与4里面没有执行记录。\n这个看上去是框架的bug。为了快速解决问题，想到了一个办法就是，将不同分组的调度器分开，也就是分别指定不同的scheduler。\n通过quartz官方的文档，可以了解到，集群环境下的不同实例中如果scheduler name相同，则表示他们使用的是相同的scheduler。那我们就只需要让不同的分组使用不同的scheduler name\norg.quartz.scheduler.instanceName Can be any string, and the value has no meaning to the scheduler itself - but rather serves as a mechanism for client code to distinguish schedulers when multiple instances are used within the same program. If you are using the clustering features, you must use the same name for every instance in the cluster that is ‘logically’ the same Scheduler. 这里我们使用了spring框架，默认情况下，如果不指定scheduler name，使用的bean id指作为scheduler name。如果要指定自己的scheduler name，那么正常情况下，在spring的配置中设置 org.quartz.scheduler.instanceName 属性就可以了。然而，测试下来发现，这个配置没起作用。估计是spring的bug，至少在springboot中，其他人也发现过这个问题:\nhttps://github.com/spring-projects/spring-boot/issues/14243 https://github.com/spring-projects/spring-boot/issues/14481 \u003cbean id=\"my-cluster-scheduler\" class=\"org.springframework.scheduling.quartz.SchedulerFactoryBean\" lazy-init=\"false\"\u003e ... \u003cproperty name=\"quartzProperties\"\u003e \u003cprops\u003e \u003cprop key=\"org.quartz.scheduler.instanceName\"\u003e${my.test.job.group}-my-cluster-scheduler\u003c/prop\u003e ... \u003c/props\u003e ... \u003c/property\u003e ... \u003c/bean\u003e 考虑到升级第三方库可能给生产环境带来的风险，暂时不升级的话，只能从org.springframework.scheduling.quartz.SchedulerFactoryBean的源码中看看是否有快速的解决方案。后来发现它自带了schedulerName的getter与setter方法，这样就简单了，只需要配置schedulerName属性值即可。\n\u003cbean id=\"my-cluster-scheduler\" class=\"org.springframework.scheduling.quartz.SchedulerFactoryBean\" lazy-init=\"false\"\u003e ... \u003cproperty name=\"schedulerName\" value=\"${my.test.job.group}-my-cluster-scheduler\"/\u003e \u003cproperty name=\"quartzProperties\"\u003e \u003cprops\u003e ... \u003c/props\u003e ... \u003c/property\u003e ... \u003c/bean\u003e "},"title":"Spring Quartz 指定Scheduler Name"},"/blog/2020/06/pg_check_table_size/":{"data":{"":"原文链接：https://blog.csdn.net/kmust20093211/article/details/47616345\n方法一 ，查某个表\nselect pg_size_pretty(pg_relation_size('table_name')); 方法二 ，查出所有表并按大小排序\nSELECT table_schema || '.' || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size('\"' ||table_schema || '\".\"' || table_name || '\"')) AS size FROM information_schema.tables ORDER BY pg_total_relation_size('\"' || table_schema || '\".\"' || table_name || '\"') DESC limit 20; 方法三，查出所有表按大小排序并分离data与index\nSELECT table_name, pg_size_pretty(table_size) AS table_size, pg_size_pretty(indexes_size) AS indexes_size, pg_size_pretty(total_size) AS total_size FROM ( SELECT table_name, pg_table_size(table_name) AS table_size, pg_indexes_size(table_name) AS indexes_size, pg_total_relation_size(table_name) AS total_size FROM ( SELECT ('\"' || table_schema || '\".\"' || table_name || '\"') AS table_name FROM information_schema.tables ) AS all_tables ORDER BY total_size DESC ) AS pretty_sizes; "},"title":"转: postgresql 查看单个表大小"},"/blog/2020/06/pg_wale_continuous_archiving/":{"data":{"base-backup#Base Backup":"也称为热备份，它不会中断PostgreSQL中任何事务。一旦启动了basebackup，它将等待一个checkpoint。如果到达了checkpoint，那么它将把整个数据目录复制到一个文件中。这些备份将会是replication或POINT IN TIME恢复的起点。通常，basebackup是不一致的，可能包含已经损坏的数据。这时，就需要用到WAL文件","consitent-backup#Consitent Backup":"Consitent Backup(一致性备份) = Base backup + WAL backup\nWAL日志文件必须在还原基础备份之后再还原。还原WAL文件的相关命令，必须在recovery.conf的restore_command中设置","wal#WAL":"通过WAL文件可以获得数据库内所有数据的变更。这些变更首先写入WAL文件，然后再对数据库进行实际性地写入 。因此被称作Write Ahead Log。","wal-e中的一些命令#WAL-E中的一些命令":" backup-push - 做基础备份 backup-fetch - 做还原基础备份 wal-push - 备份wal文件 wal-fetch - 还原wal文件 ","一些基本概念#一些基本概念":"wal-e这个工具可以用来给postgres数据库做基础备份与增量备份，这个对数据库容灾很有帮助。目前它支持将备份存储到AWS S3，Azure Blob Store与Google Storage等。\n一些基本概念","用法#用法":"大致的用法就是：\n主库 安装wal-e，在配置目录中指定备份需要存储的地址以及身份认证 新建crontab，调用backup-push定时做基础备份 修改postgres配置目录下的postgresql.conf中的配置，开启archive并指定archive命令备份wal文件 备库 安装wal-e，在配置目录中指定获取备份的地址以及身份认证 用backup-fetch还原一次基础备份 在postgres的数据目录下面，新增recovery.conf配置文件，里面指定了还原wal备份的命令 更多详细内容与配置，可以参考它的github项目：https://github.com/wal-e/wal-e/\n参考链接：\nhttps://github.com/wal-e/wal-e/ https://dba.stackexchange.com/questions/211416/postgresql-how-to-take-incremental-backup-with-wal-e/211422 "},"title":"postgres增量备份工具：wal-e"},"/blog/2020/06/rsyslog_high_memory_usage/":{"data":{"":"这几天生产环境中某个服务内存不时地被撑爆，原先以为是应用的问题，但是近来没有上过新的代码。该服务的总内存是8G，启动参数关于内存的配置大致是：-Xmx=6.4G，-Xms=4G 左右。看了Grafana上面的监控记录，JVM 老年代使用最多也就到4G左右，在GC的日志中发现也仅仅用到4G左右，并没有到达最高的内存值。这两个结果可以看出来，应该不是应用程序导致内存占用过大。\n后来用top命令看了一下，发现rsyslog进程使用了将近40%的内存。再查一下日志文件，发现一些日志文件大小都达到2G以上。\nrsyslog仅仅是用来同步日志，原则上讲，它仅仅是辅助的进程，不应该占用那么内存，即使它同步延迟较大甚至不工作，也不应该影响到应用程序的正常运行。那么，我们可以通过限制它的内存使用率来解决这个问题。\n如果是Ubuntu系统，可以通过修改 /etc/systemd/system/rsyslog.service 文件，在Service项目下面修改或者添加以下参数。在其他的Linux系统下，路径可能不同。通常情况下rsyslogd大小只有5M，所以将内存上限设置为8M，绝对内存限制为80M。注意: $SYSLOGD_OPTIONS这个参数必须添加上去，否则限制可能不生效。\n[Service] ExecStart=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS MemoryAccounting=yes MemoryMax=80M MemoryHigh=8M 然后重启服务:\nsystemctl daemon-reload systemctl restart rsyslog 几个参数的含义：\n名称 描述 MemoryAccounting 若设为”yes”则表示为此单元开启内存占用统计。 注意，这同时也隐含的开启了该单元 所属的 slice 以及父 slice 内所有单元的内存占用统计。 此选项的默认值由 DefaultMemoryAccounting= 决定 MemoryHigh 尽可能限制该单元中的进程最多可以使用多少内存。 虽然这是一个允许被突破的柔性限制，但是突破限制后，进程的运行速度将会大打折扣， 并且系统将会尽可能尽快回收超出的内存。此选项的目的在于柔性限制内存使用量。选项值可以是以字节为单位的绝对内存大小(可以使用以1024为基数的 K, M, G, T 后缀)， 也可以是以百分比表示的相对内存大小(相对于系统的全部物理内存)， 还可以设为特殊值 “infinity” 表示不作限制。 MemoryMax 绝对刚性的限制该单元中的进程最多可以使用多少内存。 这是一个不允许突破的刚性限制，触碰此限制会导致进程由于内存不足而被强制杀死。 建议将 MemoryHigh= 用作主要的内存限制手段， 而将 MemoryMax= 用作不可突破的底线。选项值可以是以字节为单位的绝对大小(可以使用以1024为基数的 K, M, G, T 后缀)， 也可以是以百分比表示的相对大小(相对于系统的全部物理内存)， 还可以设为特殊值 “infinity” 表示不作限制。 参考链接：\nhttps://www.sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html https://blog.espnlol.com/?p=525 "},"title":"rsyslog内存占用高导致服务不可用"},"/blog/2020/06/string_adapter/":{"data":{"":"客户用的是很旧版本的ERP系统，在与客户系统做接口对接的时候发现了一个问题。假设接口请求需要的body是xml格式的，共有三个字段：name, mobile, email。由于客户ERP系统比较老，如果某个字段没有值，传的是空字符串，而不是将该字段在请求消息体中隐藏。客户发的请求类似下面的例子：\n\u003cxml\u003e \u003cname\u003eJohn\u003c/name\u003e \u003cmobile\u003e13800138000\u003c/mobile\u003e \u003cemail\u003e\u003c/email\u003e \u003c/xml\u003e 由于历史遗留问题，我方系统里在字段上面加了 javax.validation.constraints.Pattern 注解使用正则表达式来对传入的请求值做验证。当传入值为空字符串的时候，正则表达式验证就无法通过。\n与客户做过沟通，对于空值的字段，他们也没有办法在请求中隐藏字段，只能传空字符串。那就只能在我方系统这边看看是否可以通过修改代码来解决。一种方案是修改正则表达式，来兼容空字符串，但是由于这些都是传统代码，不确定把空字符串设置在这个字段上面会对后面的处理会有什么影响。如果有更合适的、代价更小的方案，那么就最好不选择这种。\n@XmlType @XmlAccessorType(XmlAccessType.FIELD) public class TestRequest implements Serializable { @XmlElement(required = true) private String name; @XmlElement(required = false) @Pattern(regexp = Constants.regexpMobile, message = \"invalidMobile\") private String mobile; @XmlElement(required = false) @Pattern(regexp = Constants.regexpEmail, message = \"invalidEmail\") private String email; // getter / setter ... } 通过查阅相关资料，发现 javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter 注解可以达到目的。这个注解可以指定一个类，用于转换与处理xml请求中的字段值。这样，我们只需要自定义一个类，将传入空字符串值转换成null\n首先，先定义一个XmlAdapter类\npublic class MyXmlStringAdapter extends XmlAdapter\u003cString, String\u003e { @Override public String marshal(String value) throws Exception { if (\"\".equals(value)) { return null; } return value; } @Override public String unmarshal(String value) throws Exception { if (\"\".equals(value)) { return null; } return value; } } 然后，在相应的字段上面，使用前面定义好的XmlAdapter类。这样，xml解析器在转换请求的时候，会将空字符串转换成null，这样就认为该字段没有传值，不使用正则表达式做验证。\n@XmlType @XmlAccessorType(XmlAccessType.FIELD) public class TestRequest implements Serializable { @XmlElement(required = true) private String name; @XmlElement(required = false) @Pattern(regexp = Constants.regexpMobile, message = \"invalidMobile\") @XmlJavaTypeAdapter(value = MyXmlStringAdapter.class, type = String.class) // Use MyXmlStringAdapter private String mobile; @XmlElement(required = false) @Pattern(regexp = Constants.regexpEmail, message = \"invalidEmail\") @XmlJavaTypeAdapter(value = MyXmlStringAdapter.class, type = String.class) // Use MyXmlStringAdapter private String email; // getter / setter ... } "},"title":"用string adapter来解决系统接口对接中发现的空值验证问题"},"/blog/2020/07/check_zookeeper_version/":{"data":{"":"在控制台下面命令\necho stat|nc localhost 2181 返回结果示例\nZookeeper version: 3.4.8-1--1, built on Fri, 26 Feb 2016 14:51:43 +0100 Clients: /10.30.1.186:33824[1](queued=0,recved=203121,sent=203148) /10.30.1.116:39374[1](queued=0,recved=56774,sent=56790) /10.30.1.171:37240[1](queued=0,recved=20793,sent=20793) Latency min/avg/max: 0/0/10748 Received: 855235993 Sent: 856603574 Connections: 36 Outstanding: 0 Zxid: 0x125c07103 Mode: leader Node count: 6047 "},"title":"查看zookeeper版本"},"/blog/2020/07/clear_chrome_https_cert_cache/":{"data":{"":"在地址栏输入 chrome://net-internals/#hsts ， 找到 “Delete domain security policies”， 输入对应的域名，点击 Delete 按钮"},"title":"清除chrome中 HTTPS 证书缓存"},"/blog/2020/07/grep_binary_file_match/":{"data":{"":"grep “keyword” xxx.log时输出: Binary file (standard input) matches\n这个是因为grep命令认为它是一个二进制文件。解决方案是，加上一个参数 -a：\ngrep -a \"keyword\" xxx.log 该参数的解释：\n-a, --text equivalent to --binary-files=text "},"title":"grep 返回 Binary file (standard input) matches"},"/blog/2020/07/jetty_tmp_dir/":{"data":{"":"生产环境上jetty运行一段时间后，在打开某个网页的时候发现有js、css文件找不到，但是重启之后问题会解决。后来发现是设定了tmpwatch后台任务，定时会清理一次系统的tmp目录。\n默认情况下，如果没有指定jetty的临时目录，默认会使用系统的临时目录。解决方案就是，修改jetty的临时文件存放目录，不要放在 /tmp 目录下面。主要有下面几个方法：\n设置basetempdir值 \u003cConfigure class=\"org.eclipse.jetty.webapp.WebAppContext\"\u003e \u003cSet name=\"contextPath\"\u003e/test\u003c/Set\u003e \u003cSet name=\"war\"\u003efoo.war\u003c/Set\u003e \u003cCall name=\"setAttribute\"\u003e \u003cArg\u003eorg.eclipse.jetty.webapp.basetempdir\u003c/Arg\u003e \u003cArg\u003e/home/my/foo\u003c/Arg\u003e \u003c/Call\u003e \u003c/Configure\u003e 设置tempDirectory值 \u003cConfigure class=\"org.eclipse.jetty.webapp.WebAppContext\"\u003e \u003cSet name=\"contextPath\"\u003e/test\u003c/Set\u003e \u003cSet name=\"war\"\u003efoo.war\u003c/Set\u003e \u003cSet name=\"tempDirectory\"\u003e/some/dir/foo\u003c/Set\u003e \u003c/Configure\u003e 设置 javax.servlet.context.tempdir 属性 \u003cConfigure class=\"org.eclipse.jetty.webapp.WebAppContext\"\u003e \u003cSet name=\"contextPath\"\u003e/test\u003c/Set\u003e \u003cSet name=\"war\"\u003efoo.war\u003c/Set\u003e \u003cCall name=\"setAttribute\"\u003e \u003cArg\u003ejavax.servlet.context.tempdir\u003c/Arg\u003e \u003cArg\u003e/some/dir/foo\u003c/Arg\u003e \u003c/Call\u003e \u003c/Configure\u003e 在启动参数里面修改 java -jar ../start.jar -Djava.io.tmpdir=/path/to/desired/directory 参考：\nhttps://www.eclipse.org/jetty/documentation/current/ref-temporary-directories.html "},"title":"jetty临时目录下的资源文件被删导致js等资源找不到"},"/blog/2020/07/linux_dd_cmd_write_usb_disk/":{"data":{"查看执行进度#查看执行进度":"假定需要每5秒输出dd的进度，可以使用下面几种方法。新开一个命令行窗口，执行下面的命令，注意命令上面可能需要加上sudo\n方法一：\nwatch -n 5 pkill -USR1 ^dd$ 方法二：\nwatch -n 5 killall -USR1 dd 方法三：\nwhile killall -USR1 dd; do sleep 5; done 方法四：\nwhile (ps auxww |grep \" dd \" |grep -v grep |awk '{print $2}' |while read pid; do kill -USR1 $pid; done) ; do sleep 5; done 上述四种方法中使用三个命令：pkill、killall、kill向dd命令发送SIGUSR1信息，dd命令进程接收到信号之后就打印出自己当前的进度。\n看到的效果类似：\n772+0 records in 772+0 records out 809500672 bytes (810 MB, 772 MiB) copied, 117.321 s, 6.9 MB/s 791+0 records in 791+0 records out 829423616 bytes (829 MB, 791 MiB) copied, 122.737 s, 6.8 MB/s 809+0 records in 809+0 records out 848297984 bytes (848 MB, 809 MiB) copied, 128.148 s, 6.6 MB/s 824+0 records in 824+0 records out 864026624 bytes (864 MB, 824 MiB) copied, 132.425 s, 6.5 MB/s 843+0 records in 843+0 records out 883949568 bytes (884 MB, 843 MiB) copied, 137.895 s, 6.4 MB/s 862+0 records in 862+0 records out 903872512 bytes (904 MB, 862 MiB) copied, 143.285 s, 6.3 MB/s 877+0 records in 877+0 records out 919601152 bytes (920 MB, 877 MiB) copied, 147.639 s, 6.2 MB/s ","烧录u盘#烧录U盘":"烧录U盘先用fdisk来查看U盘的盘符\nsudo fdisk -l 再用dd命令来写数据到U盘\nsudo dd if=/home/paul/Downloads/test.iso of=/dev/sdc bs=1M count=10000 "},"title":"Linux下面使用dd命令烧录U盘并查看执行进度"},"/blog/2020/07/terraform_aliyun_ecs_ssh_key/":{"data":{"":"目前的terraform脚本中，在新建阿里云ECS的时候，会通过 user_data 属性值来设定初始的ssh key。但是这个就存在一个隐患，如果将来想要改变初始的ssh key，再用terraform来推机器的时候，terraform发现user_data属性值发生变化，会删除现有的ECS并重建。\n解决的方法是，修改ECS的lifecycle，将user_data添加到忽略列表中。这样terraform就可以忽略掉该属性值的变化。\n{ resource \"alicloud_instance\" \"test_instance\" { ... lifecycle { ignore_changes = [\"user_data\"] } } } "},"title":"terraform中阿里云ECS ssh key变化问题"},"/blog/2020/07/terraform_state_consistent/":{"data":{"1删除-state-中的现有资源#(1)删除 state 中的现有资源":"如果该资源受 terraform 管理，则需要先把它删除。执行下面的命令\n# 基于当前的tf文件，初始化 state 文件 terraform init # 列出当前的state文件所有管理的项目清单 terraform state list # 根据上面的输出，找到对应的项目的名称。通过rm删除, 下面假设项目名称是 alicloud_instance.testecs terraform state rm alicloud_instance.testecs ","2在阿里云控制台获取实例id#(2)在阿里云控制台获取实例ID":"登录阿里云网页上的控制台，获取所要导入的实例 ID","3tf-文件中添加实例的定义#(3)tf 文件中添加实例的定义":"保证本地的tf文件中有该实例资源的相关定义。如果没有，则可以用下面的方式在文件中新增内容。\n如果是以resource模式定义，则添加下面内容，直接留空即可，其余的数据在后续步骤中可以补全\nresource \"alicloud_instance\" \"testecs\" {} 如果是以模块方式来定义，则添加下面内容，其余的数据在后续步骤中可以补全\nmodule \"testmodule\" { source = \"../modules/instance\" environment = \"xxx\" vswitch_info = \"xxxx\" vpc_id = \"xxxx\" instance_type = \"xxxx\" security_groups = \"xxxx\" service = \"xxxx\" instance_count = \"xxxxx\" system_disk_size = \"xxxxx\" system_disk_category = \"xxxxx\" alicloud_availability_zones = \"xxxxx\" } ​","4导入实例#(4)导入实例":"如果是以resource模式定义，则直接用实例的资源路径\nterraform import alicloud_instance.testecs i-xxxxxxxxxxxxxx ​ 如果是以模块方式来定义, 则使用包含模块的资源路径\nterraform import module.testmodule.alicloud_instance.instance i-xxxxxxxxxxxxxx ​如果该服务有多个实例，则要指定下标。注意：下标部分要用引号，否则报错\nterraform import module.testlistmodule.alicloud_instance.\"instance[0]\" i-xxxxxxxxxxxxxx ​","5补齐资源模板定义#(5)补齐资源模板定义":"在确定清楚参数属性的具体值之后，如果以模板参数值为准，那么只需要运行apply命令再变更回来即可；如果以控制台的值为准，那么只需要补充或修改模板参数值即可。\n由于模板中没有完成对所导入资源的详细定义，因此，资源导入成功后，模板内容与State存储的内容存在差异，此时如果直接运行plan命令，将会看到一个update。为了保持资源模板与资源状态的一致，需要在模板中手动补齐缺失的参数定义，直到运行plan不会再有变更信息为止","后记#后记":"阿里云的文档中提到了另外三种场景，应该也可以用类似的方式来处理：\n长期使用控制台、阿里云CLI、资源编排服务或者直接调用API创建和管理资源，初次使用Terraform的场景。 所有资源都定义在一个模板中，想要对原有模板进行重构拆分，以降低随着资源不断增多而带来的模板和state的管理复杂度的场景。 想要将新版Provider中新增的参数同步到原文档中的场景。 参考链接：\nhttps://help.aliyun.com/document_detail/146144.html?spm=a2c4g.11186623.6.574.b7e93235LDfPtG https://github.com/hashicorp/terraform/issues/8149 ","概述#概述":"概述在运维过程中遇到了下面的情况：长期使用terraform管理资源，但是通过terraform以外的工具对云资源做过属性变更（比如通过网页上的控制台对云资源做属性变更）。此时，云资源的属性与terraform state的信息已经不一致，跑terraform plan就会发现，它会删除现有的，然后重建一个。但是这个是我们不希望看到的，我们希望可以保留原有实例并且把本地的terraform state更新成最新的属性。","解决方案#解决方案":"要想解决这个问题，可以利用 terraform import 命令。也就是重新导入云资源的实例，然后同步成最新的信息。\n下面以阿里云ECS为例子。"},"title":"解决terraform与远程云服务器资源状态不一致的问题"},"/blog/2020/07/zookeeper_purge_file/":{"data":{"1-写脚本删除#(1) 写脚本删除":"zookeeper主要存放了三类文件，他们都可以在配置文件中指定存储路径：\nsnapshot： 内存数据的快照，配置项为dataDir 事务日志：所有与修改数据相关的操作记录，配置项为dataLogDir。在没有dataLogDir配置项的时候，zookeeper默认将事务日志文件和快照日志文件都存储在dataDir对应的目录下。 log4j日志：记录zookeeper集群服务器运行日志。日志的配置地址在conf/目录下的log4j.properties文件中，该文件中有一个配置项为\"zookeeper.log.dir=.\" 正常运行过程中，zookeeper会不断地把快照数据和日志输出到这些目录。如果没有专门做配置或者人为清理，日志文件不会自动清理，磁盘会越占越多。\n主要的清理方法有下面几种。\n(1) 写脚本删除写一个删除日志脚本，每天定时执行\n#!/bin/bash #snapshot file dir dataDir=/home/yinshi.nc/test/zk_data/version-2 #tran log dir dataLogDir=/home/yinshi.nc/test/zk_log/version-2 #zk log dir logDir=/home/yinshi.nc/test/logs #Keep 66 files count=66 count=$[$count+1] ls -t $dataLogDir/log.* | tail -n +$count | xargs rm -f ls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -f ls -t $logDir/zookeeper.log.* | tail -n +$count | xargs rm -f 写到crontab中，设置为每天凌晨2点执行一次就可以了\ncrontab -e 2 2 * * * /bin/bash /root/clean_zook_log.sh \u003e /dev/null 2\u003e\u00261 ","2-zookeeper自带工具#(2) Zookeeper自带工具":"使用ZK的工具类PurgeTxnLog，它的实现了一种简单的历史文件清理策略，可以参考API文档看一下使用方法：http://zookeeper.apache.org/doc/r3.4.3/api/index.html\n其实在bin/zkCleanup.sh中，就直接调用了PurgeTxnLog这个工具类，所以直接使用这个脚本也是可以执行清理工作的，也更方便。比如：\n/usr/lib/zookeeper/bin/zkCleanup.sh /hadoop/zookeeper/version-2/ 5 ","3-zookeeper自动清理配置项#(3) Zookeeper自动清理配置项":"从3.4.0开始，zookeeper提供了自动清理snapshot和事务日志的功能，通过配置 autopurge.snapRetainCount 和 autopurge.purgeInterval 这两个参数能够实现定时清理了。这两个参数都是在zoo.cfg中配置的：\n# 指定清理频率，单位是小时，默认是0，表示不开启自己清理功能。 autopurge.purgeInterval=6 # 和上面的参数搭配使用，指定需要保留的文件数目，默认是保留3个。 autopurge.snapRetainCount=5 参考：\nhttps://www.cnblogs.com/sunxucool/p/5500758.html https://www.cnblogs.com/jxwch/p/6526271.html "},"title":"zookeeper服务器文件清理"},"/blog/2020/08/gitbook_installation_error/":{"data":{"":"如果nodejs使用的不是10.x版本，就会报错\nInstalling GitBook 3.2.3 /usr/local/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 if (cb) cb.apply(this, arguments) ^ TypeError: cb.apply is not a function at /usr/local/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 at FSReqCallback.oncomplete (fs.js:177:5) 参考：\nhttps://www.bilibili.com/read/cv6932054/ "},"title":"gitbook因为nodejs版本不匹配导致安装报错"},"/blog/2020/08/linux_auto_set_brightness/":{"data":{"1-创建一个启动service脚本#1. 创建一个启动service脚本":"笔记本在manjaro在启动的时候，屏幕可能会默认设置为最大亮度。可以通过设置开机启动脚本，来设置启动时候的亮度。\n1. 创建一个启动service脚本执行下面的命令\nsudo vim /etc/systemd/system/rc-local.service 输入下面的内容\n[Unit] Description=\"/etc/rc.local Compatibility\" [Service] Type=oneshot ExecStart=/etc/rc.local start TimeoutSec=0 StandardInput=tty RemainAfterExit=yes SysVStartPriority=99 [Install] WantedBy=multi-user.target ","2-创建-etcrclocal-文件#2. 创建 /etc/rc.local 文件":"执行下面的命令\nsudo vim /etc/rc.local 输入下面的内容\n#!/bin/sh # /etc/rc.local if test -d /etc/rc.local.d; then for rcscript in /etc/rc.local.d/*.sh; do test -r \"${rcscript}\" \u0026\u0026 sh ${rcscript} done unset rcscript fi ","3-添加执行权限#3. 添加执行权限":" sudo a+x /etc/rc.local ","4-添加etcrclocald文件夹#4. 添加/etc/rc.local.d文件夹":" sudo mkdir /etc/rc.local.d ","5-设置开机自启#5. 设置开机自启":" systemctl enable rc-local.service ","6-添加设置亮度脚本#6. 添加设置亮度脚本":"在 /sys/class/backlight 可以看到对应显卡的文件夹，如果是双显卡的话，会有两个文件夹。脚本可以先对其中一个文件夹做设置，如果不生效就改成另外一个。\n假设显卡文件夹的名称是intel_backlight，下面的命令可以查看屏幕亮度最大值，后面设置实际亮度的时候，不能超过这个值：\ncat /sys/class/backlight/intel_backlight/max_brightness 修改文件权限避免启动时修改文件内容报错：\nsudo chmod a+w /sys/class/backlight/intel_backlight/brightness 执行下面的命令新建文件：\nsudo vim /etc/rc.local.d/set-brightness.sh 输入文件内容，设置一个合适的亮度值：\necho 50 \u003e /sys/class/backlight/intel_backlight/brightness 参考：\nhttps://blog.csdn.net/u014025444/article/details/90142558 "},"title":"Manjaro笔记本启动时自动设置屏幕亮度"},"/blog/2020/08/manjaro_debtap/":{"data":{"":"安装debtap\nyay -S debtap 替换源，解决国内debtap同步仓库执行超慢的问题。打开 /usr/bin/debtap，更换 debtap 内容：\n将 http://ftp.debian.org/debian/dists 替换成 https://mirrors.ustc.edu.cn/debian/dists 将 http://archive.ubuntu.com/ubuntu/dists 替换成 https://mirrors.ustc.edu.cn/ubuntu/dists 升级debtap数据库\nsudo debtap -u 转换deb包。注意： 转换过程中会提示输入包名，以及license。包名随意，license可以填GPL。上述操作完成后会在deb包同级目录生成xxx.tar.xz文件\nsudo debtap xxxx.deb # -q 可以略过除了编辑元数据之外的所有问题 sudo debtap -q xxx.deb # 略过所有的问题（不推荐） sudo debtap -Q xxx.deb 安装转换好的本地包\nsudo pacman -U xxx.tar.xz 参考：\nhttps://www.jianshu.com/p/900dc8a0ecff "},"title":"Manjaro安装deb包"},"/blog/2020/09/postgres_startup_readonly_file_error/":{"data":{"关于fsck#关于fsck":"ext3的文件系统使用fsck.ext3，ext4文件系统使用fsck.etx4。/dev/vda3是系统/根分区。运行完毕后，reboot重启系统就恢复正常\nfsck不仅可以对文件系统进行扫描，还能修正文件系统的一些问题。注意的是fsck扫描文件系统时一定要在单用户模式、修复模式或把设备umount后进行。建议在单用户模式下运行。如果扫描正常运行中的系统，会造成系统文件损坏。\n文件系统扫描工具有fsck、fsck.ext2、fsck.ext3、fsck.ext4、fsck.msdos、fsck.cramfs、fsck.ext4dev、fsck.vfat。最好是根据不同的文件系统来调用不同的扫描工具，比如ext3的文件系统使用fsck.ext3，ext4文件系统使用fsck.ext4等。\n参考：\nhttps://blog.csdn.net/frank1998819/article/details/84676481 ","问题与解决方法#问题与解决方法":"问题与解决方法公司内部私有云由于断电，机器没有正常关机，结果导致 Postgres 服务器启动时，报错\n2020-09-09 07:22:15.296 UTC [3876] FATAL: could not remove old lock file \"postmaster.pid\": Read-only file system 2020-09-09 07:22:15.296 UTC [3876] HINT: The file seems accidentally left over, but it could not be removed. Please remove the file by hand and try again. pg_ctl: could not start server 尝试执行下面命令去重新挂载磁盘目录\nmount -o remount -w /var/lib/postgresql/ 但是报错\nmount: /dev/vdb is write-protected but explicit `-w' flag given 尝试另外一个命令\numount /dev/vdb 但是还是报错\numount: /var/lib/postgresql: target is busy (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1).) 这样的话， 看上去由于系统没有正常关机，导致虚拟磁盘出现文件系统错误。只能通过fsck手动修复。\n由于上面出现提示设备忙，则可以用下面命令查看进程号\nfuser -m /var/lib/postgresql /var/lib/postgresql: 3760c 修改命令参数后可以查看进程，同时杀掉进程\nfuser -mk /var/lib/postgresql /var/lib/postgresql: 3760c 杀掉进程后，如果控制台中的ssh连接断开了，重连即可\n接着，运行命令修复磁盘\nfsck.ext3 -y /dev/vdb 然后重新挂载设备\nmount /dev/vdb /var/lib/postgresql/ 重启服务即可\nservice postgresql restart "},"title":"Postgres启动时遇到只读文件系统的错误"},"/blog/2020/10/nodejs_switch_version/":{"data":{"":"安装n\nsudo npm install n -g 安装完后，可以使用命令 sudo n \u003cNODEJS 版本号\u003e 来安装对应的nodejs版本\n需要切换版本时，执行下面的命令。然后用键盘上面的上下方向键即可切换\nsudo n 切换完后，执行下面命令来验证当前版本号\nnode -v "},"title":"利用n来切换Nodejs版本"},"/blog/2020/10/ubuntu_install_postgresql/":{"data":{"":"ubuntu自带的软件仓库可能没有最新的postgres，这就需要自己手动添加安装源，再安装\n# 添加安装源 sudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" \u003e /etc/apt/sources.list.d/pgdg.list' # 导入key wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - # 更新软件列表 sudo apt-get update # 查找相关的软件包 sudo apt-cache search postgres # 安装 sudo apt install \u003c对应的软件名称\u003e 参考：\nhttps://www.postgresql.org/download/linux/ubuntu/ "},"title":"Ubuntu安装Postgres"},"/blog/2020/11/cloudflare_https_redirect_522_error/":{"data":{"":"笔者使用Cloudflare做DNS，同时使用Cloudflare的SSL证书服务。整个链路如下图:\n|----------| |-----------| |---------------| | Brower | ------\u003e | Cloudfare | ------\u003e | Origin Server | |----------| |-----------| |---------------| 笔者想要做整个链路的https，但是在配置完之后，打开页面是看到522的错误。这个错误表示连接上源站点，但是请求超时。可以参考这个页面来找到可能的原因： https://support.cloudflare.com/hc/en-us/articles/115003011431-Error-522-Connection-timed-out#522error\nCloudfare在配置https的时候有4个选项：\nOff (not secure): 不开启 Flexible: 仅在浏览器与Cloudflare之间用https加密传输, Cloudflare到源站之间不加密 Full: 整个链路的端到端加密, 源站可使用自签名的证书 Full (strict)：整个链路的端到端加密，但是源站必须使用可信任的CA证书或者Cloudflare Origin CA证书。Cloudflare Origin CA证书是用于Cloudfare与源站之间的加密通讯，需要在Cloudflare控制台配置 如果选择不恰当的选项，可能会导致访问错误。比如，如果源网站用的是自签名的证书，但是选择Full (strict)选项，会报证书错误。\n笔者遇到522的问题，是由于iptables规则的设置问题。把cloudflare的ip段添加到iptables的允许列表中就可以了。ip列表见： https://www.cloudflare.com/zh-cn/ips\niptables -A INPUT -p tcp -s 173.245.48.0/20 -j ACCEPT iptables -A INPUT -p tcp -s 103.21.244.0/22 -j ACCEPT iptables -A INPUT -p tcp -s 103.22.200.0/22 -j ACCEPT iptables -A INPUT -p tcp -s 103.31.4.0/22 -j ACCEPT iptables -A INPUT -p tcp -s 141.101.64.0/18 -j ACCEPT iptables -A INPUT -p tcp -s 108.162.192.0/18 -j ACCEPT iptables -A INPUT -p tcp -s 190.93.240.0/20 -j ACCEPT iptables -A INPUT -p tcp -s 188.114.96.0/20 -j ACCEPT iptables -A INPUT -p tcp -s 197.234.240.0/22 -j ACCEPT iptables -A INPUT -p tcp -s 198.41.128.0/17 -j ACCEPT iptables -A INPUT -p tcp -s 162.158.0.0/15 -j ACCEPT iptables -A INPUT -p tcp -s 104.16.0.0/12 -j ACCEPT iptables -A INPUT -p tcp -s 172.64.0.0/13 -j ACCEPT iptables -A INPUT -p tcp -s 131.0.72.0/22 -j ACCEPT "},"title":"Cloudflare开启HTTPS加密后，请求转发到源站报522错误"},"/blog/2020/11/es_max_map_count_error/":{"data":{"":"在启动elastic search的时候，在启动日志看到下面的错误提示\nMax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决这个问题，有两个办法：\n临时的，仅当前会话窗口有效 执行下面命令 sysctl -w vm.max_map_count=262144 然后启动elastic search\n永久生效 编辑/etc/sysctl.conf, 添加或者修改下面参数：\nvm.max_map_count=262144 重启系统，或者执行下面命令加载参数：\nsysctl --system "},"title":"Elastic Search vm.max_map_count too low 错误"},"/blog/2020/11/nas_frp_nginx/":{"data":{"iptables#iptables":"如果安装了iptables，需要确保所需的端口允许外部访问。至少需要放行4个端口：\nhttps协议默认端口443 frps服务端口。端口号可自定义，用于与frpc通讯。上面例子中是7000 frps的vhost https端口。端口号可自定义，用于代理frpc所在内网的https服务。上面例子中是7443 frps的kcp端口。端口号可自定义，用于提升访问速度，使用的是udp协议。上面例子中是7001 iptables -A INPUT -p tcp -m multiport --dport 443,7000,7443 -j ACCEPT iptables -A INPUT -p udp --dport 7001 -j ACCEPT ","nas端配置#NAS端配置":"在本机新建文件 frpc.ini, 按下面格式配置：\n[common] # VPS服务器IP server_addr = xxx.xxx.xxx.xxx server_port = 7000 # 使用kcp加速 protocol = kcp # auth token = 12345678 # log log_file = ./frpc.log log_level = info log_max_days = 3 [nas] type = https # 内网NAS访问地址与端口 local_ip = 192.168.1.100 local_port = 443 custom_domains = nas.test.com 上传刚才创建的frpc.ini至NAS，假设在NAS上路径是 /public/frpc/frpc.ini\n在群晖或者威联通的docker容器服务中搜索oldiy/frpc，并下载镜像。创建容器的时候，需要指定一些参数：\n挂载NAS文件路径/public/frpc/frpc.ini 至容器文件路径 /frp/frpc.ini （装载路径不能修改），或者挂载NAS目录路径/public/frpc/ 至容器目录路径 /frp/ 容器网络模式选择 Host 如果有限制CPU内存等选项，可自行设定 启动容器即可。","nginx配置#Nginx配置":"确保安装的nginx支持SSL。用下面命令， 如果返回值中有http_ssl_module则说明模块已经安装。如果没有，则需要安装该模块\nnginx -V 创建 /etc/nginx/cert 文件夹，把网站https证书与私钥都上传到这个目录下。\n新建配置文件 /etc/nginx/conf.d/website.conf 。假设要以二级域名nas.test.com来访问，按照下面的格式配置\nserver { listen 443 ssl; server_name nas.test.com; # ssl证书地址 ssl_certificate /etc/nginx/cert/website.pem; # pem文件的路径 ssl_certificate_key /etc/nginx/cert/website.key; # key文件的路径 # ssl验证相关配置 ssl_session_timeout 5m; #缓存有效期 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #加密算法 ssl_protocols TLSv1.2; #安全链接可选的加密协议 ssl_prefer_server_ciphers on; #使用服务器端的首选算法 location / { proxy_pass https://127.0.0.1:7443; # 针对源点使用https+SNI，需要下面两段 proxy_ssl_server_name on; proxy_ssl_name $host; # 由于是反向代理https，下面5个需要加上，否则可能报错 proxy_set_header Proxy-Connection \"\"; proxy_set_header Host $http_host; proxy_http_version 1.1; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # proxy_ssl_verify默认是off的. 如果是on,源点的证书必须是正确的 proxy_ssl_verify off; proxy_set_header cookie $http_cookie; proxy_ssl_protocols TLSv1 TLSv1.1 TLSv1.2; } } 为了增加网站安全性，nginx配置里面需要添加一些安全相关的配置。可以自行搜索网上相关内容，这里不再多述。\n执行下面命令重新加载nginx配置\nnginx -s reload ","vps上的配置#VPS上的配置":"能够在远程访问存储NAS上面的资料，才能真正发挥NAS的作用。但是对于没有公网IP的内网用户，如何实现在公网上面访问NAS，是一个需要事先解决的问题。\n如果拥有一个有公网IP的VPS，可以通过 frp + Nginx 来实现内网穿透解决这个问题。另外，从安全角度考虑，如果有可能的话，整个链路上面的都使用 https 协议通讯更加安全。\n下面大致描绘了访问的链路图：\n浏览器通过https协议与 VPS 通讯。浏览器的请求先发到nginx上，ngnix再将请求转发的至frps。在frps前面加上nginx做反向代理的好处是，如果这个VPS上面有其他请求转发的需求（比如这个VPS部署了个人网站或者博客），那在访问所有这些服务的时候，都可以使用同一个端口（比如443）。使用默认端口的话，在访问的时候，端口号都可以不用输入 frps与部署在NAS内网的frpc通讯，frpc将请求转发至内网的NAS。 (( browser )) ---https---\u003e (( nginx --\u003e frps )) ---https---\u003e\u003e (( frpc --\u003e NAS )) VPS上的配置","测试#测试":"做完上述步骤后，在浏览器中输入 https://nas.test.com 即可访问\n参考：\nhttps://github.com/fatedier/frp https://post.smzdm.com/p/ag89vz5w/ https://post.smzdm.com/p/ag87m8xw/ https://www.cnblogs.com/faberbeta/p/nginx012.html https://www.cnblogs.com/shook/p/12790532.html https://hub.docker.com/r/oldiy/frpc ","配置frps#配置frps":"从 https://github.com/fatedier/frp/releases 上找到最新的版本并下载。解压后，修改frps.ini:\n[common] bind_port = 7000 vhost_https_port = 7443 # 使用kcp加速 kcp_bind_port = 7001 # auth authentication_method = token token = 12345678 # log log_file = /var/log/frps.log log_level = info log_max_days = 3 下面注册frps为系统服务。如果是ubuntu系统，按如下格式创建一个新的文件 /etc/systemd/system/frps.service\n[Unit] Description=frps service After=network.target syslog.target Wants=network.target [Service] Type=simple ExecStart=/root/frp/frps -c /root/frp/frps.ini [Install] WantedBy=multi-user.target 启动frps服务\nsystemctl start frps 设置为自动启动\nsystemctl enable frps "},"title":"利用frp与nginx实现公网访问NAS"},"/blog/2020/11/nginx_security/":{"data":{"":"","基础知识#基础知识":"常用配置 顶部配置\n#定义 Nginx 运行的用户和用户组 user nginx; #进程文件 pid /var/run/nginx.pid; #错误日志位置和级别，debug、info、notice、warn、error、crit error_log /var/log/nginx/error.log warn; #Nginx worker 的进程数，一般可设置为可用的CPU内核数。 worker_processes 8; #每个 worker 打开文件描述符的最大数量限制。理论值应该是最多打开文件数（系统的值ulimit -n） #与 nginx 进程数相除，但是 nginx 分配请求并不均匀，所以建议与ulimit -n的值保持一致。 worker_rlimit_nofile 65535; Events 模块\nevents { #设置一个worker进程同时打开的最大连接数 worker_connections 2048; #告诉nginx收到一个新连接通知后接受尽可能多的连接 multi_accept on; #设置用于复用客户端线程的轮询方法。如果你使用Linux 2.6+，你应该使用epoll。 # 如果你使用*BSD，你应该使用kqueue。 use epoll; } HTTP 模块\nhttp { #隐藏 Nginx 的版本号，提高安全性。 server_tokens off; #开启高效文件传输模式，sendfile 指令指定 Nginx 是否调用sendfile 函数来输出文件， #对于普通应用设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平 #衡磁盘与网络 I/O 处理速度，降低系统的负载。 sendfile on; #是否开启目录列表访问，默认关闭。 autoindex off; #告诉 Nginx 在一个数据包里发送所有头文件，而不一个接一个的发送 tcp_nopush on; #告诉 Nginx 不要缓存数据，而是一段一段的发送--当需要及时发送数据时，就应该给应用设置 #这个属性，这样发送一小块数据信息时就不能立即得到返回值。Nginx 默认会始终工作在 tcp #nopush 状态下。但是当开启前面的 sendfile on; 时，它的工作特点是 nopush 的最后一 #个包会自动转转换到 nopush off。为了减小那200ms的延迟，开启 nodelay on; 将其很快 #传送出去。结论就是 sendfile on; 开启时，tcp_nopush 和 tcp_nodelay 都是on 是可以的。 tcp_nodelay on; #日志格式设定 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #定义访问日志，设置为 off 可以关闭日志，提高性能 access_log /var/log/nginx/access.log main; #连接超时时间，单位是秒 keepalive_timeout 120; #读取HTTP头部的超时时间，默认值 60。客户端与服务器建立连接后将开始接收HTTP头部，在这个过程中， #如果在一个时间间隔（超时时间）内没有读取到客户端发来的字节，则认为超时，并向客户端返回408 #(\"Request timed out\")响应。 client_header_timeout 60; #默认值 60。与client_header_timeout相似，只是这个超时时间只在读取HTTP包体时才有效。 client_body_timeout 10; #发送响应的超时时间，默认值 60。即Nginx服务器向客户端发送了数据包，但客户端一直没有去接收这个数 #据包。如果某个连接超过send_timeout定义的超时时间，那么Nginx将会关闭这个连接。 send_timeout 60; #连接超时后将通过向客户端发送RST包来直接重置连接。这个选项打开后，Nginx会在某个连接超时后，不是 #使用正常情形下的四次握手关闭TCP连接，而是直接向用户发送RST重置包，不再等待用户的应答，直接释放 #Nginx服务器上关于这个套接字使用的所有缓存（如TCP滑动窗口）。相比正常的关闭方式，它使得服务器避 #免产生许多处于FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT状态的TCP连接。注意，使用RST重置包关闭连接 #会带来一些问题，默认情况下不会开启。 reset_timedout_connection off; #要限制连接，必须先有一个容器对连接进行计数，\"zone=\" 是给它一个名字，可以随便叫，这个名字要跟下 #面的 limit_conn 一致。$binary_remote_addr 用二进制来储存客户端的地址，1m 可以储存 32000 #个并发会话。 limit_conn_zone $binary_remote_addr zone=addr:5m; #给定的key设置最大连接数。这里key是addr，我们设置的值是100，也就是说我们允许每一个IP地址最多同 #时打开有100个连接。 limit_conn addr 100; #对每个连接限速100k。这如果一个IP允许两个并发连接，那么这个IP就是限速200K。 limit_rate 100k; #include 是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载文件扩展名与文件类型映 #射表。nginx根据映射关系，设置http请求响应头的Content-Type值。当在映射表找不到时，使用nginx.conf #中default-type指定的默认值。 include /etc/nginx/mime.types; #设置文件使用的默认的MIME-type default_type text/html; #默认编码 charset UTF-8; #该模块可以读取预先压缩的gz文件，这样可以减少每次请求进行gzip压缩的CPU资源消耗。该模块启用后， #nginx首先检查是否存在请求静态文件的gz结尾的文件，如果有则直接返回该gz文件内容。 gzip_static off; #开启 gzip 压缩。 gzip on; # 禁用客户端为 IE6 时的 gzip功能。 gzip_disable \"msie6\"; #Nginx做为反向代理的时候启用。可选值：off|expired|no-cache|no-sotre|private|no_last_modified|no_etag|auth|any gzip_proxied any; #设置允许压缩的页面最小字节数，页面字节数从header头中的Content-Length中进行获取。 #建议设置成大于1k的字节数，小于1k可能会越压越大。 gzip_min_length 1024; #设置数据的压缩等级。这个等级可以是1-9之间的任意数值，9是最慢但是压缩比最大的。 gzip_comp_level 5; #设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。 例如 4 4k 代表以4k为单位， #按照原始数据大小以4k为单位的4倍申请内存。如果没有设置，默认值是申请跟原始数据相同大小的内存空间 #去存储gzip压缩结果。 gzip_buffers 4 16k; #设置需要压缩的数据格式。Nginx默认只对text/html进行压缩。 gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; #为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive #是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=30s; #多长时间检查一次缓存的有效信息 open_file_cache_valid 30s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一 #直是在缓存中打开的。出现 Last-Modified 不变的情况，就是因为当nginx对一个静态文件缓存后，如果 #30s内还在访问它，那么它的缓存就一直存在，直到30s内你不访问了为止。 open_file_cache_min_uses 2; #是否记录cache错误 open_file_cache_errors on; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } SERVER 模块\nserver { #监听端口，nginx 会根据请求的 HOST 来决定使用哪个 SERVER 段的配置。如果没有匹配的 server_name， #则默认使用配置文件中第一个。加上 default_server 则可以以指定没有匹配时的默认规则。 #listen 80; listen 80 default_server; #域名可以有多个，用空格隔开 server_name www.test.com test.com; root /user/share/nginx/html/test; #404页面配置 error_page 404 /404.html; #配置 ssl，有需要时开启。 ssl on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; location / { index index.html index.php; } #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ { expires 1h; } location ~ [^/]\\.php(/|$) { fastcgi_index index.php; #开启 PATH_INFO 支持，作用就是把参数按照给定的正则表达式分割成 $fastcgi_script_name 和 $fastcgi_path_info。 #例如：请求 index.php/id/1 不加此行配置时，fastcgi_script_name 是 /index.php/id/1，fastcgi_path_info 是空。 #加上之后，fastcgi_script_name 是 index.php，fastcgi_path_info 是 /id/1 fastcgi_split_path_info ^(.+\\.php)(.*)$; #此值即是 PHP 中 $_SERVER['SCRIPT_FILENAME'] 的值 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; #指定FastCGI服务器监听端口与地址。须和 PHP-FPM 的设置相同。 #fastcgi_pass 127.0.0.1:9000; fastcgi_pass unix:/var/run/php5-fpm.sock; include fastcgi_params; } } ","设置#设置":"通过分区挂载允许最少特权 服务器上的网页/html/php文件单独分区。例如，新建一个分区/dev/sda5(第一逻辑分区)，并且挂载在/nginx。确保 /nginx是以noexec, nodev and nosetuid的权限挂载。比如，下面是一个/etc/fstab的挂载/nginx的信息：\nLABEL=/nginx /nginx ext3 defaults,nosuid,noexec,nodev 1 2 注意：需要使用fdisk和mkfs.ext3命令创建一个新分区。\n配置/etc/sysctl.conf强化Linux安全 可以通过编辑/etc/sysctl.conf来控制和配置Linux内核、网络设置。\n# Avoid a smurf attack net.ipv4.icmp_echo_ignore_broadcasts = 1 # Turn on protection for bad icmp error messages net.ipv4.icmp_ignore_bogus_error_responses = 1 # Turn on syncookies for SYN flood attack protection net.ipv4.tcp_syncookies = 1 # Turn on and log spoofed, source routed, and redirect packets net.ipv4.conf.all.log_martians = 1 net.ipv4.conf.default.log_martians = 1 # No source routed packets here net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 # Turn on reverse path filtering net.ipv4.conf.all.rp_filter = 1 net.ipv4.conf.default.rp_filter = 1 # Make sure no one can alter the routing tables net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.all.secure_redirects = 0 net.ipv4.conf.default.secure_redirects = 0 # Don’t act as a router net.ipv4.ip_forward = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 # Turn on execshild kernel.exec-shield = 1 kernel.randomize_va_space = 1 # Tuen IPv6 net.ipv6.conf.default.router_solicitations = 0 net.ipv6.conf.default.accept_ra_rtr_pref = 0 net.ipv6.conf.default.accept_ra_pinfo = 0 net.ipv6.conf.default.accept_ra_defrtr = 0 net.ipv6.conf.default.autoconf = 0 net.ipv6.conf.default.dad_transmits = 0 net.ipv6.conf.default.max_addresses = 1 # Optimization for port usefor LBs # Increase system file descriptor limit fs.file-max = 65535 # Allow for more PIDs (to reduce rollover problems); may break some programs 32768 kernel.pid_max = 65536 # Increase system IP port limits net.ipv4.ip_local_port_range = 2000 65000 # Increase TCP max buffer size setable using setsockopt() net.ipv4.tcp_rmem = 4096 87380 8388608 net.ipv4.tcp_wmem = 4096 87380 8388608 # Increase Linux auto tuning TCP buffer limits # min, default, and max number of bytes to use # set max to at least 4MB, or higher if you use very high BDP paths # Tcp Windows etc net.core.rmem_max = 8388608 net.core.wmem_max = 8388608 net.core.netdev_max_backlog = 5000 net.ipv4.tcp_window_scaling = 1 控制缓冲区溢出攻击 编辑nginx.conf，为所有客户端设置缓冲区的大小限制。\n##Start: Size Limits \u0026 Buffer Overflows ## //server上下文 client_body_buffer_size 1K; client_header_buffer_size 1k; client_max_body_size 1k; large_client_header_buffers 2 1k; ##END:Size Limits \u0026 Buffer Overflows ## 说明\nclient_body_buffer_size 1k-（默认8k或16k）这个指令可以指定连接请求实体的缓冲区大小。如果连接请求超过缓存区指定的值，那么这些请求实体的整体或部分将尝试写入一个临时文件。 client_header_buffer_size 1k-指令指定客户端请求头部的缓冲区大小。绝大多数情况下一个请求头不会大于1k，不过如果有来自于wap客户端的较大的cookie它可能会大于 1k，Nginx将分配给它一个更大的缓冲区，这个值可以在large_client_header_buffers里面设置。 client_max_body_size 1k-指令指定允许客户端连接的最大请求实体大小，它出现在请求头部的Content-Length字段。 如果请求大于指定的值，客户端将收到一个”Request Entity Too Large” (413)错误。记住，浏览器并不知道怎样显示这个错误。 large_client_header_buffers-指定客户端一些比较大的请求头使用的缓冲区数量和大小。请求字段不能大于一个缓冲区大小，如果客户端发送一个比较大的头，nginx将返回”Request URI too large” (414) 同样，请求的头部最长字段不能大于一个缓冲区，否则服务器将返回”Bad request” (400)。缓冲区只在需求时分开。默认一个缓冲区大小为操作系统中分页文件大小，通常是4k或8k，如果一个连接请求最终将状态转换为keep- alive，它所占用的缓冲区将被释放。 还需要控制超时来提高服务器性能并与客户端断开连接。按照如下编辑：\n## Start: Timeouts ## client_body_timeout 10; client_header_timeout 10; keepalive_timeout 5 5; send_timeout 10; ## End: Timeouts ## 说明\nclient_body_timeout 10;-指令指定读取请求实体的超时时间。这里的超时是指一个请求实体没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个”Request time out” (408)错误。 client_header_timeout 10;-指令指定读取客户端请求头标题的超时时间。这里的超时是指一个请求头没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个”Request time out” (408)错误。 keepalive_timeout 5 5; – 参数的第一个值指定了客户端与服务器长连接的超时时间，超过这个时间，服务器将关闭连接。参数的第二个值（可选）指定了应答头中Keep-Alive: timeout=time的time值，这个值可以使一些浏览器知道什么时候关闭连接，以便服务器不用重复关闭，如果不指定这个参数，nginx不会在应 答头中发送Keep-Alive信息。（但这并不是指怎样将一个连接“Keep-Alive”）参数的这两个值可以不相同。 send_timeout 10; 指令指定了发送给客户端应答后的超时时间，Timeout是指没有进入完整established状态，只完成了两次握手，如果超过这个时间客户端没有任何响应，nginx将关闭连接 控制并发连接 可以使用NginxHttpLimitZone模块来限制指定的会话或者一个IP地址的特殊情况下的并发连接。\n编辑nginx.conf, 每个远程IP地址的客户端同时打开连接不能超过5个:\n### Directive describes the zone,in which the session states are stored i.e. stored in slimits. ### ### 1m can handle 32000 sessions with 32 bytes/session,set to 5m x 32000 session### limit_conn_zone $binary_remote_addr zone=slimits:5m; ### Control maximum number of simultaneous connections for one session i.e.### ### restricts the amount of connections from a single ip address ### limit_conn slimits 5; 只允许域名的访问 可以逃过ip扫描\n## Only requests to our Host are allowed i.e. xxx.in,images.xxx.in and www.xxx.in if($host !~ ^(xxx.in|www.xxx.in|images.xxx.in)$) { # 444 = Connection closed without response retrun 444; } 或者\nif ( $host !~* 'abc.com' ) { return 403; } url 参数过滤敏感字 if ($query_string ~* \"union.*select.*\\(\") { rewrite ^/(.*)$ $host permanent; } if ($query_string ~* \"concat.*\\(\") { rewrite ^/(.*)$ $host permanent; } 限制可用的请求方法 下面的指令将过滤只允许GET,HEAD和POST方法：\n##Only allow these request methods## if($request_method !~ ^(GET|HEAD|POST)$) { retrun 444; } 拒绝一些User-Agents ##Block download agents ## if ($http_user_agent ~* LWP::Simple|BBBike|wget){ retrun 403; } ##Block some robots ## # 阻止Soso和有道的机器人： if ($http_user_agent ~* Sosospider|Yodaobot){ retrun 403; } 为了更好的维护，最好创建一个文件，包含不期望的user agent列表。例如/etc/nginx/blockuseragents.rules包含如下内容：\nmap $http_user_agent $blockedagent { default 0; ~*malicious 1; ~*bot 1; ~*backdoor 1; ~*crawler 1; ~*bandit 1; } 然后将如下语句放入配置文件的server模块内,并加入if语句设置阻止后进入的页面：\ninclude /etc/nginx/blockuseragents.rules; server { if ($blockedagent) { return 403; } listen 192.168.0.12:8080; ... } 目录限制IP访问 可以对指定的目录设置访问权限。所有的网站目录应该一一配置，只允许必须的目录访问权限。\n可以通过IP地址来限制访问目录/admin/:\nlocation /docs/ { ##block one workstation deny 192.168.1.1; ## allow anyone in 192.168.1.0/24 allow 192.168.1.0/24; ##drop rest of the world deny all; } 更多的时候客户端请求会经过层层代理，我们需要通过$http_x_forwarded_for来进行限制，可以这样写：\nset $allow false; if ($http_x_forwarded_for = \"211.144.204.2\") { set $allow true; } if ($http_x_forwarded_for ~ \"108.2.66.[89]\") { set $allow true; } if ($allow = false) { return 404; } 通过密码保护目录 首先创建密码文件并增加“user”用户：\nmkdir /usr/local/nginx/conf/.htpasswd/ htpasswd -c /usr/local/nginx/conf/.htpasswd/passwd user 编辑nginx.conf,加入需要保护的目录：\n###Password Protect /personal-images/ and /delta/ directories### location ~ /(personal-images/./delta/.) { auth_basic \"Restricted\"; auth_basic_user_file /usr/local/nginx/conf/.htpasswd/passwd; } 密码文件生成后，也可以用以下的命令来增加允许访问的用户：\nhtpasswd -s /usr/local/nginx/conf/.htpasswd/passwd userName 如何防止图片盗链 如果有人直接用你网站的图片地址来显示在他的网站上，会造成你需要支付额外的宽带费用。\n# Stop deep linking or hot linking location /images/ { valid_referers none blocked www.example.com example.com; if ($invalid_referer) { return 403; } } 重定向并显示指定图片\nlocation /images/ { valid_referers blocked www.example.com example.com; if ($invalid_referer) { rewrite ^/images/uploads.*.(gif|jpg|jpeg|png)$ http://www.examples.com/banned.jpg last } } Nginx SSL配置 编辑nginx.conf并更新：\nserver{ server_name example.com; listen 443; ssl on; ssl_certificate /user/local/nginx/conf/server.crt; ssl_certificate_key /usr/local/nginx/conf/server.key; access_log /usr/local/nginx/logs/ssl.access.log; error_log /usr/local/nginx/logs/ssl.error.log; } 在防火墙级限制每个IP的连接数 网络服务器必须监视连接和每秒连接限制。PF和Iptales都能够在进入你的nginx服务器之前阻止最终用户的访问。 Linux Iptables:限制每次Nginx连接数\n下面的例子会阻止来自一个IP的60秒钟内超过15个连接端口80的连接数。\n/sbin/iptables -A INPUT -p tcp –dport 80 -i eth0 -m state –state NEW -m recent –set /sbin/iptables -A INPUT -p tcp –dport 80 -i eth0 -m state –state NEW -m recent –update –seconds 60 –hitcount 15 -j DROP service iptables save 请根据具体情况来设置限制的连接数。\n配置操作系统保护Web服务器 Nginx以用户nginx运行。但是根目录（/nginx或者/usr /local/nginx/html）不应该设置属于用户nginx或对用户nginx可写。\n找出错误权限的文件可以使用如下命令：\nfind /nginx -user nginx find /usr/local/nginx/html -user nginx 确保你更所有权为root或其它用户，一个典型的权限设置 /usr/local/nginx/html/\nls -l /usr/local/nginx/html/ 示例输出：\n-rw-r–r– 1 root root 925 Jan 3 00:50 error4xx.html -rw-r–r– 1 root root 52 Jan 3 10:00 error5xx.html -rw-r–r– 1 root root 134 Jan 3 00:52 index.html 你必须删除由vi或其它文本编辑器创建的备份文件：\nfind /nginx -name ‘.?’ -not -name .ht -or -name ‘~’ -or -name ‘.bak’ -or -name ‘.old*’ find /usr/local/nginx/html/ -name ‘.?’ -not -name .ht -or -name ‘~’ -or -name ‘.bak’ -or -name ‘.old*’ 通过find命令的-delete选项来删除这些文件。\n限制Nginx连接传出 黑客会使用工具如wget下载你服务器本地的文件。使用Iptables从nginx用户来阻止传出连接。ipt_owner模块试图匹配本地产生的数据包的创建者。下面的例子中只允许user用户在外面使用80连接。\n/sbin/iptables -A OUTPUT -o eth0 -m owner –uid-owner vivek -p tcp –dport 80 -m state –state NEW,ESTABLISHED -j ACCEPT 根据用户的真实 IP 做连接限制 ## 这里取得原始用户的IP地址 map $http_x_forwarded_for $clientRealIp { \"\" $remote_addr; ~^(?P\u003cfirstAddr\u003e[0-9\\.]+),?.*$ $firstAddr; } ## 针对原始用户 IP 地址做限制 limit_conn_zone $clientRealIp zone=TotalConnLimitZone:20m ; limit_conn TotalConnLimitZone 50; limit_conn_log_level notice; ## 针对原始用户 IP 地址做限制 limit_req_zone $clientRealIp zone=ConnLimitZone:20m rate=10r/s; #limit_req zone=ConnLimitZone burst=10 nodelay; limit_req_log_level notice; ## 具体服务器配置 server { listen 80; location ~ \\.php$ { ## 最多 5 个排队， 由于每秒处理 10 个请求 + 5个排队，你一秒最多发送 15 个请求过来，再多就直接返回 503 错误给你了 limit_req zone=ConnLimitZone burst=5 nodelay; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi_params; } } 经过多层CDN之后取得原始用户的IP地址 通过 map 指令，我们为 nginx 创建了一个变量 $clientRealIp ，这个就是 原始用户的真实 IP 地址，不论用户是直接访问，还是通过一串 CDN 之后的访问，我们都能取得正确的原始IP地址\nmap $http_x_forwarded_for $clientRealIp { ## 没有通过代理，直接用 remote_addr \"\" $remote_addr; ## 用正则匹配，从 x_forwarded_for 中取得用户的原始IP ## 例如 X-Forwarded-For: 202.123.123.11, 208.22.22.234, 192.168.2.100,... ## 这里第一个 202.123.123.11 是用户的真实 IP，后面其它都是经过的 CDN 服务器 ~^(?P\u003cfirstAddr\u003e[0-9\\.]+),?.*$ $firstAddr; } 隐藏版本信息 server_tokens off; proxy_hide_header X-Powered-By; 禁用扩展名 location ~* .(txt|doc|sql|gz|svn|git)$ { deny all; } 重定向HTTP请求到HTTPS server { ... return 301 https://$server_name$request_uri; ... } 防止XSS攻击 add_header X-Frame-Options \"SAMEORIGIN\"; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Content-Type-Options \"nosniff\"; X-Frame-Options： 响应头表示是否允许浏览器加载frame等属性，有三个配置DENY禁止任何网页被嵌入,SAMEORIGIN`只允许本网站的嵌套,ALLOW-FROM允许指定地址的嵌套 X-XSS-Protection： 表示启用XSS过滤（禁用过滤为X-XSS-Protection: 0），mode=block表示若检查到XSS攻击则停止渲染页面 X-Content-Type-Options： 响应头用来指定浏览器对未指定或错误指定Content-Type资源真正类型的猜测行为，nosniff 表示不允许任何猜测 在通常的请求响应中，浏览器会根据Content-Type来分辨响应的类型，但当响应类型未指定或错误指定时，浏览会尝试启用MIME-sniffing来猜测资源的响应类型，这是非常危险的\n例如一个.jpg的图片文件被恶意嵌入了可执行的js代码，在开启资源类型猜测的情况下，浏览器将执行嵌入的js代码，可能会有意想不到的后果\n目录只读 如果没有上传需求，完全可以把网站根目录弄成只读的，加固安全。\n做了一点小动作，给网站根目录搞了一个只读的挂载点。这里假设网站根目录为/var/www/html\nmkdir -p /data mkdir -p /var/www/html mount --bind /data /var/www/html mount -o remount,ro --bind /data /var/www/html 网站内容实际位于/data，网站内容更新就往/data里更新，目录/var/www/html无法执行任何写操作，否则会报错“Read-only file system”，极大程度上可以防止提权篡改。\n参考链接：\nhttps://www.cnblogs.com/RiwellAckerman/p/11273705.html https://www.hack520.com/456.html https://www.cnblogs.com/chenpingzhao/p/5785416.html https://blog.csdn.net/qidakui_123/article/details/106036299 https://blog.51cto.com/hobowizard/1895269 "},"title":"Nginx服务器安全加固"},"/blog/2020/11/ubuntu_install_postgresql/":{"data":{"":" 使用lsof lsof -i lsof -i:80 使用netstat netstat -anp | grep 80 "},"title":"Linux查看某个端口是否被占用"},"/blog/2020/12/k8s_api_server_security/":{"data":{"":"如果攻击者获得了访问API服务器的权限, 他们可以通过在容器镜像中打包自己的代码并在pod中运行来做任何事","认证机制#认证机制":"API 服务器可以配置一个认证插件列表。列表中的每个插件都可以检查这个请求和尝试确定谁在发送这个请求。当通过认证后，返回用户名、用户 ID 和组信息给 API 服务器，API服务器就会停止调用剩余的认证插件井继续进入授权阶段。\n用户与组 k8s 区分了两种连接到 API 服务器的客户端 :\n用户（真实的人） pod (更准确地说是运行在 pod 中的应用) 用户应该被管理在外部系统中，例如单点登录系统。没有资源代表用户账户，这也就意味着不能通过 API 服务器来创建、更新或删除用户。\npod 使用一种称为 service accounts 的机制, 该机制被创建和存储在集群中作为 ServiceAccount 资源。\n正常用户和 ServiceAccount 都可以属于一个或多个组。可以通过组对一批用户进行授权。\n由插件返回的组仅仅是表示组名称的字符串,但是系统内置的组会有一些特殊的含义。\nsystem:unauthenticated 组用于所有认证插件都不会认证客户端身份的请求。 system:authenticated 组会自动分配给一个成功通过认证的用户。 system:serviceaccounts 组包含所有在系统中的 ServiceAccount 。 system:serviceaccounts:组包含了所有在特定命名空间中的ServiceAccount。 ServiceAccount ServiceAccount介绍 ServiceAccount就像Pod、 Secret、 ConfigMap等一样都是资源, 它们作用在单独的命名空间, 为每个命名空间自动创建一个默认的ServiceAccount\n可以像其他资源那样查看ServiceAccount列表：\nkubectl get sa 在 pod 的 manifest 文件中, 可以用指定账户名称的方式将一个 ServiceAccount赋值给一个 pod。如果不显式地指定 ServiceAccount 的账户名称, pod 会使用在这个命名空间中的默认 ServiceAccount。\n可以通过将不同的 ServiceAccount 赋值给 pod 来控制每个 pod 可以访问的资源。当 API 服务器接收到一个带有认证 token 的请求时, 服务器会用这个 token 来验证发送请求的客户端所关联的 ServiceAccount 是否允许执行请求的操作。\n为了集群的安全性，根据需要，对不同的Pod赋予不一样的ServiceAccount。\n创建serviceaccount 创建serviceaccount\nkubectl create serviceaccount foo 查看serviceaccount\n$ kubectl describe sa foo Namespace: default Labels: \u003cnone\u003e Image pull secrets: \u003cnone\u003e Mountable secrets: foo-token-qzq7j Tokens: foo-token-qzq7j 查看密钥里面的数据\n$ kubectl describe secret foo-token-qzq7j ... ca.crt: 1066 bytes namespace: 7 bytes token: eyJhbGdOiJSUzI1NiisinRScCI6IkpXVCJ9... 在默认情况下,pod 可以挂载任何它需要的密钥。但是可以通过对 ServiceAccount 进行配置,让 pod 只允许挂载ServiceAccount 中列出的可挂载密钥。为了开启这个功能,ServiceAccount 必须包含以下注解: kubernetes.io/enforce-mountable-secrets=“true”。如果 ServiceAccount 被加上了这个注解,任何使用这个ServiceAccount的pod只能挂载进 ServiceAccount 的可挂载密钥，而不能使用其他的密钥。\nServiceAccount 也可以包含镜像拉取密钥的 list:\napiVersion: vl kind: ServiceAccount metadata: name: my-service-account imagePullSecrets: - name: my-dockerhub-secret ServiceAccount和可挂载密钥不同的是,ServiceAccount 中的镜像拉取密钥不是用来确定以个 pod 可以使用哪些镜像拉取密钥的。添加到 ServiceAccount 中的镜像拉取密钥会自动添加到所有使用这个 ServiceAccount 的 pod 中。\n分配ServiceAccount给Pod ServiceAccount需要将它们赋值给 pod。通过在 pod 定义文件中的 spec.serviceAccountName 字段上设置 ServiceAccount 的名称来进行分配。\n注意: pod 的 ServiceAccount 必须在 pod 创建时进行设置，后续不能被修改。","通过基于角色的权限控制加强集群安全#通过基于角色的权限控制加强集群安全":"在Kubernetes1.8.0版本中,RBAC授权插件升级为GA(通用可用性),并且在很多集群上默认开启。RBAC会阻止未授权的用户查看和修改集群状态。\n注意：除了RBAC插件, k8s也包含其他的授权插件,比如基于属性的访问控制插件 (ABAC)、WebHook插件和自定义插件实现。但是,RBAC插件是标准的。\nRBAC授权插件 动作 RBAC授权插件会决定一个客户端是否允许在请求的资源上执行请求的动词。下面是认证动词和HTTP方法之间的映射关系：\nHTTP方法 单一资源的动词 集合的动词 GET、HEAD get (以及watch用于监听) list以及watch POST create n/a PUT update n/a PATCH patch n/a DELETE delete deletecollection 注意: 额外的动词 use 用于 PodSecurityPolicy 资源\n除了可以对全部资源类型应用安全权限, RBAC 规则还可以应用于特定的资源实例(例如, 一个名为 myservice 的服务), 也可以应用于non-resource (非资源) URL路径, 因为并不是 API 服务器对外暴露的每个路径都映射到一个资源(例如 /api 路径本身或服务器健康信息在的路径 /health)。\n角色与授权规则 RBAC 授权插件将用户角色作为决定用户能否执行操作的关键因素。主体可以是一个人、一个 ServiceAccount, 或者一组用户或 ServiceAccount和一个或多个角色相关联, 每个角色被允许在特定的资源上执行特定的动词。如果一个用户有多个角色, 他们可以做任何他们的角色允许他们做的事情。\nRBAC 授权规则是通过四种资源来进行配置的, 它们可以分为两个组：\nRole(角色)和 ClusterRole (集群角色), 它们指定了在资源上可以执行哪些动词。 RoleBinding (角色绑定) 和 ClusterRoleBinding (集群角色绑定), 它们将上述角色绑定到特定的用户、组或 ServiceAccounts 上。 角色和角色绑定是命名空间的资源, 而集群角色和集群角色绑定是集群级别的资源。\n使用Role和RoleBinding apiVersion: rbac.authorization.k8s.io/v1 kind: Role namespace: foo # Role所在命名空间，没有填写则使用当前命名空间 metadata: server-reader rules: - apiGroups: [\"\"] # Service是核心apiGroup的资源,所以没有apiGroup名,就是\"\" verbs: [\"get\", \"list\"] #获取独立的service（通过名字）并且列出所有允许的服务 resources: [\"services\"] #这条规则与服务有关（必须使用复数的名字） 注意：在指定资源时必须使用复数的形式。\n绑定角色到service account\nkubectl create rolebinding te st --role=service-reader --serviceaccount=foo:default -n foo 注意: 如果要绑定一个角色到一个 user (用户)而不是 ServiceAccount 上, 使用 --user 作为参数来指定用户名。如果要绑定角色到组,可以使用 --group 参数 。\n使用 ClusterRole 和 ClusterRoleBinding 一个 RoleBinding 不能授予集群级别的资源访问权限,即使它引用了一个 ClusterRoleBinding。\n在授予集群级别的资源访问权限时,必须使用一个 ClusterRole和一个 ClusterRoleBinding。\nClusterRole不是必须一直和集群级别的ClusterRoleBinding捆绑使用。它们也可以和常规的有命名空间的RoleBinding进行捆绑\n何时使用具体的role和binding的组合：\n访问的资源 使用的角色类型 使用的绑定类型 集群级别的资源(Nodes、 Pers1stentVolumes、…) ClusterRole ClusterRoleBinding 非资源型URL(/api、/healthz、…) ClusterRole ClusterRoleBinding 在任何命名空间中的资源(和跨所有命名空间的资源) ClusterRole ClusterRoleBinding 在具体命名空间中的资源(在多个命名空间中重用这个相同的ClusterRole) ClusterRole RoleBinding 在具体命名空间中的资源(Role必须在每个命名空间中定义好) Role RoleBinding 默认的 ClusterRole 和 ClusterRoleBinding k8s 提供了一 组默认的ClusterRole和ClusterRoleBinding, 每次API服务器启动时都会更新它们。 这保证了在你错误地删除角色和绑定, 或者Kubernetes的新版本使用了不同的集群角色和绑定配置时, 所有的默认角色和绑定都会被重新创建。\n可以执行下面的命令查看：\nkubectl get clusterrolebindings kubectl get clusterroles view、edit、admin和 cluster-admin 这些ClusterRole是最重要的角色, 它们应该绑定到用户定义pod中的ServiceAccount上\n默认的ClusterRole列表包含了大量其他的ClusterRole, 它们以system:为前缀。这些角色用于各种k8s组件中\n理性地授予授权权限 在默认情况下, 命名空间中的默认ServiceAccount除了包含未经身份验证的用户之外，没有其他任何权限。因此,在默认情况下, pod甚至不能查看集群状态。\n目标是减少入侵者获得集群控制的可能性。\n一个好的想法是，为每一个pod(或一组pod的副本)创建一个特定ServiceAccount, 并且把它和一个定制的Role (或ClusterRole)通过RoleBinding联系起来(不是ClusterRoleBinding, 因为这样做会给其他命名空间的pod对资源的访 问权限,这可能不是想要的)。\n图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (14) API Server服务器的安全防护"},"/blog/2020/12/k8s_cluster_structure/":{"data":{"":"","使用kubernetes的好处#使用Kubernetes的好处":"简化应用程序部署 由于k8s将其所有工作节点公开为一个部署平台, 因此应用程序开发人员可以直接部署应用程序,不需要了解组成集群的服务器。\n开发人员通常不关心应用程序运行在哪个服务器上,只要服务器能够为应用程序提供足够的系统资源即可。\n有时开发人员需要指定应用程序应该运行在哪种硬件上，比如SSD，那只需要告诉k8s只在具有 SSD 的节点中进行选择即可。\n更好地利用硬件 将应用程序与基础设施分离开来， k8s根据资源需求描述和每个节点上的可用资源选择最合适的节点\n通过使用容器,不再用把这个应用绑定到一个特定的集群节点,而允许应用程序在任何时候都在集群中自由迁移。让节点的硬件资源得到尽可能好的利用。\n健康检查和自修复 k8s 监控应用程序组件和它们运行的节点,并在节点出现故障时自动将它们重新调度到其他节点。这使运维团队不必手动迁移应用程序组件,并允许团队立即专注于修复节点本身, 并将其修好送回到可用的硬件资源池中, 而不是将重点放在重新定位应用程序上。\n自动扩容 可以让k8s监视每个应用程序使用的资源, 自动调整每个应用程序的运行实例数量。这意味着运维团队不需要不断地监控单个应用程序的负载\n图书资料：\nhttps://book.douban.com/subject/30418855/ 参考：\nhttps://www.cnblogs.com/ants/p/11489598.html ","集群架构#集群架构":"k8s集群由很多节点组成，被分成两种类型：Master节点与Node节点。\nMaster节点 承载着控制和管理整个集群系统的 Control Panel。包含下面组件：\nAPI Server 一个api服务器，所有外部与k8s集群的交互都需要经过它 可水平扩展 Scheduler 将pod调度到具体的Node节点上 一个master集群中只会有一个节点处于激活状态，由etcd选举产生 Control Manager 执行集群级别的功能，通过apiserver监控集群状态做出相应的处理，如复制组件、持续跟踪工作节点 、处理节点失败等 一个master集群中只会有一个节点处于激活状态，由etcd选举产生 etcd 一个可靠的分布式数据存储,它能持久化存储集群配置。使用RAFT算法 k8s依赖etcd所以不存在数据一致性的问题（把数据一致性压到了etcd上），所以k8s master不需要采取投票的机制来进行选举，而只需节点健康就可以成为leader。所以这边master并不要求奇数，偶数也是可以的。那么master高可用至少需要2个节点，失败容忍度是(n/0)+1，也就是只要有一个是健康的k8s master集群就属于可用状态。（这边需要注意的是master依赖etcd，如果etcd不可用那么master也将不可用）\netcd的失败容忍度：最小可用节点数：(n/2)+1。通常是奇数节点，防止脑裂\nNode 节点 无高可用一说。\n主要的几个组件：\nContainer Runtime 每个节点都需要一个容器运行时来执行容器，比如Docker。非pod启动。 kubelet 用于执行API server下达的命令，也可以重启启动失败的pod。 kube-proxy (Kubernetes Service Proxy) 通过修改iptables来达到网络代理、负载均衡的效果 组件之间的通讯 系统组件间只能通过API服务器通信，它们之间不会直接通信。\n唯一能直接和etcd通信的是 k8s 的API服务器。所有其他组件通过API服务器间接地读取、写入数据到etcd。这带来一些好处，其中之一就是增强乐观锁系统、验证系统的健壮性;并且,通过把实际存储机制从其他组件抽离,未来替换起来也更容易"},"title":"Kubernetes in Action笔记 - (2) k8s集群架构"},"/blog/2020/12/k8s_config_map_secret/":{"data":{"":"","使用-secret-给容器传递敏感数据#使用 Secret 给容器传递敏感数据":"Secret介绍 配置通常会包含一些敏感数据, 如证书和私钥, 需要确保其安全性。\nSecret 结构与 ConfigMap 类似, 均是键/值对的映射，使用方法也相同。Secret 只会存储在节点的内存中, 永不写入物理存储, 这样从节点上删除 Secret 时就不需要擦除磁盘了。\n从k8s 1.7开始， etcd 会以加密形式存储 Secret, 某种程度提高了系统的安全性。\n如何选择 ConfigMap与Secret\n采用 ConfigMap 存储非敏感的文本配置数据 采用 Secret 存储天生敏感的数据, 通过键来引用。如果一个配置文件同时包含敏感与非敏感数据, 该文件应该被存储在 Secret 中 默认secret卷 每个pod都会被自动挂载上一个默认的secret卷，这个Secret包含三个条目：ca.crt、namespace与token, 包含了从pod内部安全访问KubernetesAPI服务器所需的全部信息。尽管希望做到应用程序对k8s的完全无感知,然而在除了直连k8s别无他法的情况下,将会使用到secret卷提供的文件。\n挂载secret卷\nvolumes: - name: certs secret: secretName: fortune-https 暴露成环境变量\nenv: - name: FOO_SECRET valueFrom: secretKeyRef: name: fortune-https key: foo 使用secret从私有仓库拉取镜像 先创建用于私有镜像仓库鉴权的secret\nkubectl create secret docker-registry mydockerhubsecret \\ --docker-username=myusername --docker-password=mypassword \\ --docker-email=my.email@provider.com 然后在pod定义中使用该secret\napiVersion: vl kind : Pod metadata: name: private-pod spec: imagePullSecrets: - name: mydockerhubsecret containers: - image : username/private:tag name : main 图书资料：\nhttps://book.douban.com/subject/30418855/ ","利用-configmap-解耦配置#利用 ConfigMap 解耦配置":"应用配置的关键在于能够在多个环境中区分配置边项,将配置从应用程序源码中分离,可频繁变更配置值。如果将 pod 定义描述看作是应用程序源代码,显然需要将配置移出 pod 定义\n什么是ConfigMap k8s允许将配置选项分离到单独的资源对象 ConfigMap 中, 它本质上就是一个键值对,值可以是短字面量,也可以是完整的配置文件。\n应用无须直接读取 ConfigMap, 甚至根本不需要知道其是否存在。映射的内容并非直接传递给容器，可以通过下面的形式传递给容器：\n环境变量 卷文件 通过k8s API直接按需读取ConfigMap条目。不推荐这么做，因为要保持应用对k8s无感知。 命令行参数的定义中可以通过 $ (ENV VAR )语法引用环境变量,因而可以达到将 ConfigMap 的条目当作命令行参数传递给进程的效果。\npod是通过名称引用 ConfigMap 的,因此可以在多环境下使用相同的 pod 定义描述,同时保持不同的配置值以适应不同环境。\n注意：\nConfigMap 中的 键名必须是一个合法的 DNS 子域,仅包含数字字母、破折号、下画线以及圆点。首位的圆点符号是可选的 。 ConfigMap通常被用作存储非敏感数据 创建ConfigMap 通过字面量创建条目\n# 单条目 kubectl create configmap fortune-config --from-literal=sleep-interval=25 # 包含多条目 kubectl create conf igmap myconfigmap --from-literal=foo=bar --from-literal=bar=baz --from-literal=one=two 从文件内容创建 ConfigMap 条目\n# 在当前目录下查找 config-file.conf 文件, 并将文件内容存储在 ConfigMap 中以 config-file.conf 为键名的条目下 kubectl create configmap my-config --from-file=config-file.conf # 手动指定键名 kubectl create configmap my-config -from-file=customkey=config file.conf 从文件夹创建 ConfigMap\n# 为文件夹中的每个文件单独创建条目,仅限于那些文件名可作为合法 ConfigMap 键名的文件 kubectl create configmap my -config --from-file=/path/to/dir 通过上述多种方式创建\nkubectl create configmap my-config --from-file=foo.json --from-file=foobar.conf --from-literal=some=thing 通过ConfigMap向容器传递参数 （1）以环境变量的方式 仅传递特定的条目\nenv: - name: INTERVAL valueFrom: configMapKeyRef: name: fortune-config key: sleep-interval 默认情况下，引用不存在的 ConfigMap , 那容器会启动失败。可以标记对 ConfigMap 的引用是可选的(设置configMapKeyRef.optional: true )。这样,即使 ConfigMap 不存在,容器也能正常启动。\n一次性传递 ConfigMap 的所有条目作为环境变量\nspec: containers: - image: some-image envFrom: - prefix: CONFIG_ # 所有环境变量包含前缀CONFIG_ configMapRef: name: my-config-map 前缀设置是可选的,若不设直前缀佳,环境变量的名称与 ConfigMap 中的键名相同.\n（2）以命令行参数的方式 在宇段 pod.spec.containers.args 中无法直接引用 ConfigMap 的条目,但是可以利用 ConfigMap 条目初始化某个环境变 量 ,然后再在参数字段中引用该环境变量\napiVersion: vl kind: Pod metadata: name: fortune-args-from-configmap spec: containers: - image: luksa/fortune:args env: - name: INTERVAL valueFrom: configMapKeyRef: name: fortune-config key : sleep-interval args : [\"$(INTERVAL)\"] (3) 将条目暴露为文件 环境变量或者命令行参数值作为配置值通常适用于变量值较短的场景。由于 ConfigMap 中可以包含完整的配置文件内容, 可以通过 configMap 卷将onfigMap 中的每个条目均暴露成一个文件。\napiVersion: v1 kind: Pod metadata: name: fortune-configmap-volume spec: containers: - image: nginx:alpine name: web-server volumeMounts: ... # 挂载configMap - name: config mouthPath: /etc/nginx/conf.d readOnly: true ... volumes: ... # 定义卷来应用configMap - name: config configMap: name: fortune-config 卷可以仅暴露指定的ConfigMap条目\nvolumes: - name: config configMap: name: fortune-config items: # 选择暴露的条目 - key: my-nginx-config.conf # 该键对应的条目被包含 path: gzip.conf # 条目的值被存储在该文件中 为configMap卷中的文件设置权限\nvolumes: - name: config configMap: name: fortune-config defaultMode: \"6600\" #指定权限 注意：\n挂载某一文件夹会隐藏该文件夹中已存在的文件 ConfigMap独立条目作为文件被挂载且不隐藏文件夹中的其他文件 使用环境变量或者命令行参数作为配置源的弊端在于无法在进程运行时更新配置。将ConfigMap暴露为卷可以达到配置热更新的效果, 无须重新创建pod或者重启容器。ConfigMap被更新之后, 卷中引用它的所有文件也会相应更新, 进程发现文件被改变之后进行重载。但是，这仅仅是容器里面的文件发生的变化，如果应用程序本身需要重启才能加载这些文件，那还是要重启的。比如nginx.conf文件，虽然配置文件已经发生了变化，还是需要手动执行 nginx -s reload才正式生效。","向容器传递应用程序的配置参数#向容器传递应用程序的配置参数":"方法：\n向容器传递命令行参数 为每个容器设置自定义环境变量 通过特殊类型的卷将配置文件挂载到容器中 向容器传递命令行参数 在Docker中定义命令与参数 容器中运行的完整指令由两部分组成:命令与参数。Dockerfile中的两种指令分别定义命令与参数这两个部分：\nENTRYPOINT: 定义容器启动时被调用的可执行程序 CMD: 指定传递给ENTRYPOINT的参数。 尽管可以直接使用CMD指令指定镜像运行时想要执行的命令, 正确的做法依旧 是借助ENTRYPOINT指令, 仅仅用CMD指定所需的默认参数。 这样, 镜像可以直 接运行, 无须添加任何参数\ndocker run \u003cimage\u003e 或者是添加一些参数, 覆盖Dockerile中任何由CMD指定的默认参数值:\ndocker run \u003cimage\u003e \u003carguments\u003e shell与exec的区别 上述两条指令均支持以下两种形式。两者的区别在于指定的命令是否是在shell中被调用。\nshell形式。如ENTRYPOINT node app.js。 exec形式。如ENTRYPOINT [“node”, “app.js”]。 下面用例子来看他们的区别\n# exec形式 # 从返回的进程列表看出:这里是直接运行node进程,而并非在shell中执行。 $ docker exec 4675d ps x PID TTY STAT TIME COMMAND 1 ? Ssl 0:00 node app.Js 12 ? Rs 0:00 ps x # shell形式 # 可以看出,主进程(PID 1)是shell进程而非node进程,node进程(PID 7)于shell中启动。 $ docker exec -it e4bad ps x PID TTY STAT TIME COMMAND 1 ? Ss 0:00 /bin/sh -c node app. J s 7 ? Sl 0:00 node app.js 13 ? Rs+ 0:00 ps x shell进程往往是多余的, 因此通常可以直接采用exec形式的ENTRYPOINT指令。\n可配置化镜像中的间隔参数 编辑fortuneloop.sh脚本\n#!/bin/bash trap \"exit\" SIGINT INTERVAL=$1 echo Configured to generate new fortune every $INTERVAL seconds mkdir -p /var/htdocs while do echo $(date) Writing fortune to /var/htdocs/index.html /usr/games/fortune \u003e /var/htdocs/index.html sleep $INTERVAL done 编写docker file，采用exec形式的ENTRYPOINT命令，并设定默认参数\nFROM ubuntu:latest RUN apt-get update; apt-get -y install fortune ADD fortuneloop.sh /bin/fortuneloop.sh ENTRYPOINT [\"/bin/fortuneloop.sh\"] CMD [\"10\"] # 默认参数 启动docker时，另外指定参数值15覆盖默认的值\ndocker run -it docker.io/luksa/fortune:latest 15 在 Kubernetes 中覆盖命令和参数 在 k8s 中定义容器时, 镜像的 ENTRYPOINT 和 CMD 均可以被覆盖, 仅需在容器定义中设置属性 command 和 args 的值.\nkind: Pod spec: containers: - image: some/image command: [\"/bin/command\" l args: [\"argl\", \"arg2\", \"arg3\"] 绝大多数情况下, 只需要设置自定义参数。命令一般很少被覆盖, 除非针对一些未定义 ENTRYPOINT 的通用镜像\n为容器设置环境变量 注意：\n环境变量被设置在pod的容器定义中,并非是pod级别 在每个容器中,k8s会自动暴露相同命名空间下每个service对应的环境变量。这些环境变量基本上可以被看作自动注入的配置。 kind: Pod spec: containers: - image: luksa/fortune:env #添加环境变量 env: - name: INTERVAL value: \"30\" name: html-generator 可以采用$(VAR)语法在环境变量值中引用其他的环境变量\nenv: - name: FIRST_VAR value: \"foo\" - name: SECOND_VAR value: \"$(FIRST_VAR)bar\" 缺点：硬编码环境变量，就意味着Pod定义必须可以有效区分生产环境与开发环境，否则会带来一些麻烦。"},"title":"Kubernetes in Action笔记 - (10) 使用ConfigMap与Secret传递应用配置"},"/blog/2020/12/k8s_container_tech_intro/":{"data":{"":"容器允许你在同一台机器上运行多个服务, 不仅提供不同的环境给每个服务, 而且将它们互相隔离。","容器与虚拟机比较#容器与虚拟机比较":"轻量级 和虚拟机比较, 容器更加轻量级, 它允许在相同的硬件上运行更多数量的组件。主要是因为每个虚拟机需要运行自己的一组系统进程, 这就产生了除组件进程消耗以外的额外计算资源损耗。而一个容器仅仅是运行在宿主机上被隔离的单个进程, 仅消耗应用容器消耗的资源, 不会有其他进程的开销。\n虚拟化 多个容器则会完全执行运行在宿主机上的同一个内核的系统调用, 此内核是唯一一个在宿主机操作系统上执行指令的内核。 CPU也不需要做任何对虚拟机能做那样的虚拟化。\n隔离性 虚拟机的主要好处是它们提供完全隔离的环境, 因为每个虚拟机运行在它自己的Linux内核上, 而容器都是调用同一个内核, 这会有一定的安全隐患","容器实现隔离机制介绍#容器实现隔离机制介绍":"用 Linux 命名空间隔离进程 默认情况下, 每个 Linux 系统最初仅有一个命名空间。可以创建额外的命名空间, 以及在它们之间组织资源。\n对于一个进程, 可以在其中一个命名空间中运行它。进程将只能看到同一个命名空间下的资源。 存在多种类型的多个命名空间, 所以一个进程不单单只属于某一个命名空间, 而属于每个类型的一个命名空间。存在以下类型的命名空间:\nMount (mnt) Process ID (pid) Network (net) Inter-process communicaion (ipd) UTS (UNIX Time-Sharing) User ID (user) 每种命名空间被用来隔离一组特定的资源。例如, UTS 命名空间决定了运行在命名空间里的进程能看见哪些主机名和域名。通过分派两个不同的 UTS 命名空间给一对进程, 能使它们看见不同的本地主机名。换句话说, 这两个进程就好像正在两个不同的机器上运行一样(至少就主机名而言是这样的)。同样地, 一个进程属于什么 Network 命名空间决定了运行在进程里的应用程序能看见什么网络接口。每个网络接口属于一个命名空间, 但是可以从一个命名空间转移到另一个。 每个容器都使用它自己的网络命名空间, 因此每个容器仅能看见它自己的一组网络接口。\n限制进程的可用资源 另外的隔离性就是限制容器能使用的系统资源。 这通过cgroups来实现。cgroups 是一个Linux 内核功能, 它被用来限制 一个进程或者一组进程的资源使用。一个进程的资源(CPU、 内存、 网络带宽等)使用量不能超出被分配的量。 这种方式下, 进程不能过分使用为其他进程保留的资源, 这和进程运行在不同的机器上是类似的。\n备注：2020年3月发布的Linux 5.6引入了新的Time Namespace这个命名空间，它可以让不同命名空间里的进程看到不同的系统时间\n图书资料：\nhttps://book.douban.com/subject/30418855/ 参考：\nhttps://en.wikipedia.org/wiki/Linux_namespaces "},"title":"Kubernetes in Action笔记 - (1) 容器技术介绍"},"/blog/2020/12/k8s_daemonset_job/":{"data":{"":"","cronjob#CronJob":"cron 任务通过创建 CronJob 资源进行配置。它可以通过配置项中的 jobTemplate 属性创建任务资源。\n计划任务的运行方式：在计划的时间内,CronJob资源 会创建 Job资源,然后Job创建pod。\napiVersion: batch/vlbeta kind: CronJob metadata: cron-job-run-every-fifteen-minutes spec: schedule: \"0,15,30,45 * * * *\" jobTemplate: spec: template: metadata: labels: app: periodic-batch-job spec: restartPolicy: OnFailure containers: - name: main image: luksa/batch-job startingDeadlineSeconds字段来指定截止日期。当Job或pod创建并运行得相对较晚的时候，任务将不会运行,并将显示为Failed。\n在正常 情况下,CronJob总是为计划中配置的每个执行创建一个 Job, 但可能会同时创建两个Job, 或者根本没有创建。为了解决第一个问题,任务应该是幂等的(多次而不是一次运行不会得到不希望的结果)。对于第二个问题,请确保下一个任务运行完成本应该由上一次的(错过的)运行完成的任何工作。\n图书资料：\nhttps://book.douban.com/subject/30418855/ ","daemonset#DaemonSet":"DaemonSet 用于确保一个pod匹配它的选择器并在每个节点上运行。因此，它并没有期望的副本数的概念。\n如果节点下线, DaemonSet不会在其他地方重新创建pod。 但是, 当将一个新节 点添加到集群中时, DaemonSet会立刻部署一个新的pod实例。\n使用场景的例子：\npod执行系统级别的与基础结构相关的操作。例如, 希望在每个节点上运行日志收集器和资源监控器。 另一个典型的例子是Kubemetes 自己的kube-proxy进程, 它需要运行在所有节点上才能使服务工作 可以通过 pod 模板中的 nodeSelector 属性让 DaemonSet 只在特定的节点上运行 pod。\napiVersion: apps/vlbeta2 kind: DaemonSet metadata: name: ssd-monitor spec: selector: matchLabels: app: ssd-monitor template: metadata: labels: app: ssd-monitor spec: # pod模板包含 会选择有disk=ssd标签的节点个节点选择器, nodeSelector: disk: ssd containers: - name: main image: luksa/ssd-monitor ","job#Job":"Job允许运行一种 pod, 该 pod 在内部进程成功结束时, 不重启容器。\n在发生节点故障时,该节点上由 Job 管理的 pod 将按照 ReplicationSet 的 pod 的方式,重新安排到其他节点。 如果进程本身异常退出(进程返回错误退出代码时), 可以将 Job 配置为重新启动容器。\nJob 对于临时任务很有用, 关键是任务要以正确的方式结束。需要明确地将重启策略设置为OnFa辽ure或Never，防止容器在完成任务时重新启动\napiVersion: batch/vl kind: Job metadata: name: batch-job spec: template: metadata: labels: app: batch-job spec: # Job 不能使用Always作为默认的重启策略 restartPolicy: OnFailure containers: - name: main image: luksa/ssd-monitor 作业可以配置为创建多个pod实例, 以并行或串行方式运行它们。这是通过在Job配置中设置 completions和paralletism属性来完成的。\n如果需要一个Job顺序运行多次，则可以将completions设为希望运行的次数。Job将一个接一个地运行五个pod。它最初创建一个pod, 当pod的容器运行完成时,它创建第二个pod, 以此类推，直到五个pod成功完成。如果其中 一 个pod发生故障，工作会创建 一个新的pod, 所以Job总共可以创建五个以上的pod。\napiVersion: batch/vl kind: Job metadata: name: multi-completion-batch-job spec: completions: 5 template: ... 通过paralletism Job配置属性,指定允许多少个pod并行执行\napiVersion: batch/vl kind: Job metadata: name: multi-completion-batch-job spec: completions: 5 paralletism: 2 template: ... 可以在 Job 运行时更改 Job 的 parallelism 属性\nkubectl scale job multi-completion-ba七ch-job --replicas 3 通过在 pod 配置中设置 activeDeadlineSeconds 属性，可以限制 pod的时间。如果 pod 运行时间超过此时间, 系统将尝试终止 pod, 并将 Job 标记为失败。通过指定 Job manifest 中的 spec.backoff巨m辽字段, 可以配置 Job 在被标记为失败之前可以重试的次数。 如果没有明确指定它, 则默认为6。"},"title":"Kubernetes in Action笔记 - (7) DaemonSet、Job和CronJob"},"/blog/2020/12/k8s_deployment/":{"data":{"":"Deployment是一种更高阶资源, 用于部署应用程序并以声明的方式升级应用。\n在使用 Deployment 时, 实际的 pod是由 Deployment 的 Replicaset 创建和管理的, 而不是由 Deployment 直接创建和管理的。\n在升级应用过程中，部署新版本的应用时，会创建新的Replicaset用于管理版本的pod。升级过程中的某个时刻，就会存在新旧两个版本的Replicaset。因此，需要引入Deployment来协调。\n与Replicaset类似，Deployment也是由标签选择器、期望副数和pod模板组成的。此外,它还包含另一个字段，用于指定一 个部署策略，表示在修改Deployment资源时应该如何执行更新。","创建deployment#创建Deployment":" appVersion: apps/v1beta1 kind: Deployment metadata: name: kubia spec: replicas: 3 template: metadata: name: kubia labels: app: kubia spec: containers: - image: luksa/kubia:vl name: nodejs 创建一个Deployment\n# 确保在创建时使用了 --record 选项。 这个选项会记录历史版本号, 在之后的操作中非常有用 kubectl create -f kubia-deployment-v1.yaml --record 查看 Deployment 的详细信息\nkubectl get deployment kubectl describe de­ployment 查看部署状态\nkubectl rollout status deployment kubia ","升级deployment#升级deployment":"只需修改 Deployment 资源中定义的 pod 模板, k8s 会自动将实际的系统状态收敛为资源中定义的状态\n不同的 Deployment 升级策略：\nRollingUpdate：执行滚动更新，默认值。如果应用能够支持多个版本同时对外提供服务, 则推荐使用这个策略来升级应用 Recreate：一次性删除所有旧版本的 pod, 然后创建新的 pod。如果应用程序不支持多个版本同时对外提供服务, 需要在启动新版本之前完全停用旧版本, 那么需要使用这种策略。但是会导致应用程序出现短暂的不可用。 下面是修改 Deployment 或其他资源的不同方式。这些方式在操作 Deployment 资源时效果都是一样的。 它们无非就是修改Deployment 的规格定义, 修改后会触发滚动升级过程。\n方法 作用 kubectl edit 使用默认编辑器打开资源配置。修改保存并退出编辑器, 资源对象会被更新。例子: kubectl edit deployment kubia kubectl patch 修改单个资源属性。例子: kubectl patch deployment kubia -p’ {“spec”: {“template”: {“spec”: {“containers”: [ {“name”: “nodejs”, “image”: “luksa/kubia:v2”}]}}}}' kubectl apply 通过一个完整的YAML或JSON文件,应用其中新的值来修改对象。如果YAML/JSON中指定的对象不存在,则会被创建。该文件需要包含资源的完整定义(不能像kubectl patch那样只包含想要更新的字段)。例子 : kubectl apply -f kubia-deployment-v2.yaml kubectl replace 将原有对象替换为YAML/JSON文件中定义的新对象。与apply命令相反, 运行这个命令前要求对象必须存在,否则会打印错误。例子: kubectl replace -f kubia-deployment-v2.yaml 。 kubectl setimage 修改Pod、ReplicationController、Deployment、DaemonSet、Job或ReplicaSet内的镜像。例子: kubectl set image deployment kubia nodejs=luksa/kubia:v2 ","回滚deployment#回滚Deployment":"取消最后一次部署的 Deployment\nkubectl rollout undo deployment kubia undo 命令也可以在滚动升级过程中运行,并直接停止滚动升级。过程中已创建的 pod 会被删除并被老版本的 pod 替代。\n使用kubectl rollout history显示升级的版本。注意：需要在创建 Deployment 时指定 –record 参数。如果不给定这个参数, 版本历史中的 CHANGE-CAUSE 这一栏会为空，这就很难辨别每次的版本做了哪些修改\n$ kubectl rollout history deployment kubia deployments \"kubia\" REVISION CHANGE-CAUSE 2 kubectl set image deployment kubia nodejs=luksa/kubia:v2 3 kubectl set image deployment kubia nodejs=luksa/kubia:v3 回滚到一个特定的 Deployment 版本\nkubectl rollout undo deployment kubia --to-revision=l 可以通过指定 Deployment 的 revisionHistoryLimit 属性来限制历史版本数量。默认值是2，所以正常情况下在版本列表里只有当前版本和上一个版本","恢复滚动升级#恢复滚动升级":" kubectl rollout resume deployment kubia ","控制滚动升级速率#控制滚动升级速率":"在 Deployment 的滚动升级期间,有两个属性会决定一次替换多少个pod: maxSurge 和 maxUnavailable。可以通过 Deployment 的 strategy 字段下rollingUpdate 的子属性来配置\nspec: strategy: rollingUpdate: maxSurge: 1 maxunavailable: 0 type: RollingUpdate 属性 含义 maxSurge 决定了 Deployment 配置中期望的副本数之外,最多允许超出的 pod 实例的数量。默认值为 25% ,所以 pod 实例最多可以比期望数量多25%。如果期望副本数被设置为4，那么在滚动升级期间,不会运行超过 5 个 pod 实例。当把百分数转换成绝对值时, 会将数字四舍五入。这个值也可以不是百分数而是绝对值 ( 例如,可以允许最多多出一个或两个pod) 。 maxUnavailable 决定了在滚动升级期间，相对于期望副本数能够允许有多少 pod 实例处于不可用状态。默认值也是 25%, 所以可用 pod 实例的数量不能低于期望副本数的 75%。百分数转换成绝对值时这个数字也会四舍五入。如果期望副本数设置为 4，并且百分比为 25%。那么只能有一个pod 处于不可用状态。在整个发布过程中，总是保持至少有三个pod实例处于可用状态来提供服务。与 maxSurge 一样,也可以指定绝对值而不是百分比 ","暂停滚动升级#暂停滚动升级":" kubectl rollout pause deployment kubia ","阻止出错版本的滚动升级#阻止出错版本的滚动升级":"Deployment的minReadySeconds属性指定新创建的pod至少要成功运行多久之后, 才能将其视为可用。在pod可用之前, 滚动升级的过程不会继续。\n如果一个新的pod 运行出错, 并且在minReadySeconds时间内它的就绪探针出现了失败, 那么新版本的滚动升级将被阻止。\n使用这个属性可以通过让k8s在pod就绪之后继续等待10秒, 然后继续执行滚动升级, 来减缓滚动升级的过程。通常情况下需要将minReadySeconds设置为 更高的值, 以确保pod在它们真正开始接收实际流量之后可以持续保持就绪状态。\n图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (12) Deployment"},"/blog/2020/12/k8s_label_annotation_namespace/":{"data":{"":"","命名空间#命名空间":"作用 k8s的命名空间简单地为对象名称提供了一个作用域。这样就可以将包含大量组件的复杂系统拆分为更小的不同组，这些不同组也可以用于在多租户环境中分配资源，将资源分配为生产、开发和 QA 环境,或者以其他任何你需要的方式分配资源。资源名称只需在命名空间内保持唯一即可，因此两个不同的命名空间可以包含同名的资源。\n创建命名空间及其资源 可以使用yaml文件来创建命名空间\napiVersion: vl kind: Namespace metadata: name：custom-namespace 或者使用命令来创建命名空间\nkubectl create namespace custom-namespace 想要在创建的命名空间中创建资源, 可以选择在 metadata 宇段中添加一个 namespace: custom-namespace 属性,也可以在使用 kubectl create命令创建资源时指定命名空间:\nkubectl create -f kubia-manual.yaml -n custom-namespace 命名空间的切换 如果不指定命名空间, kubectl 将在当前上下文中配置的默认命名空间中执行操作。而当前上下文的命名空间和当前上下文本身都可以通过 kubectl config 命令进行更改。如果想要对其他命名空间中的对象进行操作, 需要给 kubectl 命令传递– namespace (或 -n) 选项。\n要想快速切换到不同的命名空间, 可以设置以下别名，然后,可以使用 kcd some-namespace 在命名空间之间进行切换 。\nalias kcd =’kubectl config set context $(kubectl config current-context) -- namespace’ 命名空间的隔离性 尽管命名空间将对象分隔到不同的组,只允许你对属于特定命名空间的对象进行操作, 但实际上命名空间之间并不提供对正在运行的对象的任何隔离 。\n例如,你可能会认为当不同的用户在不同的命名空间中部署 pod 时,这些 pod 应该彼此隔离,并且无法通信,但事实却并非如此。命名空间之间是否提供网络隔离取决于 Kubemetes 所使用的网络解决方案。\n图书资料：\nhttps://book.douban.com/subject/30418855/ ","标签#标签":"什么是标签 标签是可以附加到资源的任意键值对。通过标签选择器，可以筛选出具有该确切标签的资源。\n使用标签和选择器来约束pod调度 默认情况下，Pod基本上是随机地调度到任意Node节点的。但是某些情况下，想要调度到特定的Node节点，比如SSD硬盘的节点。这个时候，可以通过节点标签和节点标签选择器完成。\n# 这个例子中通过nodeSelector选择部署到gpu=true的节点 apiVersion: vl kind: Pod metadata: name: kubia-gpu spec: nodeSelector: gpu=true containers: - image: luksa/kubia name: kubia ","注解#注解":"除标签外,pod和其他对象还可以包含注解。注解也是键值对, 但与标签不同, 注解并不是为了保存标识信息而存在的。\n使用注解可以为每个pod或其他API对象添加说明,以便每个使用该集群的人都可以快速查找有关每个单独对象的信息。"},"title":"Kubernetes in Action笔记 - (4) 标签、注解与命名空间"},"/blog/2020/12/k8s_pod_intro/":{"data":{"":"","pod的一些特征#Pod的一些特征":"同一Pod中容器之间的部分隔离 Pod内部的容器共享部分资源（不是全部），没有完全隔离。这些容器共享相同的 Linux 命名空间, 而不是每个容器都有自己的一组命名空间。比如，它们有相同的 network 和 UTS 命名空间，所以它们都共享相同的主机名和网络接口。\n但当涉及文件系统时, 情况就有所不同。 由于大多数容器的文件系统来自容器镜像, 因此默认情况下, 每个容器的文件系统与其他容器完全隔离。但是，可以使用名为 Volume 的 k8s 资源来共享文件目录。\nPod内部容器共享相同的IP和端口空间 由于一个pod中的容器运行于相同的 Network 命名空间中, 因此它们共享相同的 IP 地址和端口空间。这意味着在同一 pod 中的容器运行的多个进程需要注意不能绑定到相同的端口号, 否则会导致端口冲突, 但这只涉及同一pod 中的容器。\n由于每个 pod 都有独立的端口空间, 对于不同 pod 中的容器来说则永远不会遇到端口冲突。\n此外, 一个pod 中的所有容器也都具有相同的 loopback网络接口, 因此容器可以通过 localhost 与同一 pod 中的其他容器进行通信。\n平坦的Pod之间网络 k8s 集群中的所有 pod 都在同一个共享网络地址空间中, 这意味着每个 pod 都可以通过其他 pod 的 IP 地址来实现相互访问。 换句话说, 这也表示它们之间没有 NAT (网络地址转换) 网关。 当两个 pod 彼此之间发送网络数据包时, 它们都会将对方的实际 IP 地址看作数据包中的源 IP 。\n不论是将两个 pod 安排在相同或是不同的工作节点上, 同时不管实际节点间的网络拓扑结构如何, 这些 pod 内的容器都能够像在无 NAT 的平坦网络中一样相互通信","为何需要pod#为何需要Pod":"多个容器比单个容器中包含多个进程要好 想象一个由多个进程组成的应用程序, 无论是通过ipc (进程间通信)还是本地存储文件进行通信, 都要求它们运行于同一 台机器上。 在k8s中, 我们经常在容器中运行进程, 由于每一个容器都非常像一台独立的机器, 此时你可能认为在单个容器中运行多个进程是合乎逻辑的, 然而在实践中这种做法并不合理。\n容器被设计为每个容器只运行一个进程(除非进程本身产生子进程)。如果在单个容器中运行多个不相关的进程, 那么保持所有进程运行、 管理它们的日志等将会是我们的责任。例如, 我们需要包含一种在进程崩溃时能够自动重启的机制。同时这些进程都将记录到相同的标准输出中, 而此时我们将很难确定每个进程分别记录了什么。\n综上所述, 我们需要让每个进程运行于自己的容器中, 而这就是Docker和k8s期望使用的方式。\n引入Pod 由于不能将多个进程聚集在一个单独的容器中, 我们需要另一种更高级的结构来将容器绑定在一起,并将它们作为一个单元进行管理,这就是 Pod 背后的根本原理。\n在包含容器的 Pod 下,我们可以同时运行一些密切相关的进程,并为它们提供几乎相同的环境, 此时这些进程就好像全部运行于单个容器中一样, 同时又保持着一定的隔离。这样一来, 我们便能全面地利用容器所提供的特性, 同时对这些进程来说它们就像运行在一起一 样, 实现两全其美。","什么是pod#什么是Pod":"Pod是k8s的基本构建模块，包含一个或者多个容器。一个Pod中的所有容器都运行在同—个节点上，绝不跨越两个节点","通过pod合理管理容器#通过Pod合理管理容器":" 应该将多层应用分散到多个 pod 中。比如前后端应用要分别在不同的pod中 基于扩缩容考虑而分割到多个 pod 中。不应该将应用程序都放到单一pod 中的原因就是扩缩容。 pod 也是扩缩 容的基本单位, 如果两个应用的扩缩容需求不一致，那肯定是要放在不同的pod中 将多个容器添加到单个 pod 的主要原因是应用可能由一个主进程和一个或多个辅助进程组成。比如一个是主业务服务容器，另外一个是sidecar容器。sidecar 容器的例子包括日志轮转器和收集器、数据处理器、通信适配器等。\n基本上, 总是应该倾向于在单独的pod 中运行容器, 除非有特定的原因要求它们是同一 pod 的一部分。当决定是将两个容器放入一个 pod 还是两个单独的 pod 时, 需要考虑以下问题:\n它们需要一起运行还是可以在不同的主机上运行? 它们代表的是一个 体还是相互独立的组件? 它们必须一起进行扩缩容还是可以分别进行? 图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (3) Pod介绍"},"/blog/2020/12/k8s_pod_lifecycle_probes/":{"data":{"":"","pod-状况#Pod 状况":"Pod 有一个 PodStatus 对象，其中包含一个 PodConditions 数组。Pod 可能通过也可能未通过其中的一些状况测试。\nPodScheduled：Pod 已经被调度到某节点； ContainersReady：Pod 中所有容器都已就绪； Initialized：所有的 Init 容器 都已成功启动； Ready：Pod 可以为请求提供服务，并且应该被添加到对应服务的负载均衡池中。 字段名称 描述 type Pod 状况的名称 status 表明该状况是否适用，可能的取值有 “True”, “False” 或 “Unknown” lastProbeTime 上次探测 Pod 状况时的时间戳 lastTransitionTime Pod 上次从一种状态转换到另一种状态时的时间戳 reason 机器可读的、驼峰编码（UpperCamelCase）的文字，表述上次状况变化的原因 message 人类可读的消息，给出上次状态转换的详细信息 ","pod生命周期#Pod生命周期":"Pod的phase是Pod生命周期中的简单宏观描述，定义在Pod的PodStatus对象的phase 字段中。\nphase有以下几种值：\n状态值 说明 挂起（Pending） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间。 运行中（Running） 该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。 成功（Succeeded） Pod 中的所有容器都被成功终止，并且不会再重启。 失败（Failed） Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。 未知（Unknown） 因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。 ","两种探针的区别#两种探针的区别":"总的来说 ReadinessProbe 和 LivenessProbe 是使用相同探测的方式，只是探测后对 Pod 的处置方式不同：\n存活探针： 当检测失败后将杀死容器，并根据 Pod 的重启策略来决定作出对应的措施。即重启，或删除并重建。 就绪探针： 当检测失败后，将 Pod 的 IP:Port 从对应 Service 关联的 EndPoint 地址列表中删除。即设置为服务不可访问。 图书资料：\nhttps://book.douban.com/subject/30418855/ 参考：\nhttp://www.mydlq.club/article/39/ https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/ ","存活探针#存活探针":"介绍 通过存活探针 (liveness probe) 检查容器是否还在运行。如果探测失败, k8s将定期执行探针并重新启动容器。\n可以为pod中的每个容器单独指定存活探针。\n有以下三种探测容器的机制：\nHTTP GET 探针 对容器的IP地址(你指定的端口和路径)执行 HTTP GET请求。如果探测器收到响应，并且响应状态码不代表错误(换句话说，如果HTTP响应状态码是2xx或3xx)，则认为探测成功。如果服务器返回错误响应状态码或者根本没有响应,那么探测就被认为是失败的，容器将被重新启动。 TCP套接字探针 尝试与容器指定端口建立TCP连接。如果连接成功建立,则探测成功。否则，容器重新启动。 Exec探针 在容器内执行任意命令,并检查命令的退出状态码。如果状态码是0，则探测成功。所有其他状态码都被认为失败。 下面是包含存活探针的例子\napiVersion: vl kind: Pod metadata: name: test-liveness spec: containers: - image: pz/testPod name: testPod livenessProbe: httpGet: path: / port: 8080 initialDelaySeconds: 15 存活探针还有一些附加属性，比如：\ndelay: 在容器启动后延迟多久开始探测 timeout： 此容器必须在多少时间内进行响应, 否则这次探测记作失败 period： 多久探测一次 failure： 失败几次后重启容器 initialDelaySeconds： 初始延迟探测时间。如果没有设置初始延迟，探针将在启动时立即开始探测容器, 这通常会导致探测失败, 因为应用程序还没准备好开始接收请求。如果失败次数超过阈值, 在应用程序能正确响应请求之前, 容器就会重启。务必设置一个初始延迟来说明应用程序的启动时间。 创建有效的探针 对于在生产中运行的pod, 一定要定义一个存活探针。没有探针的话，k8s无法知道应用是否还活着。\n存活探针的注意事项：\n为了更好地进行存活检查，将探针配置为请求特定的URL路径(例如/health), 并让应用从内部对内部运行的所有重要组件执行状态检查, 以确保它们都没有终止或停止响应。 一定要检查应用程序的内部, 而没有任何外部因素的影响。 例如, 当服务器无法连接到后端数据库时, 前端Web服务器的存活探针不应该返回失败。 如果间题的底层原因在数据库中, 重启Web服务器容器不会解决问题。 由于存活探测将再次失败, 你将反复重启容器直到数据库恢复。 确保 /health 的 HTTP瑞点不需要认证, 否则探剧会一直失败, 导致你的容器无限重启 保持探针轻量。它不应消耗太多的计算资源, 并且运行不应该花太长时间 无须在探针中实现重试循环。因为它的失败阙值是可配置，而且k8s本身会重试 ","容器状态#容器状态":"容器的状态有三种：Waiting（等待）、Running（运行中）和 Terminated（已终止）。","容器重启策略#容器重启策略":"Pod 的 spec 中包含一个 restartPolicy 字段，其可能取值包括 Always、OnFailure 和 Never。默认值是 Always。\nrestartPolicy 适用于 Pod 中的所有容器。restartPolicy 仅针对同一节点上 kubelet 的容器重启动作。当 Pod 中的容器退出时，kubelet 会按指数回退 方式计算重启的延迟（10s、20s、40s、…），其最长延迟为 5 分钟。 一旦某容器执行了 10 分钟并且没有出现问题，kubelet 对该容器的重启回退计时器执行 重置操作。","就绪探针#就绪探针":"与存活探针一样，就绪探针也有三种类型:\nHTTP GET 探针 TCP socket 探针 Exec 探针 启动容器时,可以为 k8s 配置一个等待时间,经过等待时间后才可以执行第一次准备就绪检查。之后,它会周期性地调用探针,并根据就绪探针的结果采取行动。如果某个 pod 报告它尚未准备就绪,则会从该服务中删除该 pod。 如果 pod再次准备就绪,则重新添加 pod。\n就绪探针的重要性:设想一组pod (例如, 运行应用程序服务器的pod)取决于另一个pod (例如, 后端数据库)提供的服务。 如果任何一个前端连接点出现连接间题并且无法再访问数据库, 那么就绪探针可能会告知k8s该pod没有准备好处理任何请求。如果其他pod实例没有遇到类似的连接问题, 则它们可以正常处理请求。就绪探针确保客户端只与正常的pod交互, 并且永远不会知道系统存在问题。\n注意事项：\n务必定义就绪探针 不要将停止 pod 的逻辑纳入就绪探针中 "},"title":"Kubernetes in Action笔记 - (5) Pod的生命周期与探针"},"/blog/2020/12/k8s_pod_meta_data/":{"data":{"":"","与kubernetes-api服务器交互#与Kubernetes API服务器交互":"通过 Kubectl proxy 访问 API 服务器 kubectl proxy命令启动了一 个代理服务来接收来自你本机的 HTTP 连接并转发至 API 服务器, 同时处理身份认证, 所以不需要每次请求都上传认证凭证。\n运行代理很简单, 执行下面的命令\n$ kubectl proxy Starting to serve on 127.0.0.1:8001 上面的返回结果可以看到已经在本地8001代理端口接受请求。执行下面的命令，服务器会返回一个路径清单，这些路径对应了创建Pod、Service这些资源时定义的API组和版本信息\ncurl http://localhost: 8001 通过这些路径可以获取更多的信息，比如下面这个命令可以获取到集群中所有job实例\ncurl http://localhost:8001/apis/batch/vl/jobs 从pod内部与API服务器进行交互 每个pod都会被自动挂载上一个默认的secret卷，映射到每个容器的 /var/run/secrets/kubernetes.io/serviceaccount目录下。 这个Secret包含三个条目：ca.crt、namespace与token, 包含了从pod内部安全访问KubernetesAPI服务器所需的全部信息。\n在pod中运行的应用如何正确访问k8s的 API:\n应用应该验证 API 服务器的证书是否是证书机构所签发, 这个证书是在ca.crt文件中。 应用应该将它在token文件中持有的凭证通过Authorization标头来获得 API 服务器的授权。 当对pod所在命名空间的 API对象进行CRUD操作时, 应该使用namespace文件来传递命名空间信息到 API服务器。 (1) 获取API服务器地址 可以使用下面的命令来获取API服务器地址\n$ kubectl get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes 10.0.0.1 \u003cnone\u003e 443/TCP 46d 可以在容器内通过查询KUBERNETES_SERVICE_HOST 和 KUBERNETES_SERVICE_PORT 这两个环境变量\n$ env | grep KUBERNETES SERVICE KUBERNETES_SERVICE _PORT=443 KUBERNETES_SERVICE_HOST=l0.0.0.1 KUBERNETES_SERVICE_PORT_HTTPS=443 由于每个服务都获得一个DNS入口，也可以简单地将 curl 指向 https://kubernetes，DNS会自动解析到k8s API服务器\n（2）验证身份 指定证书\ncurl --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt https://kubernetes 或者，先定义成环境变量来简化后续的调用 export CURL_CA_BUNDLE=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt curl https://kubernetes 需要获得 API 服务器的授权, 以便可以读取并进一步修改或删除部署在集群中的 API 对象。\nTOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token) curl -H \"Authorization: Bearer $TOKEN\" https://kubernetes 指定访问命名空间\nNS=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace) curl -H \"Authorization: Bearer $TOKEN\" https://kubernetes/api/vl/namespaces/$NS/pods 通过 ambassador 容器简化与 API 服务器的交互 使用HTTPS、 证书和授权凭证, 对千开发者来说看上去有点复杂。 在pod中 向代理而不是直接向API服务器发送请求, 通过代理来处理授权、 加密和服务器验证。\n如果一个应用需要查询API服务器，可以在主容器运行的同时, 启动一个ambassador容器,并在其中运行kubecctl proxy命令, 通过它来实现与API服务器的交互。在这种模式下, 运行在主容器中的应用不是直接与API服务器进行交互, 而是通过HTTP协议(不是HTTPS协议)与ambassador连接, 并且由ambassador通过HTTPS协议来连接API服务器, 对应用透明地来处理安全问题。 这种方式同样使用了默认凭证Secret卷中的文件。\n使用客户端库与API服务器交互 目前, 存在由 API Machinery special interest group(SIG) 支持的两个版本的Kuberbetes API 客户端库。\nGalang client Python k8s社区中还有其他各种不同语言的客户端库\n图书资料：\nhttps://book.douban.com/subject/30418855/ ","通过downward-api传递元数据#通过Downward API传递元数据":"通过Downward API传递元数据 对于pod调度、运行前预设的数据，可以通过环境变量或者configMap和secret卷向应用传递配置数据。但是对于那些不能预先知道的数据, 比如pod的IP、 主机名或者是通过ReplicaSet等控制生成的pod名称，该如何获取呢？这种类型的数据，可以通过使用Kubernetes Downward API解决。\nDownward API可以给在pod中运行的进程暴露pod的元数据。目前可以给容器传递以下数据:\npod的名称 pod的IP pod所在的命名空间 pod运行节点的名称 pod运行所归属的服务账户的名称 每个容器请求的CPU和内存的使用量 每个容器可以使用的CPU和内存的限制 pod的标签 pod的注解 通过环境变量暴露元数据 env: - name: POD_NAME # 引用pod manifest中的元数据名称字段,而不是设定一个具体的值 valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: SERVICE_ACCOUNT valueFrom: fieldRef: fieldPath: spec.serviceAccountName - name: CONTAINER_CPU_REQUEST_MILLICORES valueFrom: # 容器请求的CPU和内存使用量是使用resourceFieldRef字段而不是feildRef字段 resourceFieldRef: resource: requests.cpu divisor: 1m # 对于资源相关字段，定义一个基数单位，从而生成每一部分的值 - name: CONTAINER MEMORY LIMIT KIBIBYTES valueFrom: resourceFieldRef: resource: limits.memory divisor: 1Ki 对于暴露资源请 和使用限制的环境变量, 我们会设定一个基数单位。实际的资源请求值和限制值除以这个基数单位, 所得的结果通过环境变量暴露出去。在上面的例子中, 我们设定 CPU 请求的基数为1m (即1 millicore, 也就是千分之一核CPU)。当我们设置资源请求为15m时, 环境变量CONTAINER_CPU_REQUEST_MILLICORES的值就是15\n在完成创建pod后, 我们可以使用kubectl exec命令来查看容器中的所有环境变量\nkubectl exec downward env 通过卷传递元数据 可以定义一个downwardAPI卷，并以文件的方式挂载在容器中。\napiVersion: v1 kind: Pod metadata: # 后面会添加定义，通过downwardAPI卷来暴露这些标签 name: downward labels: foo: bar annotations: key1: value1 key2: | multi line value spec: containers: - name: main image: busybox command: [\"sleep\", \"9999999\"] resources: requests: cpu: 15m memory: l00Ki limits: cpu: 100m memory: 4Mi volumeMounts: # 挂载卷 - name: downward mountPath: /etc/downward volumes: # 定义一个名字为downward的downwardAPI卷 - name: downward downwardAPI: items: # Pod名称（来自manifest文件中的metadata.name字段）将被写入podName这个文件 - path: \"podName\" fieldRef: fieldPath: metadata.name - path: \"podNamespace\" fieldRef: fieldPath: metadata.namespace - path: \"labels\" fieldRef: fieldPath: metadata.labels - path: \"annotations\" fieldRef: fieldPath: metadata.annotations - path: \"containerCpuRequestMilliCores\" resourceFieldRef: containerName: main resource: requests.cpu divisor: 1m - path: \"containerMemoryLimitBytes\" resourceFieldRef: containerName: main resource: limits.memory divisor: 1 访问权限设置 与configMap和secret卷一样，可以通过pod定义中downwardAPI卷的defaultMode属性来改变文件的访问权限设置。\n修改标签与注解 可以在pod运行时修改标签和注解。当标签和注解被修改后, k8s会更新存有相关信息的文件,从而使pod可以获取最新的数据。这也解释了为什么不能通过环境变量的方式暴露标签和注解,在环境变量方式下,一旦标签和注解被修改,新的值将无法暴露。\n在卷的定义中引用容器级的元数据 当暴露容器级的元数据时,如容器可使用的资源限制或者资源请求(使用字段resourceFieldRef), 必须指定引用资源字段对应的容器名称。这是因为对于卷的定义是基于 pod 级的,而不是容器级的。当引用卷定义某一个容器的资源字段时, 需要明确说明引用的容器的名称。这个规则对于只包含单容器的 pod 同样适用。\nresourceFieldRef: containerName: main #必须指定容器名称 resource: limits.memory divisor: 1 使用卷的方式来暴露容器的资源请求和使用限制比环境变量的方式稍显复杂，但好处是如果有必要, 可以传递一个容器的资源字段到另一个容器(当然两个容器必须处于同一个 pod)。使用环境变量的方式, 一个容器只能传递它自身资源申请求和限制的信息。\nDownward API优缺点 DownwardAPI 方式并不复杂, 它使得应用独立于k8s。这一点在处理部分数据已在环境变量中的现有应用时特别有用。它使得我们不必通过修改应用, 或者使用 shell 脚本获取数据再传递给环境变量的方式来暴露数据。\n不过这种方式获取的元数据是相当有限的, 如果需要获取更多的元数据, 需要使用直接访问 k8s API 服务器的方式"},"title":"Kubernetes in Action笔记 - (11) 从应用访问pod元数据及其他资源"},"/blog/2020/12/k8s_replctl_replset/":{"data":{"":"","replicaset#ReplicaSet":"它是新一代的ReplicationController, ReplicationController会被弃用。ReplicaSet 的行为与 ReplicationController 完全相同, 但 pod 选择器的表达能力 更强。\n通常不会直接创建ReplicaSet, 而是在创建更高层级的 Deployment 资源时自动创建。\n注意：ReplicaSet不是v1 API的一部分，因此需要确保在创建资源时指定正确的apiVersion\n# 与ReplicationController的定义基本相同，唯一的区别在选择器中。 apiVersion: apps/v1beta2 kind: ReplicaSet metadata: name: kubia spec: replicas: 3 selector: matchLabels: app: kubia template: metadata: labels: app: kubia spec: containers: - name: kubia image: luksa/kubia ports: - containerPort: 8080 除了matchLabels之外，还支持matchExpressions表达式。operator支持4中运算符：In, NotIn, Exists, DoesNotExist\nselector: matchExpression: - key: app operator: In values: - kubia 删除ReplicaSet会删除所有的pod\nkubectl delete rs kubia 图书资料：\nhttps://book.douban.com/subject/30418855/ ","replicationcontroller#ReplicationController":"ReplicationController是一种k8s资源，会持续监控正在运行的pod列表, 并保证相应类型的pod的数目与期望相符。\n一个ReplicationController有三个主要部分：\nlabel selector (标签选择器), 用于确定ReplicationController作用域中有哪些pod replica count (副本个数), 指定应运行的pod 数量 pod template (pod模板), 用于创建新的pod 副本 使用 ReplicationController 的好处:\n确保一个 pod (或多个 pod 副本)持续运行, 方法是在现有 pod 丢失时启动一个新 pod 。 集群节点发生故障时, 它将为故障节点上运行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。 它能轻松实现 pod 的水平伸缩，手动和自动都可以 创建一个ReplicationController\napiVersion: vl kind: Replicationcontroller metadata: name: kubia spec: replicas: 3 selector: app: kubia template: metadata: labels: app: kubia spec: containers: - name: kubia image: luksa/kubia ports: - containerPort: 8080 通过kubectl get命令显示的关于ReplicationController的信息\nkubectl get rc kubectl get replicationcontroller 通过kubectl describe查看附加信息\nkubectl describe rc kubia 通过更改pod的标签, 可以将它从ReplicationController的作用域中添加或删除，甚至移动到另外一个ReplicationController\nReplicationController 的 pod 模板可以随时修改，但是只会影响后面新建的 Pod。如果需要修改旧的Pod，要将Pod删除，ReplicationController会自动根据新的模板创建Pod来替代。\n通过修改replicas字段，可以实现水平缩放pod\nkubectl scale rc kubia --replicas=lO 也可以通过下面命令打开编辑器直接修改声明\nkubectl edit rc kubia 通过 kubectl delete 删除 ReplicationController 时, pod 也会被删除\nkubectl delete rc kubia 但是由于由 ReplicationController 创建的 pod 不是 ReplicationController 的组成部分, 只是由其进行管理, 因此可以只删除 ReplicationController 并保待 pod 运行。\nkubectl delete rc kubia --cascade=false ","托管的pod#托管的Pod":"如果是直接创建Pod，当节点失效，这个Pod就会丢失。\n如果是通过ReplicationController或者Deployment等资源来创建的，那就属于托管的资源。k8s集群会管理并检测它的运行状态，当一些意外情况发生的，k8s会自动采取应对措施。"},"title":"Kubernetes in Action笔记 - (6) ReplicationController和ReplicationSet"},"/blog/2020/12/k8s_service/":{"data":{"":"","为什么需要服务#为什么需要服务":"pod 的存在是短暂的,一个 pod 可能会在任何时候消失, 或许因为它所在节点发生故障, 或许因为有人删除了 pod, 或者因为 pod 被从一个健康的节点剔除了。 当其中任何一种情况发生时, 消失的 pod 将被ReplicationController 替换为新的 pod。 新的 pod 与替换它的 pod 具有不同的 IP 地址。\n这就是需要服务的地方，解决不断变化的 pod IP 地址的问题, 以及在一个固定的IP和端口对上对外暴露多个 pod。当一个服务被创建时, 它会得到一个静态的 IP, 在服务的生命周期中这个 IP不会发生改变。 客户端应该 通过固定 IP 地址连接到服务, 而不是直接连接 pod。服务会确保其中一个pod 接收连接, 而不关心 pod 当前运行在哪里(以及它的 IP 地址 是什么)。","什么是服务#什么是服务":"服务是一种为一组功能相同的 pod 提供单 一 不变的接入点的资源。当服务存在时,它的 IP 地址和端口不会改变","创建服务#创建服务":"通过 kubectl expose 创建服务\nkubectl expose pod valid-pod --port=444 --name=frontend 通过 YAML 描述文件来创建服务\napiVersion: v1 kind: Service metadata: name: kubia spec: ports: - port: 80 # 该服务的可用端口 targetPort: 8080 # 转发到的容器端口 # 选择Pod selector: app: kubia ","将服务暴露给外部客户端#将服务暴露给外部客户端":"（1）使用NodePort类型的服务 通过创建NodePort服务, 可以让Kubemetes在其所有节点上保留一个端口(所有节点上都使用相同的端口号), 并将传入的连接转发给作为服务部分的pod\n这与常规服务类似(它们的实际类型是ClusterIP), 但是不仅可以通过服务的内部集群IP访问NodePod 服务, 还可以通过任何节点的IP和预留节点端口访问NodePort服务。\n（2）通过负载均衡器将服务暴露出来 Load Badancer服务是NodePod服务的扩展。\n负载均衡器拥有自己独一无二的可公开访问的 IP 地址, 并将所有连接重定向到服务。可以通过负载均衡器的 IP 地址访问服务。\n（3）通过Ingress暴露服务 为什么需要 Ingress 用Ingress一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器, 以及独有的公有 IP 地址, 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问。\nIngress 在网络栈 (HTTP) 的应用层操作, 并且可以提供一些服务不能实现的功能, 诸如基于 cookie 的会话亲和性 (session affinity) 等功能。\n注意：只有 Ingress 控制器在集群中运行, Ingress 资源才能正常工作。不同的 Kubernetes 环境使用不同的控制器实现, 但有些并不提供默认控制器\n为 Ingress 创建 TLS 认证 Ingress如果要处理TLS内容，需要将证书和私钥附加到 Ingress。这两个必需资源存储在称为 Secret 的 Kubernetes 资源 中,然后在 Ingress manifest 中引用它\n图书资料：\nhttps://book.douban.com/subject/30418855/ ","服务endpoint#服务Endpoint":"服务并不是和 pod 直接相连的，有一种资源介于两者之间，它就是 Endpoint 资源。kubectl describe svc xxx 命令可以看到输出的结果中有Endpoint属性值","服务发现#服务发现":"通过环境变量发现服务 在 pod 开始运行的 时候 , k8s 会初始化一系列的环境变量指向现在存在的服务。\n如果创建的服务早于客户端 pod 的创 建, pod 上的进程可以根据环境变量获得服务的 IP 地址和端口号。\n如果服务的创建晚于 pod 的创建, 那么关于这个服务的环境变量并没有设置。需要删除所有的 pod 使得 ReplicationController创建全新的 pod\n通过 DNS 发现服务 kube-system 的命名空间中有kube-dns的pod，它运行了 DNS 服务。在集群中的其他 pod 都被配置成使用其作为 dns ( k8s 通过修改每个容器的/etc/resolv.conf 文件实现)。\n注意：从 Kubernetes v1.12 开始，CoreDNS 是推荐的 DNS 服务器，取代了 kube-dns\n通过 FQDN 连接服务 FQDN，全限定域名\n下面是一个例子。其中，backend-database 对应于服务名称, default 表示服务在其中定义的名称空间,而 svc.cluster.local 是在所有集群本地服务名称中使用的可配置集群域后缀。\nbackend-database.default.svc.cluster.local 如果前端 pod 和数据库 pod 在同一个命名空间下,可以省略 svc.cluster.local 后缀，甚至命名空间","服务的一些配置#服务的一些配置":"会话的亲和性 如果多次执行同样的命令, 每次调用执行在随机的pod上。如果希望特定客户端产生的所有请求每次都指向同一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (默认值是None)。这种方式将会使服务代理将来自同 一 个 client IP 的所有请求转发至同一个pod上\n同一个服务暴露多个端口 创建的服务可以暴露一个端口,也可以暴露多个端口。比如,你的 pod 监听两个端口,比如 HTTP 监听 8080 端口、HTTPS 监听 8443 端口,可以使用一个服务从端口 80 和 443 转发至 pod 端口 8080 和 8443 。\n使用命名的端口 在服务 spec 中也可以给不同的端口号命名, 通过名称来指定。这样对于一些不是众所周知的端口号,使得服务 spec 更 加清晰。\n最大的好处就是即使更换端口号 也无须更改服务 spec 。\n# 在 pod 的定义中指定port 名称 kind: Pod spec: containers: - name: kubia ports : - name : http containerPort: 8080 - name : https containerPort: 8443 # 在服务中引用命名 pod apiVersion : vl kind: Service spec: ports: - name : http port : 80 targetPort: http - name : https port: 443 targetPort: https ","通过完全限定名fqdn访问外部服务#通过完全限定名（FQDN）访问外部服务":"要将资源的一个type字段设置为ExternalName。\n例如, 在api.somecompany.com上有公共可用的API，可以定义一个指向它的服务。服务创建完成后,pod可以通过external-service.default.svc.cluster.local域名(甚至是external-service)连接到外部服务\napiVersion: v1 kind: Service metadata: name: external-service spec: type: ExternalName externalName: someapi.somecompany.com ports: - port: 80 ExternalName服务仅在DNS级别实施一为服务创建了简单的CNAME DNS记录,指向完全限定的域名而不是数字 IP 地址"},"title":"Kubernetes in Action笔记 - (8) 服务、Endpoint、Ingress"},"/blog/2020/12/k8s_statefulset/":{"data":{"":"","了解statefulset#了解Statefulset":"与ReplicaSet比较 Statefulset 保证了pod在重新调度后保留它们的标识和状态。\n与ReplicaSet类似, Statefulset 也是依据Statefulset 的pod模板创建的，也会指定期望的副本个数。\n不同的是, Statefulset创建的pod副本并不是完全一样的。每个pod都可以拥有一组独立的数据卷(持久化状态)。pod的名字都是规律的(固定的), 而不是每个新pod都随机获取一个名字。\n提供稳定的网络标识 一个Statefulset创建的每个pod都有一个从零开始的顺序索引, 这个会体现在pod的名称和主机名上, 同样还会体现在pod对应的固定存储上。\n与普通的pod不一样的是, 有状态的pod有时候需要通过其主机名来定位。无状态Pod都是一样的，所以访问的时候随便选择一个都可以；而有状态的pod是彼此不同的，通常希望操作的是其中特定的一个。\n一个Statefulset 通常要求创建一个用来记录每个pod网络标记的headless Service。通过这个Service, 每个pod将拥有独立的DNS记录, 这样集群里它的伙伴或者客户端可以通过主机名方便地找到它。比如说, 一个属于default命名空间, 名为foo的控制服务, 它的一个pod名称为A-0, 那么可以通过下面的完整域名来访问它 : a-0.foo.default.svc.cluster.local\n扩缩容 Statefulset 扩容一个Statefulset会使用下一个还没用到的顺序索引值创建一个新的pod实例。比如, 要把一个Statefulset从两个实例扩容到三个实例, 那么新实例的索引值就会是2 (现有实例使用的索引值为0和1)。\n缩容一个Statefulset将会最先删除最高索引值的实例，所以缩容的结果是可预知的。作为对比, ReplicaSet 的缩容操作则不同,不知道哪个实例会被删除, 也不能指定先删除哪个实例\n因为 Statefulset 缩容任何时候只会操作一个pod实例，所以有状态应用的缩容相对比较慢。举例来说, 一个分布式存储应用若同时下线多个节点, 则可能导致其数据丢失。比如说一个数据项副本数设置为2的数据存储应用,若同时有两个节点下线,一份数据如果它正好保存在这两个节点上记录就会丢失。若缩容是线性的, 则分布式存储应用就有时间把丢失的副本复制到其他节点,保证数据不会丢失。基于以上原因, Statefulset 在有实例不健康的情况下是不允许做缩容操作的 。若一个实例是不健康的, 而这时再缩容一个实例的话, 也就意味着你实际上同时失去了两个集群成员 。\n为每个有状态实例提供稳定的专属存储 有状态的pod的存储必须是持久的,并且与pod解耦。必须设置成手动释放，否则数据丢失。\n持久卷声明与持久卷是一对一的关系,所以每个Statefulset的 pod 都需要关联到不同的持久卷声明, 与独自的持久卷相对应。\n缩容 Statefulset 时会保留持久卷声明, 所以在随后的扩容操作中, 新的pod实例会使用绑定在持久卷上的相同声明和其上的数据\nStatefulset 的 at-most-one 的语义 一个 Statefulset 必须保证有状态的pod实例的αt-most-one语义。也就是说一个Statefulset必须在准确确认一个pod不再运行后,才会去创建它的替换pod","在-statefulset-中发现伙伴节点#在 Statefulset 中发现伙伴节点":"一个Statefulset中的成员需要很容易地找到其他的所有成员。当然它可以通过与API服务器通信来获取, 但是K8s的一个目标是设计功能来帮助应用完全感觉不到k8s的存在。因此让应用与API服务器通信的设计是不允许的\nDNS中的SRV记录 SRV记录用来指向提供指定服务的服务器的主机名和端口号。k8s通过一个headless service创建SRV记录来指向pod的主机名。\n可以在一个临时pod里运行DNS查询工具dig命令, 列出有状态pod的SRV记录。下面的命令运行 一个名为srvlo okup的 一 次性pod(–restart=Never),它会关联控制台(-it)并且在终止后立即删除(–rm)。这个pod依据tutum/dnsutils镜像启动单独的容器, 然后运行dig命令\n$ kubectl run -it srvlookup --image=tutum/dnsutils --rm --restart=Never -- dig SRV kubia.default.svc.cluster.local ; ; ANSWER SECTION: k.d.s.c.l. 30 IN SRV k.d. s .c.1 . 30 IN SRV 10 33 O kubia-0.kubia.default.svc.cluster.local. 10 33 O kubia-1.kubia.default.svc.cluster.local. ; ; ADDITIONAL SECTION: kubia-0.kubia.default.svc.cluster.local. 30 IN A 172.17.0.4 kubia-1.kubia.default.svc.cluster.local. 30 IN A 172.17.0.6 上面的 ANSWER SECTION显示了两条指向后台headless service的 SRV记录。 同时如ADDITIONAL SECTION所示, 每个pod都拥有独自的一条记录。\n当一个pod要获取一个Statefulset里的其他pod列表时, 需要做的就是触发 一次SRVDNS查询。例如, 在Node.js中查询命令为:\ndns.resolveSrv(\"kubia.default.svc.cluster.local\", callBackFunction); 注意: 返回的SRV记录顺序是随机的, 因为它们拥有相同的优先级。\n图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (13) Statefulset"},"/blog/2020/12/k8s_volume/":{"data":{"":"","卷#卷":"卷是 pod 的一个组成部分，不是独立的 Kubernetes 对象, 不能单独创建或删除。 pod 中的所有容器都可以使用卷, 但必须先将它挂载在每个需要访问它的容器中。","卷类型#卷类型":"主要类型：\nemptyDir:用于存储临时数据的简单空目录。 hostPath: 用于将目录从工作节点的文件系统挂载到pod中 gitRepo: 通过检出Git仓库的内容来初始化的卷 nfs: 挂载到pod中的NFS共享卷 用于挂载云服务商提供的特定存储类型。比如，gcePersistentDi sk (Google 高效能型存储磁盘卷)、 awsElasticBlockStore (AmazonWeb 服务弹性块存储卷)、 azureDisk (Microsoft Azure 磁盘卷) 用于挂载其他类型的网络存储。比如，cinder、cephfs、iscsi、flocker、glusterfs、quobyte、rbd、flexVolume、vsphere-Volume、photonPersistentDisk 、scaleIO configMap、secret、downwardAPI 一一用于将 k8s 部分资源和集群信息公开给 pod 的特殊类型的卷 persistentVolumeClaim：一种使用预置或者动态配置的持久存储类型 emptyDir 卷从一个空目录开始,运行在 pod 内的应用程序可以写入它需要的任何文件。当删除 pod 时,卷的内容就会丢失。\n一个 emptyDir 卷对于在同一个 pod 中运行的容器之间共享文件特别有用。但是它也可以被单个容器用于将数据临时写入磁盘。\n下面是个例子\napiVersion: vl kind: Pod metadata: name : fortune spec: containers: - image: luksa/fortune name: html-generator volumeMounts: - name: html mountPath: /var/html/docs - image: nginx:alpine name: web-server volumeMounts : - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP volumes: - name: html emptyDir: {} medium属性可以指定存储介质。比如内存\nvolumes: name: html emptyDir: medium: Memory 使用 Git 仓库作为存储卷 gitRepo 卷基本上也是 一 个 emptyDir 卷,它通过克隆 Git 仓库并在 pod 启动时(但在创建容器之前) 检出特定版本来填充数据\nvolumes: - name: html gitRepo: repository: https://github.com/luksa/kubia-website-example.git revision: master directory: . 但是它并未与git仓库保持同步，如果git仓库有任何更新，这些更新不会反映到挂载的卷中。可以通过删除并重建pod来获得最新的git代码，或者运行一个附加进程来使卷与 Git 仓库保持同步。\nGit 同步进程不应该运行在主容器中，而应该是在另外一个容器: sidecar container。这种容器增加了对 pod 主容器的操作。在Docker Hub中搜索 “git syc”, 可以看到很多可以实现git仓库同步的容器镜像\nhostPath卷 大多数 pod 应该忽略它们的主机节点, 因此它们不应该访问节点文件系统上的任何文件。但是某些系统级别的 pod(切记, 这些通常由 DaemonSet 管理)确实需要读取节点的文件或使用节点文件系统来访问节点设备。\n它是持久性存储，Pod删除时候，hostPath 卷的内容则不会被删除。\n如果你正在考虑使用 hostPath 卷作为存储数据库数据的目录, 请重新考虑。因为卷的内容存储在特定节点的文件系统中, 所以当数据库 pod 被重新安排在另一个节点时, 会找不到数据。这解释了为什么对常规 pod 使用 hostPath 卷不是一个好主意, 因为这会使 pod 对预定规划的节点很敏感。\n使用持久化卷 当运行在一个 pod 中的应用程序需要将数据保存到磁盘上, 并且即使该 pod 重新调度到另一个节点时也要求具有相同的数据可用，这就必须将其存储在某种类型的网络存储 (NAS) 中。比如 Google Kubernetes Engine的GCE持久磁盘、AWS的awsElasticBlockStore、NFS等等\n持久卷和持久卷声明 为了使应用能够正常请求存储资源, 同时避免处理基础设施细节, 引入了两个新的资源, 分别是待久卷和持久卷声明。这样，开发人员不需要知道底层使用的是哪种存储技术, 同理他们也不需要了解应该使用哪些类型的物理服务器来运行pod, 与基础设施相关的交互是集群管理员独有的控制领域。当开发入员需要一定数量的持久化存储来进行应用时, 可以向 k8s 请求,就像在创建 pod 时可以请求 CPU、 内存和其他资源一样。\n由集群管理员设置底层存储, 然后通过 Kubernetes API 服务器创建持久卷并注册。在创建持久卷时, 管理员可以指定其大小和所支持的访问模式。当集群用户需要在其 pod 中使用持久 化存储时, 他们首先创建持久卷声明(PersistentVolumeClaim, 简称 PVC) 清单, 指定所需要的最低容量要求和访问模式, 然后用户将待久卷声明清单提交给 Kubernetes API 服务器, Kubernetes 将找到可匹配的持久卷并将其绑定到持久卷声明。持久卷声明可以当作 pod 中的一个卷来使用, 其他用户不能使用相同的持久卷,除非先通过删除持久卷声明绑定来释放。\n通过 persistentVolumeReclaimPolicy 属性设置存储卷回收策略：\nRetain: 在持久卷从持久卷声明中释放后仍然能保留它的卷和数据内容。 Recycle: 删除卷的内容并使卷可用于再次声明,通过这种方式,持久卷可以被不同的持久卷声明和 pod 反复使用 Delete: 策略删除底层存储 另外，集群管理员也可以创建一个持久卷配置,并定义一个或多个 StorageClass 对象,从而让用户选择他们想要的持久卷类型而不仅仅只是创建持久卷。用户可以在其持久卷声明中引用 StorageClass，而配置程序在配置持久存储时将采用这一点。可以指定默认的StorageClass，未指定StorageClass时就用默认的。\nStorageClasses 的好处在于,声明是通过名称引用它们的。因此,只要 StorageClass名称在所有这些名称中相同, PVC 定义便可跨不同集群移植\n图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (9) 卷"},"/blog/2021/01/k8s_advanced_scheduling/":{"data":{"":"","使用污点和容忍度阻止节点调度到特定节点#使用污点和容忍度阻止节点调度到特定节点":"污点和容忍度 污点是在不修改已有pod信息的前提下,通过在节点上添加污点信息,来拒绝pod在某些节点上的部署。\n只有当一个pod容忍某个节点的污点, 这个pod才能被调度到该节点。\n可以通过kubectl describe node查看节点的污点信息，在返回结果的Taints字段值中；可以通过kubectl describe po查看pod的污点容忍度，在返回结果的Tolerations字段值中。\n每一个污点都可以关联一个效果, 效果包含了以下三种:\nNoSchedule：表示如果pod没有容忍这些污点, pod则不能被调度到包含这些污点的节点上。 PreferNoSchedule：它是NoSchedule的一个宽松的版本,表示尽量阻止pod被调度到这个节点上,但是如果没有其他节点可以调度, pod依然会被调度到这个节点上。 NoExecute：不同于NoSchedule以及PreferNoSchedule,后两者只在调度期间起作用, 而NoExecute也会影响正在节点上运行着的pod。如果在一个节点上添加了NoExecute污点,那些在该节点上运行着的pod,如果没有容忍这个NoExecute污点,将会从这个节点去除。 添加污点与容忍度 在节点上添加自定义污点 假设有一个单独的 Kubernetes 集群,上面同时有生产环境和非生产环境的流量。其中最重要的一点是,非生产环境的pod不能运行在生产环境的节点上。可以通过在生产环境的节点上添加污点来满足这个要求:\n# 这个命令添加了一个taint,其中key为node-type,value为production,效果为NoSchedule kubectl taint node nodel.k8s node-type=production:NoSchedule 在pod上添加污点容忍度 apiVersion: extensions/vlbetal kind: Deployment metadata: name: prod spec: replicas: 5 template: spec: tolerations: # 此处的污点容忍度允许pod被调度到生产环境节点上 - key: node-type operator: Equal value: production effect: NoSchedule 污点和污点容忍度的使用场景 节点可以拥有多个污点信息,而pod也可以有多个污点容忍度。\n污点可以只有一个key和一个效果,而不必设置value。污点容忍度可以通过设置Equal操作符Equal操作符来指定匹配的value(默认情况下的操作符)，或者也可以通过设置Exists操作符来匹配污点的key。\n在调度时使用污点和容忍度 污点可以用来组织新pod的调度(使用 NoSchedule效果),或者定义非优先调度的节点(使用PreferNoSchedule效果), 甚至是将已有的pod从当前节点剔除。\n可以用任何觉得合适的方式去设置污点和容忍度。例如,可以将一个集群分成多个部分,只允许开发团队将pod调度到他们特定的节点上。 当部分节点提供了某种特殊硬件, 并且只有部分pod需要使用到这些硬件的时候, 也可以通过设置污点和容忍度的方式来实现。\n配置节点失效之后的pod重新调度最长等待时间 也可以配置一个容忍度, 用于当某个pod运行所在的节点变成unready或者unreachable状态时,k8s可以等待该pod被调度到其他节点的最长等待时间\n$ kubectl get po prod-350605-lphSh -o yaml ... tolerations: - effect: NoExecute key: node.alpha.kubernetes.io/notReady operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.alpha.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 这两个容忍度表示, 该pod将容忍所在节点处于notReady或者unreachable状态维持300秒。当k8s控制器检测到有节点处于notReady或者unreachable状态时, 将会等待300秒, 如果状态持续的话, 之后将把该pod重新调度到其他节点上。当没有定义这两个容忍度时, 他们会自动添加到pod上。如果觉得5分钟太长的话,可以在pod描述中显式地将这两个容忍度设置得更短一些。\n注意：在作者写书的时候，这是一个alpha阶段的特性,在未来的k8s版本中可能会有所改变。基于污点信息的pod剔除也不是默认启的, 如果要启用这个特性, 需要在运行控制器管理器时使用--feature-gates=TaintBasedEvictions=true选项。","使用节点亲缘性将pod调度到特定节点上#使用节点亲缘性将pod调度到特定节点上":"可以定义pod的节点亲缘性规则，指定硬性限制或者偏好。\n如果指定一种偏好的话，k8s将尽量把这个pod 调度到某些特定的节点上面；如果没法实现的话, pod 将被调度到其他节点。\n指定强制性节点亲缘性规则 使用了节点选择器使得需要GPU的pod只被调度到有GPU的节点上。\napiVersion: vl kind : Pod metadata: name: kubia-gpu spec: nodeSelector: gpu: \"true\" ... 将节点选择器替换为节点亲缘性规则\napiVersion: v1 kind: Pod metadata: name: kubia-gpu spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: gpu operator: In values: \"true\" requiredDuringScheduling… 表明了该字段下定义的规则,为了让pod能调度到该节点上,明确指出了该节点必须包含的标签。 …IgnoredDuringExecution 表明了该字段下定义的规则, 不会影响已经在节点上运行着的pod 调度pod时优先考虑某些节点 这个功能是通过 preferredDuringSchedulingIgnoredDuringExecution 宇段来实现的\nnodeAffinity: preferredDuringSchedulingignoredDuringExecution: - weight: 80 preference: matchExpressions: - key: availability-zone operator: In values: - zone1 - weight: 20 preference: matchExpressions: - key: share-type operator: In values: - dedicated 使用pod亲缘性与非亲缘性对pod进行协同部署 上面主要涉及到pod和节点之间的亲缘性，这里介绍如何指定pod自身之间的亲缘性。\n使用pod间亲缘性将多个pod部署在同一个节点上 举例来说,想象一下你一个前端pod和一个后端pod, 将这些节点部署得比较靠近,可以降低延时,提高应用的性能。可以使用节点亲缘性规则来确保这两个pod被调度到同一个节点、同一个机架、同一个数据中心。但是,之后还需要指定调度到具体哪个节点、哪个机架或者哪个数据中心。因此,这不是一个最佳的解决方案。更好的做法应该是,让k8s将你的pod部署在任何它觉得合适的地方,同时确保2个pod是靠近的。这种功能可以通过pod亲缘性来实现。\n# 注意不是nodeAffinity podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernates.io/hostname labelSelector: matchLabels: app: backend 注意：除了使用简单的matchLabels字段, 也可以使用表达能力更强的matchExpressions字段。\n将pod部署在同一机柜、可用性区域或者地理地域 在同一个可用性区域中协同部署pod，需要将topologyKey属性设置为failure-domain.beta.kubernetes.io/zone\n在同一个地域中协同部署pod，需要将topologyKey属性设置为failure-domain.beta.kubernetes.io/region\ntopologyKey是如何工作的 topologyKey的工作方式很简单,可以任意设置自定义的键,唯一的前置条件就是,在节点上加上对应的标签。\n注意：在调度时,默认情况下,标签选择器只有匹配同一命名空间中的pod。但是,可以通过在label Selector同一级添加namespaces字段,实现从其他的命名空间选择pod的功能。\n表达pod亲缘性优先级取代强制性要求 podAffinity与nodeAffinity，都可以指定硬性限制（仅允许调度到特定节点或者pod）或者偏好（如果无法满足，则可以调度到其他地方）。\n利用pod的非亲缘性分开调度pod 有时候可能希望pod远离彼此，这种特性叫作pod非亲缘性。\n它和pod亲缘性的表示方式一样, 只不过是将podAffinity字段换成podAntiAffinity, 这将导致调度器永远不会选择那些有包含podAntiAffinity匹配标签的pod所在的节点\n下面的例子使用非亲缘性分散一个部署中的pod：\n# 一个前端pod必须不能调度到有app=frontend标签的pod运行的节点 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernates.io/hostname labelSelector: matchLabels: app: frontend 图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (18) 高级调度：污点、容忍度和亲缘性"},"/blog/2021/01/k8s_computing_resource_management/":{"data":{"":"","pod-qos等级#pod QoS等级":"当节点无法提供足量内存,哪个容器将被杀掉呢？k8s可能无法做出正确的决策。因此就需要一种方式, 通过这种方式可以指定哪种 pod 在该场景中优先级更高。k8s将pod 划分为3种QoS等级:\nBestEffort (优先级最低) Burstable Guaranteed (优先级最高) 定义pod的QoS等级 QoS等级不是通过独立的字段来分配，它来源于pod所包含的容器的资源requests和limits的配置。\n为pod分配BestEffort等级 最低优先级的QoS等级是BestEffort。会分配给那些没有(为任何容器)设置任何requests和limits的pod。\n为pod分配Guaranteed等级 与 Burstable 相对的是 Guaranteed 等级,会分配给那些所有资源request和limits 相等的 pod 。对于一个 Guaranteed 级别的pod,有以下几个条件:\nCPU和内存都要设置 requests 和 limits 每个容器都需要设置资源量 它们必须相等(每个容器的每种资源的requests和limits必须相等) 因为如果容器的资源 requests 没有显式设置,默认与limits相同,所以只设置所有资源(pod内每个容器的每种资源)的限制量就可以使pod的QoS等级为Guaranteed。这些 pod 的容器可以使用它所申请的等额资源,但是无法消耗更多的资源(因为它们的limits和requests相等)。\n为pod分配Burstable等级 Burstable QoS等级介于BestEffort和Guaranteed之间。其他所有的pod都属于这个等级。包括:\n容器的requests和limits不相同的单容器 pod 至少有一个容器只定义了requests 但没有定义limits的pod 一个容器的request limits 相等,但是另一个容器不指定requests或limits的pod。 Burstable pod可以获得它们所申请的等额资源,并可以使用额外的资源(不超过 limits)。\n单容器Pod的QOS等级 下面的表显示了基于资源requests和limits如何为单个容器Pod定义QoS等级。对于单容器pod,容器的QoS等级也适用于 pod 。\nCPU requests vs. limits 内 存的 requests vs. limits 容器 的 QoS 等级 未设置 未设置 BestEffort 未设置 Requests \u003c Limits Burstable 未设置 Requests = Limits Burstable Requests \u003c Limits 未设置 Burstable Requests \u003c Limits Requests \u003c Limits Burstable Requests\u003c Limits Requests = Limits Burstable Requests = Limits Requests = Limits Guaranteed 注意：如果设置了requests而没有设置limits,参考表中requests小于limits那一行。如果设置了limits,requests默认与 limits相等,因此参考request等于limits那一行\n多容器Pod的QOS等级 对千多容器pod, 如果所有的容器的QoS等级相同, 那么这个等级就是pod的QoS等级。如果至少有一个容器的QoS等级与其他不同,无论这个容器是什么等级, 这个pod的QoS等级都是Burstable等级。\n注意：运行kubectl describe pod以及通过pod的YAML/JSON描述的Status.qosClass字段都可以查看pod的QoS等级。\n内存不足时哪个进程会被杀死 等级不同的情况 BestEffort等级的pod首先被杀掉, 其次是Burstable pod, 最后是Guaranteed pod。Guaranteedpod只有在系统进程 需要内存时才会被杀掉。\n等级相同的情况 每个运行中的进程都有一个称为OutOfMemory (OOM)分数的值。系统通过比较所有运行进程的OOM分数来选择要杀掉的进程。当需要释放内存时, 分数最高的进程将被杀死。\nOOM分数由两个参数计算得出:进程已消耗内存占可用内存的百分比,与一个基于pod QoS等级和容器内存申请量固定的OOM分数调节因子。对于两个属于Burstable等级的单容器的pod, 系统会杀掉内存实际使用量占内存申请量比例更高的pod。","为pod中的容器申请资源#为pod中的容器申请资源":"创建一个pod时,可以指定容器对 CPU 和内存的资源请求量(即requests),以及资源限制量(即limits)。它是针对每个容器单独指定，pod对资源的请求量和限制量是所包含的所有容器的请求量和限制量之和。\napiVersion: v1 kind: Pod metadata: name: requests-pod spec: containers: - image: busybox command: [\"dd\", \"if=/dev/zero\", \"of=/dev/null\"] name: main resources: requests: cpu: 200m # 申请200毫核，即一个CPU核心的1/5时间 memory: 10Mi # 申请50MB内存 资源requests对调度的影响 资源requests指定了pod对资源需求的最小值。调度器在调度时只考虑那些未分配资源量满足pod需求量的节点。如果节点的未分配资源量小于pod需求量,这时节点没有能力提供pod对资源需求的最小量,因此k8s不会将该pod调度到这个节点。\n调度器在调度时并不关注各类资源在当前时刻的实际使用量,而只关心节点上部署的所有pod的资源申请量之和。尽管现有所有pod的资源实际使用量可能小于它的申请量,但如果使用基于实际资源消耗量的调度算法将打破系统为这些已部署成功的pod提供足够资源的保证。\n调度器如何利用pod requests为其选择最佳节点 调度器首先会对节点列表进行过滤，排除那些不满足需求的节点, 然后根据预先配置的优先级函数对其余节点进行排序。其中有两个基于资源请求量的优先级排序函数:\nLeastRequestedPriority：优先将pod调度到请求量少的节点上，也就是拥有更多未分配资源的节点 MostRequestedPriority：优先调度到请求量多的节点，拥有更少未分配资源的节点。 它们都只考虑资源请求量, 而不关注实际使用资源量。\n调度器只能配置一种优先级函数。\n配置调度器使用MostRequestedPriority函数, 可以在为每个pod提供足量CPU与内存资源的同时, 确保k8s使用尽可能少的节点。通过使pod紧凑地编排,一些节点可以保持空闲并可随时从集群中移除。\n查看节点资源总量 查看节点资源总量\n$ kubectl describe nodes Name: minikube ... # 节点的资源总量 Capacity: cpu: 2 memory: 2048484Ki pods: 110 # 可分配给pod的资源量 Allocatable: cpu: 2 memory: 1946084Ki pods: 110 ... 通过kubectl describe node命令的输出结果，可以检查节点已经分配的资源，找出为什么pod没有成功调度\nkubectl describe node CPU requests对CPU时间分配的影响 CPU requests不仅仅在调度时起作用,它还决定着剩余(未使用) 的CPU时间如何在pod之间分配。假设第一个pod请求了200毫核,另一个请求了1000毫核，那么未使用的CPU将按照1:5的比例来划分给这两个pod。\n另一方面,如果一个容器能够跑满CPU, 而另一个容器在该时段处于空闲状态,那么前者将可以使用整个CPU时间","为命名空间中的pod设置默认的requests和limits#为命名空间中的pod设置默认的requests和limits":"用户可以通过创建一个LimitRange资源来避免给每个容器分别配置。它不仅允许用户 (为每个命名空间)指定能给容器配置的每种资源的最小和最大限额, 还支持在没有显式指定资源 requests 时为容器设置默认值。\nLimitRange资源中的limits应用千同一个命名空间中每个独立的pod、容器或者其他类型的对象。它并不会限制这个命名空间中所有pod可用资源的总量, 总量是通过ResourceQuota对象指定的\napiVersion: v1 kind: LimitRange metadata: name: example spec: limits: # 指定整个pod资源的limits - type: Pod # 所有容器的CPU与内存请求量之和的最小值 min: cpu: 50m memory: 5Mi # 所有容器的CPU与内存请求量之和的最大值 max: cpu: 1 memory: 1Gi - type: Container # 容器没有指定CPU与内存请求量时设置的默认值 defaultRequest: cpu: 100m memory: 10Mi # 没有指定limits时设置的默认值 default: cpu: 200m memory: 100Mi # 容器CPU和内存的资源request和limits的最小值 min: cpu: 50m memory: 5Mi # 容器CPU和内存的资源request和limits的最大值 max: cpu: 1 memory: 1Gi # 每种资源requests与limits的最大比值 maxLimitRequestRatio: cpu: 4 memory: 10 # 请求PVC存储容量的最大值与最小值 - type: persistentVolumeClaim min: storage: 1Gi max: storage: 10Gi ","监控-pod-的资源使用量#监控 pod 的资源使用量":"设置合适的资源requests和limits对充分利用k8s节点资源来说非常重要。如果requests设置得太高,集群节点利用率就会比较低；如果设置得太低,应用就会处于CPU饥饿状态,甚至很容易被OOM Killer杀死。\n可以通过对容器在期望负载下的资源实际使用率进行监控来找到这个最佳配置\n收集、获取实际资源使用情况 Kubelet自身就包含了一个名为cAdvisor的agent,它会收集整个节点和节点上运行的所有单独容器的资源消耗情况。集中统计整个集群的监控信息需要运行一个叫作 Heapster的附加组件。\nHeapster以pod的方式运行在某个节点上,它通过普通的Kubernetes Service暴露服务,使外部可以通过一个稳定的IP地址访问。它从集群中所有的cAdvisor收集数据,然后通过一个单独的地址暴露。\n显示集群节点的CPU和内存使用量 显示节点的CPU和内存的实际使用量\nkubectl top node 显示单独pod的CPU和内存的实际使用量\nkubectl top node --all-namespaces 显示容器的CPU和内存的实际使用量\nkubectl top node --container 保存并分析历史资源的使用统计信息 一种方案是，使用 InfluxDB 来存储统计数据, 然后使用Grafana 对数据进行可视化和分析\n图书资料：\nhttps://book.douban.com/subject/30418855/ ","限制命名空间中的可用资源总量#限制命名空间中的可用资源总量":"ResourceQuota的接纳控制插件会检查将要创建的pod是否会引起总资源量超出ResourceQuota。如果那样,创建请求会被拒绝。资源配额只是在pod创建时进行检查,所以ResourceQuota对象仅仅作用于在其后创建的pod，并不影响已经存在的pod。\n为CPU和内存创建ResourceQuota apiVersion: v1 kind: ResourceQuota metadata: name: cpu-and-memory spec: hard: requests.cpu: 400m requests.memory: 200Mi limits.cpu: 600m limits.memory: 500Mi 与LimitRange一样,ResourceQuota对象应用于它所创建的那个命名空间。\n查看配额和配额使用情况：\nkubectl describe quota 为持久化存储指定配额 它也可以限制某个命名空间中最多可以声明的持久化存储总量\napiVersion: v1 kind: ResourceQuota metadata: name: storage spec: hard: # 可声明总存储量 requests.storage: 500Gi # SSD可声明的存储量 ssd.storageclass.storage.k8s.io/requests.storage: 300Gi standard.storageclass.storage.k8s.io/requests.storage: 1Ti 限制可创建对象的个数 资源配额同样可以限制单个命名空间中的pod、ReplicationController、Service以及其他对象的个数。\napiVersion: v1 kind: ResourceQuota metadata: name: objects spec: hard: pods: 10 replicationcontrollers: 5 secrets: 10 configmaps: 10 persistentvolumeclaims: 4 services: 5 services.loadbalancers: 5 services.nodeports: 5 ssd.storageclass.storage.k8s.io/persistentvolumeclaims: 2 为特定的pod状态或者QoS等级指定配额 Quota 可以被一组quota scopes限制。目前配额作用范围共有4种:\nBestEffort：应用于 BestEffort QoS 等级 NotBestEffort： 应用于除了BestEffort之外的 QoS等级，即Burstable和Guaranteed Termination：应用于配置了 activeDeadlineSeconds 的 pod NotTerminating：应用于那些没有指定activeDeadlineSeconds配置的 pod activeDeadlineSeconds属性定义了一个 pod 从开始尝试停止的时间到其被标记为 Failed 然后真正停止 之前,允许其在节点上继续运行的秒数。\n配额的范围也决定着配额可以限制的内容。BestEffort范围只允许限制pod个数,而其他3种范围除了pod个数,还可以限制 CPU和内存的requests和limits。","限制容器的可用资源#限制容器的可用资源":"设置容器可使用资源量的硬限制 CPU是一种可压缩资源,意味着我们可以在不对容器内运行的进程产生不利影响的同时,对其使用量进行限制\n内存是一种不可压缩资源。一旦系统为进程分配了一块内存,这块内存在进程主动释放之前将无法被回收。这就是为什么需要限制容器的最大内存分配量的根本原因。\ncontainers: - image: busybox ... resources: limits: cpu: 1 memory: 10Mi # 注意:因为这里没有指定资源requests,它将被设置为与资源limits相同的值 与资源requests不同的是,资源 limits 不受节点可分配资源量的约束。所有limits的总和允许超过节点资源总量的100%。换句话说,资源limits可以超卖。如果节点资源使用量超过100%,一些容器将被杀掉。\n当为一个容器设置 CPU 限额时,该进程只会分不到比限额更多的 CPU 而己。而内存却有所不同，当进程尝试申请分配比限额更多的内存时会被杀掉。如果 pod 的重启策略为 Always 或 OnFailure ,进程将会立即重启,因此用户可能根本察觉不到它被杀掉。但是如果它继续超限并被杀死, k8s会再次尝试重启,并开始增加下次重启的间隔时间。这种情况下用户会看到 pod 处于CrashLoopBackOff状态。\nCrashLoopBackOff 状态表示 Kubelet 还没有放弃,它意味着在每次崩溃之后,Kubelet 就会增加下次重启之前的间隔时间。 第一次崩渍之后, Kubelet立即重启容器, 如果容器再次崩溃, 会等待10秒钟后再重启。随着不断崩溃,延迟时间也会按照20、40、80、160秒以几何倍数增长,最终收敛在300秒。一旦间隔时间达到300秒, Kubelet将以5分钟为间隔时间对容器进行无限重启,直到容器正常运行或被删除。\n要定位容器crash的原因,可以通过查看pod日志以及kubectl describe pod命令。\n容器中的应用如何看待limits 在容器内看到的始终是节点的内存, 而不是容器本身的内存 在容器内看到的始终是节点的内存, 而不是容器本身的内存。即使你为容器设置了最大可用内存的限额, top 命令显示的是运行该容器的节点的内存数量, 而容器无法感知到此限制。\n对于Java程序来说这是个很大的问题，简单的设置 -Xmx 选项并不能解决问题，因为仅仅限制了堆大小,并不管其他 off-heap 内存。在新版本的Java 会考虑到容器 limits 以 缓解这个 问题\n容器内同样可以看到节点所有的 CPU 核 与内存完全一样,无论有没有配置 CPU limits, 容器内也会看到节点所有的CPU\nCPU limits 做的只是限制容器使用的 CPU 时间。\n一些程序通过查询系统 CPU 核数来决定启动工作线程的数量。同样在开发环境的笔记本电脑上运行良好,但是部署在拥有更多数量 CPU 的节点上,程序将快速启动大量线程,所有线程都会争夺(可能极其)有限的 CPU 时间。同时每个线程通常都需要额外的内存资源,导致应用的内存用量急剧增加。不要依赖应用程序从系统获取的 CPU 数量, 可能需要使用 Downward API 将 CPU 限额传递至容器并使用这个值。也可以通过 cgroup 系统直接获取配置的 CPU限制,请查看下面的文件:\n/sys/fs/cgroup/cpu/cpu.cfs_quota_us /sys/fs/cgroup/cpu/cpu.cfs_period_us "},"title":"Kubernetes in Action笔记 - (16) 计算资源管理"},"/blog/2021/01/k8s_node_security/":{"data":{"":"","podsecuritypolicy#PodSecurityPolicy":"什么是PodSecurityPolicy PodSecurityPolicy 是一种集群级别(无命名空间)的资源, 它定义了用户能否在 pod 中使用各种安全相关的特性。维护 PodSecurityPolicy 资源中配置策略的工作由集成在 API 服务器中的 PodSecurityPolicy 准入控制插件完成。\n当有人向 API 服务器发送 pod 资源时, PodSecurityPolicy 准入控制插件会将这个 pod 与已经配置的 PodSecurityPolicy 进行校验。如果这个 pod 符合集群中已有安全策略, 它会被接收并存入 etcd; 否则它会立即被拒绝。这个插件也会根据安全策略中配置的默认值对 pod 进行修改。\nPodSecurityPolicy 可以做的事： 一个 PodSecurityPolicy 资源可以定义以下事项:\n是否允许 pod 使用宿主节点的 PID、IPC、网络命名空间 pod 允许绑定的宿主节点端口 容器运行时允许使用的用户 ID 是否允许拥有特权模式容器的 pod 允许添加哪些内核功能, 默认添加哪些内核功能, 总是禁用哪些内核功能 允许容器使用哪些 SELinux 选项 容器是否允许使用可写的根文件系统 允许容器在哪些文件系统组下运行 允许 pod 使用哪些类型的存储卷 下面是一个 PodSecurityPolicy 样例，它阻止了 pod 使用宿主节点的 PID 、 IPC 、 网络命名空间, 运行特权模式的容器, 以及绑定大多数宿主节点的端口(除11 000-11000和13000-14000范围内的端口)。 它没有限制容器运行时使用的用户、用户组和SELinux 选项\napiVersion: externsions/v1beta1 kind: PodSecurityPolicy metadata: name: default spec: hostIPC: false hostPID: false hostNetwork: false hostPorts: - min: 10000 max: 11000 - min: 13000 max: 14000 privileged: false readOnlyRootFilesystem: true runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny supplementalGroups: rule: RunAsAny seLinux: rule: RunAsAny volumes: - '*' 注意: 修改策略对已经存在的pod无效,因为PodSecurityPolicy资原仅在创建和升级pod时起作用。\n可以使用命令查看当前PodSecurityPolicy\nkubectl get psp runAsUser、fsGroup 和 supplementalGroup 策略 上面的例子中，没有限制用户或者用户组。如果需要限制容器可以使用的用户和用户组ID, 可以将规则改为MustRunAs\nrunAsUser: rule: MustRunAs ranges: - min: 2 max: 2 runAsUser字段中还可以使用另一种规则: mustRunAsNonRoot。它将阻止用户部署以 root 用户运行的容器。在此种情况下,spec 容器中必须指定runAsUser字段,并且不能为0(0为root用户的ID),或者容器的镜像本身指定了用一个非0的用户ID 运行。\n配置允许、默认添加、禁止使用的内核功能 以下三个字段会影响容器可以使用的内核功能:\nallowedCapabilities defaultAddCapabilities requiredDropCapabilities apiVersion: externsions/v1beta1 kind: PodSecurityPolicy spec: # 允许的功能 allowedCapabilities: - SYS_TIME # 为容器自动添加的功能 defaultAddCapabilities: - CHOWN # 要求禁用的功能 requiredDropCapabilities: - SYS_ADMIN - SYS_MODULE ... 注意：SYS_ADMIN 功能允许使用一系列的管理操作; SYS_MODULE 功能允许加载或卸载Linux内核模块。\nallowedCapabilities字段用于指定 spec 容器的 securityContext.capabilities 中可以添加哪些内核功能。 defaultAddCapabilities字段中列出的所有内核功能将被添加到每个已 部署的 pod 的每个容器中 requiredDropCapabilities列出的内核功能会在所有容器中被禁用(PodSecurityPolicy 访问控制插件会在所有容器的 securityContext.capabilities.drop 宇段中加入这些功能〉 限制 pod 可以使用的存储卷类型 kind: PodSecurityPolicy spec: volumes: - emptyDir - configMap - secret - downwardAPI - persistentVolumeClaim 如果有多个 PodSecurityPolicy 资源, pod 可以使用 PodSecurityPolicy 中允许使用的任何一个存储卷类型(实际生效的是所有 volume 列表的并集〉。\n对不同的用户与组分配不同的 PodSecurityPolicy PodSecurityPolicy 是集群级别的资源,这意味着它不能存储和应用在某一特定的命名空间上。\n对不同用户分配不同 PodSecurityPolicy 是通过RBAC机制实现的。这个方法是,创建需要的 PodSecurityPolicy 资源,然后创建 ClusterRole 资源并通过名称将它们指向不同的策略,以此便 PodSecurityPolicy 资源中的策略对不同的用户或组生效。通过 ClusterRoleBinding 资源将特定的用户或组绑定到 ClusterRole上,当 PodSecurityPolicy 访问控制插件需要决定是否接纳一个 pod 时,它只会考虑、创建 pod 的用户可以访问到 的 PodSecurityPolicy 中的策略。","在pod中使用宿主节点的linux命名空间#在pod中使用宿主节点的Linux命名空间":"pod中的容器通常在分开的Linux命名空间中运行。 这些命名空间将容器中的进程与其他容器中,或者宿主机默认命名空间中的进程隔离开来。\n使用宿主节点的网络命名空间 部分pod(特别是系统pod)需要在宿主节点的默认命名空间中运行,以允许它们看到和操作节点级别的资源和设备。例如,某个pod可能需要使用宿主节点上的网络适配器,而不是自己的虚拟网络设备。这可以通过将pod spec中的hostNetwork设置为true实现。\n在这种情况下,这个pod可以使用宿主节点的网络接口,而不是拥有自己独立的网络。这意味着这个pod没有自己的IP地址;如果这个pod中的一某进程绑定了某个端口,那么该进程将被绑定到宿主节点的端口上。\n绑定宿主节点上的端口而不使用宿主节点的网络命名空间 这个功能可以让 pod 在拥有自己的网络命名空间的同时,将端口绑定到宿主节点的端口上。可以通过配置 pod 的spec.containers.ports字段中某个容器某一端口的 hostPort 属性来实现。\n不要混淆使用 hostPort 的 pod 和通过 Node Port 服务暴露的 pod。如果一个 pod 绑定了宿主节点上的一个特定端口,每个宿主节点只能调度-个这样的 pod 实例,因为两个进程不能绑定宿主机上的同一个端口。调度器在调度 pod 时会考虑这一点, 所以它不会把两个这样的 pod 调度到同一个节点上,\n使用宿主节点的 PID 与 IPC 命名空间 pod spec 中的 hostPID 和 host IPC 选项与 hostNetwork 相似。当它们被设 置为 true 时, pod 中的容器会使用宿主节点的 PID 和 IPC 命名空间,分别允许它们看到宿主机上的全部进程,或通过 IPC 机制与它们通信。","配置节点的安全上下文#配置节点的安全上下文":"除了让 pod 使用宿主节点的 Linux 命名空间,还可以在 pod 或其所属容器的描 述中通过 security-Context 选项配置其他与安全性相关的特性。这个选项可以 运用于整个 pod ,或者每个 pod 中单独的容器。\n配置安全上下文可以做很多事情:\n指定容器中运行进程的用户(用户ID)。 阻止容器使用 root 用户运行(容器的默认运行用户通常在其镜像中指定,所 以可能需要阻止容器以 root 用户运行)。 使用特权模式运行容器, 使其对宿主节点的内核具有完全的访问权限。 与以上相反,通过添加或禁用内核功能,配置细粒度的内核访问权限。 设置 SELinux （Security Enhanced Linux, 安全增强型 Linux）选项,加强对容器的限制。 阻止进程写入容器的根文件系统。 使用指定用户运行容器 为了使用一个与镜像中不同的用户 ID 来运行 pod, 需要设置该 pod 的securityContext.runAsUser 选项。\napiVersion: vl kind: Pod metaadata: name: pod-as-user-guest specL containers: - name: main image: alpine command: [\"/bin/sleep\", \"999999\"] securityContext: # 需要指明一个用户ID，而不是用户名 runAsUser: 405 阻止容器以 root 用户运行 可能安全隐患场景：假设有一个已经部署好的 pod，其在 daemon 用户下运行。如果攻击者获取了访问镜像仓库的权限, 井上传了一个标签完全相同, 在root用户下运行的镜像。当Kubernetes的调度器运行该pod的新实例时, kubelet会下载攻击者的镜像, 并运行该镜像中的任何代码。虽然容器与宿主节点基本上是隔离的,使用 root 用户运行容器中的进程仍然是一种不好的实践。例如,当宿主节点上的一个目录被挂载到容器中时,如果这个容器中的进程使用了 root 用户运行,它就拥有该目录的完整访问权限 ; 如果用非 root用户运行,则没有完整权限。\nrunAsNonRoot设置为true后，虽然pod它会被成功调度,但是不允许运行。\nsecurityContext: runAsNonRoot: true 使用特权模式运行 pod 有时 pod 需要做它们的宿主节点上能够做的任何事,例如操作被保护的系统设 备,或使用其他在通常容器中不能使用的内核功能。比如kube-proxy pod\nsecurityContext: privileged : true 为容器单独添加内核功能 相比于让容器运行在特权模式下以给予其无限的权限, 一个更加安全的做法是只给予它使用真正需要的内核功能的权限。Kubernetes允许为特定的容器添加内核功能, 或禁用部分内核功能, 以允许对容器进行更加精细的权限控制, 限制攻击者潜在侵入的影响。\n比如。如果需要允许容器修改系统时间, 可以在容器的capabilities里add一项名为CAP_SYS_TIME的功能\nsecurityContext: capabilities: add: - SYS_TIME 注意:\nLinux内核功能的名称通常以CAP_开头。但在pod spec中指定内核功能时,必须省略CAP_前缀。 可以在Linux手册中查阅Linux内核功能列表。 在容器中禁用内核功能 在容器的securityContext.capabilities.drop列表中添加禁用的功能\nsecurityContext: capabilities: drop: - CHOWN 阻止对容器根文件系统的写入 为了增强安全性, 请将在生产环境运行的容器的readOnlyRootF且esystem选项设置为true。\nsecurityContext: readOnlyRootFilesystem: true 设置pod级别的安全上下文 以上的例子都是对单独的容器设置安全上下文。 这些选项中的一部分也可以从pod级别设定(通过pod.spec.securityContext属性)。 它们会作为pod中每一个容器的默认安全上下文, 但是会被容器级别的安全上下文覆盖\n容器使用不同用户运行时共享存储卷 k8s允许为pod中所有容器指定supplemental组,以允许它们无论以哪个用户ID运行都可以共享文件。这可以通过以下两个属性设置:\nfsGroup supplementalGroups apiVersion: v1 kind: Pod metadata: name: pod-with-shared-volume-fsgroup spec: securityContext: # 这两个属性在pod级别 fsGroup: 555 supplementalGroups: [666,777] containers: - name: first image: alpine command: [\"/bin/sleep\", \"999999\"] securityContext: runAsUser: 1111 # 第一个容器使用的用户ID为1111 volumeMounts: - name: shared-volume # 两个容器使用同一个存储卷 mountPath: /volume readonly: false - name: second image: alpine command: [\"/bin/sleep\", \"999999\"] securityContext: runAsUser: 2222 # 第二个容器使用的用户ID为2222 volumeMounts: - name: shared-volume # 两个容器使用同一个存储卷 mountPath: /volume readonly: false volumes: - name: shared-volume emptyDir: ","隔离pod的网络#隔离pod的网络":"通过限制 pod 可以与其他哪些 pod 通信，来确保 pod 之间的网络安全。\n是否可以进行这些配置取决于集群中使用的容器网络插件。如果网络插件支持，可以通过 NetworkPolicy 资源配置网络隔离 。\n一个 NetworkPolicy 会应用在匹配它的标签选择器的 pod 上，指明这些允许访问这些 pod 的源地址,或这些 pod 可以访问的目标地址。这些分别由入向(ingress)和出向(egress)规则指定。这两种规则都可以匹配由标签选择器选出的 pod ,或者一个 namespace 中的所有 pod，或者通过无类别域间路由(Classless Inter-DomainRouting, CIDR )指定的 IP 地址段。\n注意：入向规则与Ingress资源无关\n在一个命名空间中启用网络隔离 在默认情况下, 某一命名空间中的 pod 可以被任意来源访问。\n下面这个例子中，在任何一个特定的命名空间中创建该 NetworkPolicy 之后,任何客户端都不能访问该命名空间中的 pod 。\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny spec: # 空的标签选择器匹配命名空间中所有pod podSelector: 注意：集群中的 CNI 插件或其他网络方案需要支持 NetworkPolicy ,否则 NetworkPolicy 将不会影响 pod 之间的可达性。\n允许同一命名空间中的部分pod访问一个服务端pod 为了允许同一命名空间中的客户端pod访问该命名空间的pod,需要指明哪些pod可以访问。\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: postgres-netpolicy spec: podSelector: matchLabels: app: database ingress: - from: # 只允许指定标签与端口的pod访问 - podSelector: matchLabels: app: webserver ports: - port: 5432 在不同 Kubernetes 命名空间之间进行网络隔离 存在一种情况，多个租户使用同一Kubernetes集群。每个租户有多个命名空间，每个命名空间中有一个标签指明它们屈于哪个租户。\napiVervsion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: shoppingcart-netpolicy spec: # 该策略应用于有app=shopping-cart标签的pod podSelector: matchLabels: app: shopping-cart ingress: - from: # 只有在具有tenant=manning标签的命名空间中运行的pod可以访问该服务 - namespaceSelector: matchLabels: tenant: manning ports: - port: 80 注意：在多租户的Kubernetes集群中,通常租户不能为他们的命名空间添加标签(或注释)。否则,他们可以规避基于namespaceSelector的入向规则。\n使用CIDR隔离网络 可以通过CIDR表示法指定一个IP段来隔离网络\ningress: - from: - ipBlock: cidr: 192.168.1.0/24 限制pod的对外访问流量 可以通过出向规则限制pod的对外访问流量\nspec: podSelector: matchLabels: app: webserver egress: - to: - podSelector: matchLabels: app: database 图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (15) 节点与网络安全"},"/blog/2021/01/k8s_pod_auto_scaling/":{"data":{"":"注意：Kubernetes的自动伸缩特性在1.6与1.7版本之间经历了一次重写, 因此网上关于此方面的内容有可能已经过时了。","pod的横向自动伸缩#pod的横向自动伸缩":"自动伸缩步骤 横向pod自动伸缩是指由控制器管理的pod副本数量的自动伸缩。它由Horizontal控制器执行, 通过创建一个HorizontalpodAutoscaler(HPA)资源来启用和配置Horizontal控制器。该控制器周期性检查pod度量,计算满足HPA资源所配置的目标数值所需的副本数量, 进而调整目标资源(如Deployment、ReplicaSet、 ReplicationController、 StatefulSet等)的replicas字段。\n自动伸缩的过程可以分为三个步骤:\n获取被伸缩资源对象所管理的所有pod度量。 计算使度量数值到达(或接近)所指定目标数值所需的pod数量。 更新被伸缩资源的replicas字段。 获取pod度量 pod与节点度量数据是由运行在每个节点的kubelet之上, 名为cAdvisor的agent采集的;这些数据将由集群级的组件Heapster聚合。\nAutoscaler本身并不负责采集pod度量数据，HPA控制器向Heapster发起REST调用来获取所有pod度量数据。\n关于Autoscaler采集度量数据方式的改变 在Kubernetes 1.6版本之前,HPA直接从Heapster采集度量。在1.8版本中,如果用–horizontal-pod-autoscaler-use-rest-clients=true参数启动ControllerManager, Autoscaler就能通过聚合版的资源度量API拉取度量了。该行为从1.9版本开始将变为默认。核心API服务器本身并不会向外界暴露度量数据。从1.7版本开始,k8s允许注册多个API服务器并使它们对外呈现为单个API服务器。这允许k8s通过这些底层API服务器之一来对外暴露度量数据。\n集群管理员负责选择集群中使用何种度量采集器。通常需要一层简单的转换组件将度量数据以正确的格式暴露在正确的API路径下。\n计算所需的pod数量 一旦Autoscaler获得了它所调整的资源(Deployment、 ReplicaSet、ReplicationController或StatefulSet)所辖pod的全部度量, 它便可以利用这些度量计算出所需的副本数量。它需要计算出一个合适的副本数量, 以使所有副本上度量的平均值尽量接近配置的目标值。该计算的输入是一组pod度量(每个pod可能有多个), 输出则是一个整数(pod副本数量)。\n更新被伸缩资源的副本数 自动伸缩操作的最后一步是更新被伸缩资源对象(比如ReplicaSet)上的副本数字段, 然后让ReplicaSet控制器负责启动更多pod或者删除多余的pod。\nAutoscaler控制器通过Scale子资源来修改被伸缩资源的replicas字段，这样Autoscaler不必了解它所管理资源的细节。\n目前暴露了Scale子资源的资源有:\nDeployment ReplicaSet ReplicationController StatefulSet 基于CPU使用率进行自动伸缩 因为CPU使用通常是不稳定的, 比较靠谱的做法是在CPU被压垮之前就横向扩容。\n注意：一定把目标CPU使用率设置得远远低于100%预留充分空间给突发的流量洪峰。\nAutoscaler对比pod的实际CPU使用与它的请求, 这意味着需要给被伸缩的pod设置CPU请求,不管是直接设置还是通过LimitRange对象间接设置，这样Autoscaler才能确定CPU使用率。\n基于CPU使用率创建HPA 先创建一个Deployment\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: kubia spec: replicas: 3 template: metadata: name: kubia label: app: kubia spec: containers: - image: luksa:kubia:v1 name: nodejs resources: # 需要设定CPU请求量 requests: cpu: 100m 为了给pod启用横向自动伸缩, 需要创建一个HorizontalpodAutoscaler (HPA)对象, 并把它指向该Deployment。\n可以使用kubectl autoscale命令, 这个相对简单点\nkubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5 或者使用YAML文件\napiVersion: autoscaling/v2beta1 kind: HorizontalPodAutoscaler metadata: name: kubia spec: maxReplicas: 5 metrics: - resource: name: cpu targetAverageUtilization: 30 type: Resource minReplicas: 1 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment metadata: name: kubia 注意：一定要确保自动伸缩的目标是Deployment而不是底层的ReplicaSet。这样才能确保预期的副本数量在应用更新后继续保持(记着Deployment会给每个应用版本创建一个新的ReplicaSet)。手动伸缩也是同样的道理。\n伸缩操作的最大速率 Autoscaler 两次扩容操作之间的时间间隔有限制。目前,只有当3分钟内没有任何伸缩操作时才会触发扩容,缩容操作频率更低,为5分钟\n基于内存使用进行自动伸缩 基于内存的自动伸缩比基于CPU的困难很多。主要原因在于,扩容之后原有的pod需要有办法释放内存。这只能由应用完成,系统无法代劳。系统所能做的只有杀死并重启应用,希望它能比之前少占用一些内存;但如果应用使用了跟之前一样多的内存,Autoscaler就会扩容、扩容,再扩容,直到达到HPA资源上配置的最大pod数量。显然没有人想要这种行为。\n基于内存使用的自动伸缩在Kubernetes 1.8中得到支持,配置方法与基于CPU的自动伸缩完全相同。\n基于其他自定义度量进行自动伸缩 metrics字段允许定义多个度量供使用。HPA支持3种类型的度量：Resource, Pods, Object\nResource: 基于一个资源度量做出自动伸缩决策。比如上面的CPU，内存 Pods：用来引用任何其他种类的(包括自定义的)与 pod 直接相关的度量。比如：每秒查询次数,或者消息队列中的消息数量(当消息队列服务运行在pod之中)都属于这种度量 Object: 用来让Autoscaler基于并非直接与pod关联的度量来进行伸缩。比如, 基于另一个集 群对象(例如Ingress对象）,来伸缩你的pod ","pod的纵向自动伸缩#pod的纵向自动伸缩":"并不是所有应用都能被横向伸缩。对这些应用而言,唯一的选项是纵向伸缩，也就是给它们更多CPU或内存。\n但是作者在写书的时候，还未实现。\n图书资料：\nhttps://book.douban.com/subject/30418855/ "},"title":"Kubernetes in Action笔记 - (17) 自动横向伸缩pod与集群节点"},"/blog/2021/01/manjaro_set_default_java_version/":{"data":{"":"如果本机装了多个java版本，会有一个默认的java版本。随着java版本的不断升级，一些新的工具会要求高版本的java，否则无法运行。这个时候，就需要修改默认的java版本。\n查看当前的java版本\n$ java -version openjdk version \"11.0.10\" 2021-01-19 OpenJDK Runtime Environment (build 11.0.10+8) OpenJDK 64-Bit Server VM (build 11.0.10+8, mixed mode) 命令查看已安装的java版本\n$ archlinux-java status Available Java environments: java-11-openjdk (default) java-15-openjdk java-8-openjdk 设置新的默认版本\nsudo archlinux-java set java-15-openjdk 再次查看当前的java版本，可以发现已经变更\n$ java -version openjdk version \"15.0.1\" 2020-10-20 OpenJDK Runtime Environment (build 15.0.1+9) OpenJDK 64-Bit Server VM (build 15.0.1+9, mixed mode) "},"title":"Manjaro设置默认Java版本"},"/blog/2021/01/mybatis_set_schema/":{"data":{"":"由于业务的需要，在查询的时候，需要动态地在SQL语句中指定schema。在mybatis的的查询语句中，可以使用 ${schemaName}。注意，必须要用$, 而不是#\nSET search_path TO ${schemaName}; select * from foo where bar = #{bar}; "},"title":"MyBatis查询中动态指定schema"},"/blog/2021/01/postgres_copy_table_schema/":{"data":{"":"在创建临时数据表的时候会有用\ncreate table if not exists foo as (select * from bar) with no data; "},"title":"Postgres通过SQL语句复制表结构"},"/blog/2021/01/python_copy_data_between_two_postgres/":{"data":{"":"在python脚本中，通过 psycopg2 库的copy_expert，可以很方便地在两个Postgres数据库之间复制数据\ns = StringIO() # Export into memory buffer sql = \"\"\" COPY (select * from foo) TO STDOUT WITH CSV HEADER ENCODING 'UTF8'; \"\"\" sourceCursor = sourceConn.cursor() sourceCursor.copy_expert(sql, s) # Import from memory buffer to destination database sql = \"\"\" COPY bar from STDIN WITH CSV HEADER ENCODING 'UTF8'; \"\"\" destinationCursor = destinationConn.cursor() destinationCursor.copy_expert(sql, s) 参考：\nhttps://www.psycopg.org/docs/cursor.html#cursor.copy_expert "},"title":"使用Python在两个Postgres数据库直接复制数据"},"/blog/2021/02/es_search_improvement/":{"data":{"":"","优化前后的性能对比#优化前后的性能对比":"通过Grafana的监控数据，可以很明显地看出优化的效果。\n切换新旧方案的瞬间 切换新旧方案的瞬间，可以看到查询耗时断崖式减少\n平峰时期CPU使用率对比 优化前平均40%左右\n优化后平均5%\n高峰时期CPU使用率对比 优化前平均82%，最高98%\n优化后平均15%\n平峰时期查询耗时对比 优化前平均3.2s\n优化后9ms\n高峰时期查询耗时对比 优化前平均7.8s，最高13.24s\n优化后平均32ms","背景#背景":"由于系统中的订单量大，一些查询语句需要级联多张表来查询，单纯靠数据库的索引已经无法满足查询速度与用户界面响应速度的要求，因此在5年前引入了ES来加快查询速度。但是，原先的方案中ES存放的是全量的订单数据，并且是存放在同一个数据库索引中，随着业务的发展与订单量的累积，ES查询的速度已经越来越慢。通过Grafana监控数据，可以看到单个索引的数据量已达到1.5TB，主要的性能指标越来越差。ES的CPU使用率不时地大于80%，甚至100%，导致极端情况下ES查询耗时十几秒。对于用户的直观感受就是，在界面上面查询数据，需要耗时很久才能看到数据。","解决方案#解决方案":"系统总是慢慢演变的，某个时间点的解决方案都是基于当前的一些情况，满足近3年内的需求就足够了。考虑到成本问题，尽可能在不增加硬件投入的情况下，找到节省时间的优化方案。\n在原先的方案中，索引中有1.5TB的数据量。从1.5TB的数据集里面查找数据，会很耗时间。由于系统中大部分的操作都是根据公司来区分的，所以如果把ES里面的数据，按照公司来拆分成不同的索引，某个公司查询订单的时候，仅仅查询它自己公司的索引。拆分成若干个索引之后，最大的一个索引不到3GB，小的一些索引就100多MB。由于单个公司索引的数据量很小，查询速度自然就比原先快了。\n系统中也存在一些查询，需要跨公司来查数据，但是这些查询有个特点，它们仅仅需要查最近一定时间范围内的数据，比如半年之内。对于这些数据，可以再专门建一个ES索引来存放，同时有个后台的Job，定期删除过期的数据。这样，就可以控制该索引的总数据量在一定的范围之内，不会因为数据量多大的原因导致查询变慢。\n当然，在写代码实现的时候还需要考虑很多具体的问题，比如：\n修改原先ES数据实时同步方案，支持根据公司ID写入到不同的索引 修改原先ES数据全量加载方案，支持根据公司ID写入到不同的索引 修改原先ES数据查询方案，支持根据公司ID从不同的索引读取数据 修改ES查询相关设置参数的实现逻辑，比如某个公司是否开启ES，开启ES的走ES查询，不开启ES的走数据库查询。 需要考虑到将来的扩展性，如何更合理的接口 原先的java ES库的某些操作不支持显式指定index名称，需要继承该库中的一些类并重写方法 在过渡阶段，让系统支持新旧两种的查询方式，不需要重启服务，仅通过修改配置就可以实现无缝切换。这样的话，如果由于新方案中，代码有bug，可以直接通过修改配置切换到旧的方式，bug修复后再切换成新的。等到新方案的上线一定的时间，稳定之后，再移除旧方案的代码 "},"title":"订单ES查询性能优化"},"/blog/2021/02/java7_gramma_new_features/":{"data":{"":" ","switch-语句支持字符串变量#switch 语句支持字符串变量":"之前在switch中只能使用number或enum，Java 7开始支持string。\nString s = \"a\"; switch (s) { case \"a\": System.out.println(\"is a\"); break; case \"b\": System.out.println(\"is b\"); break; default: System.out.println(\"is c\"); break; } ","try-with-resources-语句#try-with-resources 语句":"Java 7之前对某些资源的操作是需要手动关闭，如InputStream，Writes，Sockets，Sql等，这些需要在finally语句中进行关闭资源的操作。\nOutputStream fos = null; try { fos = new FileOutputStream(\"/tmp/file\"); } finally { fos.close(); } 从Java 7开始, 在采用try-with-resources方式后，它会自动释放资源, 不需要再次声明流的关闭。可以使用try-with-resources的资源有： 任何实现了java.lang.AutoCloseable接口或者java.io.Closeable接口的对象。这里Closeable继承了AutoCloseable。\npublic interface Closeable extends AutoCloseable 从Java 7开始可以把上面例子中的代码改写成下面的形式\ntry(OutputStream fos = new FileOutputStream(\"/tmp/file\");) { // 不需要再次指明fos.close(); } ","二进制数字表达方式#二进制数字表达方式":"在Java 7之前，支持十进制（123）、八进制（0123）、十六进制（0X12AB）的表示形式。Java 7中增加支持二进制的表示（0B11110001、0b11110001）\nint binary = 0b0001_1001; System.out.println(\"binary is :\" + binary); 输出\nbinary is :25 ","使用下划线对数字进行分隔表达#使用下划线对数字进行分隔表达":"Java 7中支持在数字中间增加’_‘作为分隔符，分隔长int以及long（也支持double,float），显示更直观，如（12_123_456）。\n下划线只能在数字中间，编译时编译器自动删除数字中的下划线。\nint intOne = 1_000_000; long longOne = 1_000_000; double doubleOne = 1_000_000; float floatOne = 1_000_000; ","同时捕获多个异常处理#同时捕获多个异常处理":"Java 7以前在一个方法抛出多个异常时，只能一个个的catch\ntry { result = field.get(obj); } catch (IllegalArgumentException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } Java 7开始支持一个catch语句中包含多个异常类型，用\"|“隔开。\ntry { result = field.get(obj); } catch (IllegalArgumentException | IllegalAccessException e) { e.printStackTrace(); } 参考：\nhttps://www.oschina.net/news/20119/new-features-of-java-7 https://blog.csdn.net/u014209205/article/details/79718689 ","泛型实例创建的类型推断#泛型实例创建的类型推断":"运用泛型实例化类型自动推断，对通用实例创建(diamond)的type引用进行了改进，语法更加简洁\n// Java 7 之前的写法 List\u003cString\u003e list = new ArrayList\u003cString\u003e(); // Java 7 开始支持的写法 List\u003cString\u003e list = new ArrayList\u003c\u003e(); "},"title":"Java 7新特性 - (1)Java语法特性"},"/blog/2021/02/java8_lambda/":{"data":{"":" ","lambda-表达式与匿名类的区别#Lambda 表达式与匿名类的区别":"使用匿名类与 Lambda 表达式的一大区别在于关键词的使用。对于匿名类，关键词 this 解读为匿名类，而对于 Lambda 表达式，关键词 this 解读为写就 Lambda 的外部类。\nLambda 表达式与匿名类的另一不同在于两者的编译方法。Java 编译器编译 Lambda 表达式并将他们转化为类里面的私有函数，它使用 Java 7 中新加的 invokedynamic 指令动态绑定该方法\n参考：\nhttp://blog.oneapm.com/apm-tech/226.html https://www.runoob.com/java/java8-lambda-expressions.html ","为什么java需要lambda表达式#为什么Java需要Lambda表达式?":"在函数式编程语言中，函数是一等公民，它们可以独立存在，你可以将其赋值给一个变量，或将他们当做参数传给其他函数。JavaScript是最典型的函数式编程语言。函数式语言提供了一种强大的功能——闭包，相比于传统的编程方法有很多优势，闭包是一个可调用的对象，它记录了一些信息，这些信息来自于创建它的作用域。\nJava现在提供的最接近闭包的概念便是Lambda表达式，虽然闭包与Lambda表达式之间存在显著差别，但至少Lambda表达式是闭包很好的替代者。\nLambda表达式为Java添加了缺失的函数式编程特点，它与闭包不同，但是又无限地接近闭包。在支持一类函数的语言中，Lambda 表达式的类型将是函数。但是，在Java中，Lambda表达式是对象，他们必须依附于一类特别的对象类型——函数式接口(functional interface)。","函数式接口#函数式接口":"在Java中，Marker（标记）类型的接口是一种没有方法或属性声明的接口，也就是空接口。相似地，函数式接口是只包含一个抽象方法声明的接口。比如java.lang.Runnable就是一种函数式接口，在Runnable接口中只声明了一个方法 void run()。\n每个Lambda表达式都能隐式地赋值给函数式接口，例如，可以通过Lambda表达式创建 Runnable 接口的引用。\nRunnable r = () -\u003e System.out.println(\"hello world\"); 当不指明函数式接口时，编译器会自动解释这种转化。下面的代码中，编译器会自动推断：根据线程类的构造函数签名 public Thread(Runnable r) { }，将该 Lambda 表达式赋给 Runnable 接口。\nnew Thread( () -\u003e System.out.println(\"hello world\") ).start(); @FunctionalInterface 是 Java 8 新加入的一种接口，用于指明该接口类型声明是根据 Java 语言规范定义的函数式接口。Java 8 还声明了一些 Lambda 表达式可以使用的函数式接口，当你注释的接口不是有效的函数式接口时，可以使用 @FunctionalInterface 解决编译层面的错误。\n以下是一种自定义的函数式接口：\n@FunctionalInterface public interface WorkerInterface { public void doSomeWork(); } 根据定义，函数式接口只能有一个抽象方法，如果你尝试添加第二个抽象方法，将抛出编译时错误。例如：\n@FunctionalInterface public interface WorkerInterface { public void doSomeWork(); public void doSomeMoreWork(); } 错误： Unexpected @FunctionalInterface annotation @FunctionalInterface ^ WorkerInterface is not a functional interface multiple non-overriding abstract methods found in interface WorkerInterface 1 error ","变量作用域#变量作用域":"Lambda 表达式只能引用标记了 final 的外层局部变量，这就是说不能在Lambda内部修改定义在域外的局部变量，否则会编译错误。\npublic class Java8Tester { final static String salutation = \"Hello! \"; public static void main(String args[]){ GreetingService greetService1 = message -\u003e System.out.println(salutation + message); greetService1.sayMessage(\"Runoob\"); } interface GreetingService { void sayMessage(String message); } } 以上代码输出结果为：\nHello! Runoob 也可以直接在 Lambda 表达式中访问外层的局部变量：\npublic class Java8Tester { public static void main(String args[]) { final int num = 1; Converter\u003cInteger, String\u003e s = (param) -\u003e System.out.println(String.valueOf(param + num)); s.convert(2); // 输出结果为 3 } public interface Converter\u003cT1, T2\u003e { void convert(int i); } } Lambda 表达式的局部变量可以不用声明为 final，但是必须不可被后面的代码修改（即隐性的具有 final 的语义）\n将上面代码修改一下：\npublic class Java8Tester { public static void main(String args[]) { int num = 1; Converter\u003cInteger, String\u003e s = (param) -\u003e System.out.println(String.valueOf(param + num)); s.convert(2); num = 5; } public interface Converter\u003cT1, T2\u003e { void convert(int i); } } 可以看到报错信息\nLocal variable num defined in an enclosing scope must be final or effectively final 在 Lambda 表达式当中不允许声明一个与局部变量同名的参数或者局部变量。\nString first = \"\"; Comparator\u003cString\u003e comparator = (first, second) -\u003e Integer.compare(first.length(), second.length()); //编译会出错 ","表达式举例#表达式举例":"线程 //旧方法: new Thread(new Runnable() { @Override public void run() { System.out.println(\"Hello from thread\"); } }).start(); //新方法: new Thread( () -\u003e System.out.println(\"Hello from thread\") ).start(); 事件处理 //旧方法 button.addActionListener(new ActionListener() { @Override public void actionPerformed(ActionEvent e) { System.out.println(\"The button was clicked using old fashion code!\"); } }); //新方法 button.addActionListener( (e) -\u003e { System.out.println(\"The button was clicked. From Lambda expressions !\"); }); 遍历元素 以下代码的作用是打印出给定数组中的所有元素。注意，使用 Lambda 表达式的方法不止一种。在下面的例子中，我们先是用常用的箭头语法创建 Lambda 表达式，之后，使用 Java 8 全新的双冒号(::)操作符将一个常规方法转化为 Lambda 表达式：\n//Old way: List\u003cInteger\u003e list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); for(Integer n: list) { System.out.println(n); } //New way: List\u003cInteger\u003e list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); list.forEach(n -\u003e System.out.println(n)); //or we can use :: double colon operator in Java 8 list.forEach(System.out::println); 在下面的例子中，我们使用断言(Predicate)函数式接口创建一个测试，并打印所有通过测试的元素\nimport java.util.Arrays; import java.util.List; import java.util.function.Predicate; public class Main { public static void main(String [] a) { List\u003cInteger\u003e list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); System.out.println(\"Print all numbers:\"); evaluate(list, (n)-\u003etrue); System.out.println(\"Print no numbers:\"); evaluate(list, (n)-\u003efalse); System.out.println(\"Print even numbers:\"); evaluate(list, (n)-\u003e n%2 == 0 ); System.out.println(\"Print odd numbers:\"); evaluate(list, (n)-\u003e n%2 == 1 ); System.out.println(\"Print numbers greater than 5:\"); evaluate(list, (n)-\u003e n \u003e 5 ); } public static void evaluate(List\u003cInteger\u003e list, Predicate\u003cInteger\u003e predicate) { for(Integer n: list) { if(predicate.test(n)) { System.out.println(n + \" \"); } } } } 输出\nPrint all numbers: 1 2 3 4 5 6 7 Print no numbers: Print even numbers: 2 4 6 Print odd numbers: 1 3 5 7 Print numbers greater than 5: 6 7 ","语法#语法":"Java中的Lambda表达式通常使用 (argument) -\u003e (body) 语法书写，例如：\n(arg1, arg2...) -\u003e { body } (type1 arg1, type2 arg2...) -\u003e { body } 下面是一些例子:\n(int a, int b) -\u003e { return a + b; } () -\u003e System.out.println(\"Hello World\"); (String s) -\u003e { System.out.println(s); } () -\u003e 42 () -\u003e { return 3.1415 }; Lambda表达式的结构:\n一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断。例如：(int a)与(a)效果相同 所有参数需包含在圆括号内，参数之间用逗号相隔。例如：(a, b) 或 (int a, int b) 或 (String a, int b, float c) 空圆括号代表参数集为空。例如：() -\u003e 42 当只有一个参数，且其类型可推导时，圆括号（）可省略。例如：a -\u003e return a*a Lambda 表达式的主体可包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号{}可省略。匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，则表达式必须包含在花括号{}中（形成代码块）。匿名函数的返回类型与代码块的返回类型一致，若没有返回则为空 "},"title":"Java 8新特性 - (1)Lambda表达式"},"/blog/2021/02/python_push_url_to_baidu/":{"data":{"":"SEO对于网站的推广很重要，大多数搜索引擎都提供了一些API用于给站长主动提交URL，加快网页被收录的速度。\n百度提供了快速收录的API接口，下面这个Python脚本可以用来读取本地磁盘中的sitemap.xml文件，并调用接口提交URL至百度。\n仅需要修改下面的参数：\nlastUpdateTimeStr - 上次推送的时间。会与sitemap.xml中的时间做比较，仅推送在该时间之后更新的URL siteMapPath - sitemap.xml在本地磁盘上的存放路径 siteUrl - 网站地址 baiduApiToken - Baidu API的token tmpFile - 临时文件的保存地址 ignorePathPrefixes - 需要忽略的URL的前缀 #!/usr/bin/env python3 # coding: utf-8 import xml.etree.ElementTree as ET from datetime import datetime import os ### Methods ######### def stripNs(el): # Recursively search this element tree, removing namespaces. if el.tag.startswith(\"{\"): el.tag = el.tag.split('}', 1)[1] # strip namespace for k in el.attrib.keys(): if k.startswith(\"{\"): k2 = k.split('}', 1)[1] el.attrib[k2] = el.attrib[k] del el.attrib[k] for child in el: stripNs(child) ### Arguments to change #### lastUpdateTimeStr='2021-01-26T00:00:00+08:00' siteMapPath='public/sitemap.xml' siteUrl='https://www.zengxi.net' baiduApiToken='faketoken' tmpFile=\"/tmp/submitSiteMap\" ignorePathPrefixes=[ 'https://www.zengxi.net/archives/', 'https://www.zengxi.net/categories/', 'https://www.zengxi.net/links/', 'https://www.zengxi.net/posts/', 'https://www.zengxi.net/series/', 'https://www.zengxi.net/tags/' ] ### CONSTANTS ### SITEMAP_DATETIME_FORMAT='%Y-%m-%dT%H:%M:%S%z' lastUpdateTime=datetime.strptime(lastUpdateTimeStr, SITEMAP_DATETIME_FORMAT) tree = ET.parse(siteMapPath) urlset = tree.getroot() with open(tmpFile, 'w') as f: for url in urlset: location = '' lastmod = lastUpdateTime for urlChild in url: stripNs(urlChild) if urlChild.tag == 'loc': location = urlChild.text elif urlChild.tag == 'lastmod': lastmod = datetime.strptime(urlChild.text, SITEMAP_DATETIME_FORMAT) ignore = False for prefix in ignorePathPrefixes: if location.startswith(prefix): ignore = True break if ignore: continue if lastmod \u003e= lastUpdateTime: f.write(location + '\\n') command=\"\"\" curl -H 'Content-Type:text/plain' --data-binary @{filePath} \"http://data.zz.baidu.com/urls?site={siteUrl}\u0026token={token}\" \"\"\" commandToExecute=command.format(filePath=tmpFile, siteUrl=siteUrl, token=baiduApiToken) tmpres = os.popen(commandToExecute).readlines() print(commandToExecute) print(tmpres) "},"title":"用Python读取sitemap并调用百度接口推送URL"},"/blog/2021/03/cxf_ws_log/":{"data":{"":"cxf本身就支持日志功能，能打印传入传出的soap报文，但是需要配置一下。\n这里配置的是cxf结合spring做的WebService，配置步骤如下：\n在spring配置文件中的jaxws:endpoint节点下配置日志拦截器 \u003cimport resource=\"classpath:META-INF/cxf/cxf.xml\" /\u003e \u003cimport resource=\"classpath:META-INF/cxf/cxf-extension-soap.xml\" /\u003e \u003cimport resource=\"classpath:META-INF/cxf/cxf-servlet.xml\" /\u003e \u003c!-- 配置的cxf web service的地址 --\u003e \u003cjaxws:endpoint id=\"searchReq11\" implementor=\"com.iflytek.server.HelloImpl\" address=\"/SearchReqService.asmx\"\u003e \u003cjaxws:inInterceptors\u003e \u003cbean class=\"org.apache.cxf.interceptor.LoggingInInterceptor\" /\u003e \u003c/jaxws:inInterceptors\u003e \u003cjaxws:outInterceptors\u003e \u003cbean class=\"org.apache.cxf.interceptor.LoggingOutInterceptor\" /\u003e \u003c/jaxws:outInterceptors\u003e \u003c/jaxws:endpoint\u003e 具体的日志输出目录（3种方式）。需要注意,下面的3种方式优先级从低到高： 什么也不配置，使用java原生的java.util.logging.Logger记录日志。日志文件为Tomcat的logs/catalina.xxxx-xx-xx.log 配置使用slf4j+log4j。cxf默认为使用slf4j记录日志。所以在项目中引入slf4j的jar包即可。如果同时引入log4j则使用log4j记录日志，如果同时引入jcl则使用jcl记录日志。 直接使用log4j记录日志。在项目的类加载路径下创建目录META-INF/cxf/，然后在目录下新建文件“org.apache.cxf.Logger”，在文件中写入：org.apache.cxf.common.logging.Log4jLogger即可。特别要注意，(1)上述目录要放在classes目录下；(2)要引入log4j的jar包。 参考：\nhttp://ajita.iteye.com/blog/1745845 "},"title":"CXF记录WebService的soap日志"},"/blog/2021/03/java8_stream_api/":{"data":{"":" ","stream操作的三个步骤#Stream操作的三个步骤":" 创建Stream：一个数据源（如： 集合、数组）， 获取一个流。 中间操作:一个中间操作链，对数据源的数据进行处理。 终止操作(终端操作):一个终止操作，执行中间操作链，并产生结果。 创建Stream (1) 获取Stream Java 8中Collection接口被扩展，提供两种获取流的方法:\nstream() 返回一个顺序流 parallelStream()返回一个并行流 default Stream stream() // 返回一个顺序流 default Stream parallelStream() // 返回一个并行流 List\u003cString\u003e list = new ArrayList\u003c\u003e(); // 顺序流 Stream\u003cString\u003e stream1 = list.stream(); // 并行流 Stream\u003cString\u003e parallelStream = list.parallelStream(); (2) 由数组创建流 Arrays中静态方法stream()获取数组流\nJava 8 中的 Arrays 的静态方法 stream() 可以获取数组流：\nstatic Stream stream(T[] array) // 返回一个流重载形式，能够处理对应基本类型的数组 public static IntStream stream(int[] array) public static LongStream stream(long[] array) public static DoubleStream stream(double[] array) Employess[] emps = new Employess[10]; Stream\u003cEmployess\u003e stream2 = Arrays.stream(emps); （3）由值创建流 可以使用静态方法 Stream.of(), 通过显示值创建一个流。它可以接收任意数量的参数。\npublic static Stream of(T... values) // 返回一个流 Stream\u003cString\u003e stream3 = Stream.of(\"aa\", \"bb\", \"cc\"); （4）由函数创建流 由函数创建流可以创建无限流。可以使用静态方法 Stream.iterate() 和Stream.generate(), 创建无限流 。\n// 迭代 public static Stream iterate(final T seed, final UnaryOperator f) // 生成 public static Stream generate(Supplier s) // 迭代 Stream\u003cInteger\u003e stream4 = Stream.iterate(0, (x) -\u003e x + 2).limit(10); // 生成 Stream.generate(() -\u003e Math.random()).limit(5); 中间操作 (1) 筛选与切片 方法 描述 filter(Predicate p) 接收Lambda,从流中排除某些元素 distinct() 筛选，通过流所生成元素的hashCode()和equals()去除重复元素 limit(long maxSize) 截断流，使其元素不超过给定数量 skip(long n) 跳过元素，返回一个扔掉了前n个元素的流。若流中元素不足n个，则返回一个空流。与limit(n)互补 (2) 映射 方法 描述 map(Function f) 接收一个函数作为参数，该函数会被应用到每个元素上，并映射成一个新元素 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，并产生一个新的DoubleStream mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，并产生一个新的IntStream mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，并产生一个新的LongStream Flat(Function f) 接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 (3) 排序 方法 描述 sorted() 产生一个新流，其中按自然顺序排列 sorted(Comparator comp) 产生一个新流，其中按比较器顺序排列 终止操作 终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：List, Integer，甚至是void\n(1) 查找与匹配 方法 描述 allMatch(Predicate p) 检查是否匹配所有元素 anyMatch(Predicate p) 检查是否至少匹配一个元素 noneMatch(Predicate p) 检查是否所有元素都不匹配 findFirst() 返回第一个元素 findAny() 返回当前流中的任意一个元素 count() 返回流中元素总数 max(Comparator c) 返回流中最大值 min(Comparator c) 返回流中最小值 forEach(Comparator c) 内部迭代。与之相反的是，使用Collection接口需要用户去做迭代，称为外部迭代 (2) 规约 方法 描述 reduce(T iden, BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回T reduce(BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回Optional (3) 收集 方法 描述 collect(Collector c) 将流转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法 Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、 Set、 Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例， 具体方法与实例如下表\n方法 返回类型 作用 toList List 把流中元素收集到List toSet Set 把流中元素收集到Set toCollection Collection 把流中元素收集到创建的集合 counting Long 计算流中元素的个数 summingInt Integer 对流中元素的整数属性求和 averageingInt Double 计算流中元素Integer属性的平均值 summarizingInt IntSummaryStatistics 收集流中Integer属性的统计值。如平均值 joining String 连接流中每个字符串 maxBy Optional 根据比较器选择最大值 minBy Optional 根据比较器选择最小值 reducing 规约产生的类型 从一个作为累加器的初始值开始，利用BinaryOperator与流中元素逐个结合，从而归约成单个值 collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果转换函数 groupingBy Map\u003cK, List\u003e 根据某属性值对流分组，属性为K，结果为V partitioningBy Map\u003cBoolean, List\u003e 根据true或者false进行分区 示例：\nList\u003cEmployee\u003e emps = list.stream().collect(Collectors.toList()); Set\u003cEmployee\u003e emps = list.stream().collect(Collectors.toSet()); Collection\u003cEmployee\u003e emps = list.stream().collect(Collectors.toCollection(ArrayList::new)); long count = list.stream().collect(Collectors.counting()); inttotal = list.stream().collect(Collectors.summingInt(Employee::getSalary)); doubleavg = list.stream().collect(Collectors.averagingInt(Employee::getSalary)); IntSummaryStatisticsiss = list.stream().collect(Collectors.summarizingInt(Employee::getSalary)); String str = list.stream().map(Employee::getName).collect(Collectors.joining()); Optional\u003cEmp\u003e max = list.stream().collect(Collectors.maxBy(comparingInt(Employee:getSalary))); Optional\u003cEmp\u003e min = list.stream().collect(Collectors.minBy(comparingInt(Employee:getSalary))); inttotal = list.stream().collect(Collectors.reducing(0, Employee::getSalary, Integer::sum)); inthow = list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List:size)); Map\u003cEmp.Status, List\u003cEmp\u003e\u003e map = list.stream().collect(Collectors.groupingBy(Employee::getStatus)); Map\u003cBoolean, List\u003cEmp\u003e\u003e vd = list.stream.collect(Collectors.partitioningBy(Employee::getManage)); 参考：\nhttps://www.jianshu.com/p/2b40fd0765c3 https://blog.csdn.net/jiadajing267/article/details/80074022 https://www.cnblogs.com/binghe001/p/12940721.html ","什么是stream-api#什么是Stream API":"Stream API让开发者能够以一种声明的方式处理数据源（集合、数组等），它专注于对数据源进行各种高效的聚合操作（aggregate operation）和大批量数据操作 (bulk data operation)。\nStream API将处理的数据源看做一种Stream（流），Stream（流）在Pipeline（管道）中传输和运算，支持的运算包含筛选、排序、聚合等，当到达终点后便得到最终的处理结果。如果说集合讲的的数据，那么流讲的就是计算！\n几个关键概念：\n元素: Stream是一个来自数据源的元素队列，Stream本身并不存储元素。 数据源: 即Stream的来源, 包含集合、数组、I/O channel、generator（发生器）等。 聚合操作: 类似SQL中的filter、map、find、match、sorted等操作 管道运算: Stream在Pipeline中运算后返回Stream对象本身，这样多个操作串联成一个Pipeline，并形成fluent风格的代码。这种方式可以优化操作，如延迟执行(laziness)和短路( short-circuiting)。 内部迭代: 不同于java 8以前对集合的遍历方式（外部迭代），Stream API采用访问者模式（Visitor）实现了内部迭代。 并行运算: Stream API支持串行（stream()）或并行（parallelStream()）的两种操作方式。 特点：\nStream API的使用和同样是java8新特性的lambda表达式密不可分，可以大大提高编码效率和代码可读性。 Stream API提供串行和并行两种操作，其中并行操作能发挥多核处理器的优势，使用fork/join的方式进行并行操作以提高运行速度。 Stream API进行并行操作无需编写多线程代码即可写出高效的并发程序，且通常可避免多线程代码出错的问题。 注意：\nStream 自己不会存储元素。 Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。 Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。 "},"title":"Java 8新特性 - (2)Stream API"},"/blog/2021/03/jetty_session_remove_node_name/":{"data":{"":"jetty 9.4 版本对session id的生成做了升级. 他会自动在session id后面加个节点的名字(workName配置项). jetty 9.3 以及之前的版本没有这个问题.\n可以通过修改配置文件来去除session id后缀:\n# 执行下面命令来启用sessions模块，这样就会在start.d目录下面自动生成sessions.ini配置文件 java -jar \"/usr/local/jetty/start.jar\" --add-to-startd=sessions # 修改sessions.ini配置，把下面配置项的值为空 jetty.sessionIdManager.workerName= "},"title":"删除Jetty中session ID的node名称"},"/blog/2021/03/linux_set_sunday_as_first_day_of_week/":{"data":{"":"用 “locale”命令检查当前的区域，例如我的机器运行结果是：\nls@ls-laptop:~$ locale LANG=zh_CN.UTF-8 LANGUAGE=zh_CN.UTF-8 LC_CTYPE=\"zh_CN.UTF-8\" LC_NUMERIC=\"zh_CN.UTF-8\" LC_TIME=\"zh_CN.UTF-8\" LC_COLLATE=\"zh_CN.UTF-8\" LC_MONETARY=\"zh_CN.UTF-8\" LC_MESSAGES=\"zh_CN.UTF-8\" LC_PAPER=\"zh_CN.UTF-8\" LC_NAME=\"zh_CN.UTF-8\" LC_ADDRESS=\"zh_CN.UTF-8\" LC_TELEPHONE=\"zh_CN.UTF-8\" LC_MEASUREMENT=\"zh_CN.UTF-8\" LC_IDENTIFICATION=\"zh_CN.UTF-8\" LC_ALL= 执行下面命令\nsudo gedit /usr/share/i18n/locales/zh_CN 找到 “first_weekday 2” 这一行，将2改成1，周日就是每周的第一天了\n执行下面的命令重新生成 locale 信息\nsudo locale-gen 重新启动\n参考原文：\nhttp://ubuntuforums.org/archive/index.php/t-26409.html "},"title":"设置周日为一个星期的第一天"},"/blog/2021/03/manjaro_printer_service_not_available/":{"data":{"":"Manjaro升级到某个版本后，在系统设置中，查看打印机，显示“打印机服务不可用，错误的文件描述符“。\n其中一个原因是CUPS（Common UNIX Printing System）打印管理服务未启动。可以用下面的方法来解决：\n# 启动服务，保证本次登录打印机可用 sudo systemctl start cups.service # 设置开启启动 sudo systemctl enable cups.service "},"title":"Manjaro升级后打印服务不可用"},"/blog/2021/03/nginx_cfg_for_long_polling/":{"data":{"":"某些web应用需要使用到长轮询，在Nginx中需要添加配置来支持。比如说vaadin界面，如果没有做一些额外的配置，使用nginx做反向代理，会出现页面一直在加载的问题\n首先需要在http中添加map块\nmap $http_upgrade $connection_upgrade { default Upgrade; '' close; } 然后在location中添加下面的配置，使用刚才定义的内容\nlocation /chat { proxy_pass https://192.168.67.100:8443/chatapi; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_buffering off; proxy_ignore_client_abort off; break; } "},"title":"配置Nginx支持长轮询"},"/blog/2021/03/update_docker_image_timezone/":{"data":{"":"默认apline镜像没有安装时区, 即使把宿主机的/etc/localtime 挂在到镜像中也无法把时区改成 GMT+8的.\n这个就只能在构建镜像的时候,安装并设置一下时区\nRUN apk add tzdata \\ \u0026\u0026 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026\u0026 echo \"Asia/Shanghai\" \u003e /etc/timezone "},"title":"基于alpine构建docker镜像修改时区"},"/blog/2021/03/update_response_via_fiddler/":{"data":{"customize-rule编辑方式#Customize Rule编辑方式":"可以通过Fiddler菜单打开CustomRules.js文件然后通过第三方编辑器来编辑并保存，或者通过Fiddler ScriptEditor工具来编辑（推荐，右侧有相关类使用参考）。\n原文来源： http://www.cnblogs.com/liumamxu/p/5118055.html\n相关链接：\nFiddler Script基本介绍： http://www.cnblogs.com/TankXiao/archive/2012/04/25/2349049.html 官方文档参考： http://docs.telerik.com/fiddler/KnowledgeBase/FiddlerScript/ModifyRequestOrResponse 使用中踩坑借鉴： http://stackoverflow.com/questions/23094692/can-i-modify-json-responses-using-fiddler-scripts http://www.telerik.com/forums/how-to-use-fiddler-webformats-json-jsondecode FiddlerScript Editor： http://www.telerik.com/download/fiddler/fiddlerscript-editor ","基本步骤简单#基本步骤（简单）":"打开并编辑Customize Rule文件，在方法 OnBeforeResponse 中插入修改代码，重启Fiddler重新加载Rule，运行。\n插入代码：\nstatic function OnBeforeResponse(oSession: Session) { if (m_Hide304s \u0026\u0026 oSession.responseCode == 304) { oSession[\"ui-hide\"] = \"true\"; } // 判断是否为目标请求 var isMusicRequest = false; if ((oSession.host == \"m.baidu.com\") \u0026\u0026 // host oSession.fullUrl.Contains(\"suggest?ctl=his\u0026action=list\")) // url { isMusicRequest = true; } // 修改返回JSON串 if (isMusicRequest) { // 1, 获取Response Body中JSON字符串 var responseStringOriginal = oSession.GetResponseBodyAsString(); //FiddlerObject.log(responseStringOriginal); // 可在控制台中输出Log // 2, 转换为可编辑的JSONObject变量 var responseJSON = Fiddler.WebFormats.JSON.JsonDecode(responseStringOriginal); // 3, 修改JSONObject变量 // 3.1修改字段 responseJSON.JSONObject['singer'] = \"艾密莉亚·怀得堡\"; // 3.2添加字段 var similarSong1= '{' + '\"music\": \"dying in the sun\",'+ '\"singer\": \"The Cranberries\"'+ '}'; var similarSong2= '{' + '\"music\": \"seasons in sun\",'+ '\"singer\": \"WestLife\"'+ '}'; var similarSong = '[' + similarSong1 + ',' + similarSong2 + ']'; responseJSON.JSONObject['similar song'] = Fiddler.WebFormats.JSON.JsonDecode(similarSong).JSONObject ; // 4, 重新设置Response Body var responseStringDestinal = Fiddler.WebFormats.JSON.JsonEncode(responseJSON.JSONObject); //FiddlerObject.log(responseStringDestinal); oSession.utilSetResponseBody(responseStringDestinal); } } ","基本流程#基本流程":"使用Fiddler抓包工具，通过修改CustomRules.js脚本达到修改Http请求的Response中Body信息（如JSON串）。\n常用于在Server开发未完全Ready而前端或客户端开发需要Server数据时，修改请求的返回数据，达到Debug和测试的目的，较添加BreakPoint的方法更加便捷。\n本例Demo中会为JSON添加一个字段和修改一个字段，如下所示：\n// 原JSON串 V1.0 { \"music\": \"big big world\", \"singer\": \"Emilia Rydberg\" } // 新JSON串 V1.1 { \"music\": \"big big world\", \"singer\": \"艾密莉亚·怀得堡\", // 修改该字段(英文名改为中文名显示) \"similar song\": [ // 添加该字段(相似歌曲列表) { \"music\": \"dying in the sun\", \"singer\": \"The Cranberries\" }, { \"music\": \"seasons in sun\", \"singer\": \"WestLife\" } ] } 基本流程"},"title":"在Fiddler中使用脚本来修改Response数据"},"/blog/2021/04/java8_method_references/":{"data":{"":" 方法引用（Method references）。方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，可以使语言的构造更紧凑简洁，减少冗余代码。\n方法引用使用到的操作符“::”，这个操作符把方法引用分成两边，左边是类名或者某个对象的引用，右边是方法名。引用方法有下面几种方式：\n对象引用::实例方法名 类名::静态方法名 类名::实例方法名 类名::new 类型[]::new ","对象引用实例方法名#对象引用::实例方法名":"创建了一个PersonCompare对象，调用了其内部的compareByName实例方法。\npublic class PersonCompare { public int compareByName(Person a, Person b) { return a.getName().compareTo(b.getName()); } public int compareByAge(Person a, Person b) { return a.getBirthday().compareTo(b.getBirthday()); } @Test public void test(){ Person[] pArr = new Person[]{ new Person(\"1\", LocalDate.of(2019, 12, 1)), new Person(\"2\", LocalDate.of(2019, 12, 2)), new Person(\"3\", LocalDate.of(2019, 12, 3)), new Person(\"4\", LocalDate.of(2019, 12, 4))}; PersonCompare personCompare = new PersonCompare(); Arrays.sort(pArr, personCompare::compareByName); } } ","类名new#类名::new":"在引用构造器的时候，构造器参数列表要与接口中抽象方法的参数列表一致。对应的 Lambda：() -\u003e new String()。\nclass PersonFactory { private Supplier\u003cPerson\u003e supplier; public PersonFactory(Supplier\u003cPerson\u003e supplier) { this.supplier = supplier; } public Person getPerson() { return supplier.get(); } } PersonFactory factory = new PersonFactory(Person::new); Person p1 = factory.getPerson(); 上面这段代码的功能就是使用PersonFactory工厂，然后使用Person::new创建一个Person实例。","类名实例方法名#类名::实例方法名":"若Lambda表达式的参数列表的第一个参数，是实例方法的调用者，第二个参数(或无参)是实例方法的参数时，就可以使用这种方法：\nBiPredicate\u003cString, String\u003e b = String::equals; b.test(\"abc\", \"abcd\"); String是一个类而equals为该类的定义的实例方法。BiPredicate中的唯一抽象方法test方法参数列表与equals方法的参数列表相同，都是接收两个String类型参数。","类名静态方法名#类名::静态方法名":"举几个例子：\nString::valueOf，等价于 Lambda：s -\u003e String.valueOf(s)\nMath::pow 等价于lambda表达式 (x, y) -\u003e Math.pow(x, y);\nPerson::compareByAge 就是一个静态方法引用，也是前面我们举得例子。\nFunction\u003cLong, Long\u003e f = Math::abs; Long result = f.apply(-3L); Math是一个类而abs为该类的静态方法。Function中的唯一抽象方法apply方法参数列表与abs方法的参数列表相同，都是接收一个Long类型参数。","类型new#类型[]::new":"引用数组和引用构造器很像，格式为 类型[]::new，等价于 lambda 表达式 x -\u003e new int[x]。其中类型可以为基本类型也可以是类。\nFunction\u003cInteger, int[]\u003e fun = int[]::new; int[] arr = fun.apply(10); Function\u003cInteger, Integer[]\u003e fun2 = Integer[]::new; Integer[] arr2 = fun2.apply(10); 参考：\nhttps://zhuanlan.zhihu.com/p/97165121 "},"title":"Java 8新特性 - (3)方法引用"},"/blog/2021/05/java8_default_method/":{"data":{"":" ","java-8抽象类与接口对比#java 8抽象类与接口对比":"相同点 都是抽象类型； 都可以有实现方法（以前接口不行）； 都可以不需要实现类或者继承者去实现所有方法，（以前不行，现在接口中默认方法不需要实现者实现） 不同点 抽象类不可以多重继承，接口可以（无论是多重类型继承还是多重行为继承）； 抽象类和接口所反映出的设计理念不同。其实抽象类表示的是\"is-a\"关系，接口表示的是\"like-a\"关系； 接口中定义的变量默认是public static final 型，且必须给其初值，所以实现类中不能改变其值；抽象类中的变量默认是 friendly 型，其值可以在子类中重新定义，也可以重新赋值。 ","为什么要有默认方法#为什么要有默认方法":"首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。\n简单的例子: 一个接口A，Clazz类实现了接口A。\npublic interface A { default void foo(){ System.out.println(\"Calling A.foo()\"); } } public class Clazz implements A { public static void main(String[] args){ Clazz clazz = new Clazz(); clazz.foo();//调用A.foo() } } 代码是可以编译的，即使Clazz类并没有实现foo()方法。在接口A中提供了foo()方法的默认实现。","什么是默认方法#什么是默认方法":"简单说，就是接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字即可。","多重继承的冲突#多重继承的冲突":"观察以下代码，会出现编译错误：\njava: class InterfaceC inherits unrelated defaults for f() from types InterfaceA and InterfaceB\ninterface InterfaceA { default void f() {} } interface InterfaceB { default void f() {} } class InterfaceC implements InterfaceA, InterfaceB { } 为了解决以上的冲突，需要手动重写（override）默认方法\nclass InterfaceC implements InterfaceA, InterfaceB { public void f() { System.out.println(\"my local f\"); } } 如果我们想使用特定接口的默认方法，可以使用如下方式：\nclass InterfaceC implements InterfaceA, InterfaceB { public void f() { InterfaceA.super.f(); } } ","静态默认方法#静态默认方法":"Java 8 的另一个特性是接口可以声明（并且可以提供实现）静态方法。例如：\npublic interface Vehicle { default void print(){ System.out.println(\"我是一辆车!\"); } // 静态方法 static void blowHorn(){ System.out.println(\"按喇叭!!!\"); } } 参考：\nhttps://my.oschina.net/benhaile/blog/176007 https://www.jianshu.com/p/57bca8216976 https://www.runoob.com/java/java8-default-methods.html "},"title":"Java 8新特性 - (4)默认方法"},"/blog/2021/05/java8_method_parameter_reflection/":{"data":{"":"方法的参数名，在很多时候我们是需要反射得到的。但是在java8之前，代码编译为class文件后，方法参数的类型是固定的，但参数名称却丢失了，这和动态语言严重依赖参数名称形成了鲜明对比。（java是静态语言，所以入参名称叫什么其实无所谓的）。虽然名称无所谓，但很多时候，我们需要此名称来做更好的安排.\n比如mybatis的Dao层接口方法，需要特意用个注解@Param来显示标识出参数名。所以java8来了，带来的新特性解决了这一问题。\n获取方法参数名称有3种方法：","通过java8的parameter类#通过Java8的Parameter类":"Java 8开始在class文件中保留参数名，给反射带来了极大的便利。jdk8增加了类Parameter\npublic static void main(String[] args) { List\u003cString\u003e paramterNames = getParameterNameJava8(StaffMark.class, \"fun1\"); paramterNames.forEach((x) -\u003e System.out.println(x)); } public static void fun1(String aaa, Integer bbb) { } public static List\u003cString\u003e getParameterNameJava8(Class clazz, String methodName) { List\u003cString\u003e paramterList = new ArrayList\u003c\u003e(); Method[] methods = clazz.getDeclaredMethods(); for (Method method : methods) { if (methodName.equals(method.getName())) { //直接通过method就能拿到所有的参数 Parameter[] params = method.getParameters(); for (Parameter parameter : params) { paramterList.add(parameter.getName()); } } } return paramterList; } 执行后的输出：\narg0 arg1 可以看到输出的不是想要的参数名。因为java8为了保持向下兼容，默认编译是不能获取到参数名称的。需要满足下面两个条件\nJDK版本必须是1.8及以上 编译时候必须有编译选项：javac -parameters打开，默认是关闭的 在idea设置保留参数名的方法：在 preferences-》Java Compiler-\u003e设置模块字节码版本1.8，Javac Options中的 Additional command line parameters: -parameters\n这样设置之后，我们再运行上面代码，发现输出的结果为：\naaa bbb 参考：\nhttps://blog.csdn.net/f641385712/article/details/81291273 ","通过spring的localvariabletableparameternamediscoverer#通过spring的LocalVariableTableParameterNameDiscoverer":" public static void main(String[] args) { List\u003cString\u003e paramterNames = getParamterName(StaffMark.class, \"fun1\"); paramterNames.forEach((x) -\u003e System.out.println(x)); } public static void fun1(String aaa, Integer bbb) { } public static List\u003cString\u003e getParamterName(Class clazz, String methodName) { LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); Method[] methods = clazz.getDeclaredMethods(); for (Method method : methods) { if (methodName.equals(method.getName())) { //获取到该方法的参数们 String[] params = u.getParameterNames(method); return Arrays.asList(params); } } return null; } 输出：\naaa bbb 备注：如果不用Class，而是通过spring注入的实例，然后instance.getClass.getDeclaredMethods()则无法得到参数名，调试时看到方法名称是通过jdk代理过的，拿不到参数名。","采用javassit包获取#采用javassit包获取":"很麻烦，参考其他网上文章"},"title":"Java 8新特性 - (8)方法参数反射"},"/blog/2021/05/java8_repeating_annotations/":{"data":{"":"在JDK8之前，不能使用重复注解的，即某个位置相同注解只能出现一次。\n如果想编写一个定时任务的注解，使用者可以配置在每天哪一小时触发，而且允许用户配置多个时间。传统做法是：\n@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface TraditionalAnnoSchedule { int[] hour() default {0}; } @TraditionalAnnoSchedule(hour = {0, 8, 12}) public class Target { public static void main(String[] args) { TraditionalAnnoSchedule[] annotations = Target.class.getAnnotationsByType(TraditionalAnnoSchedule.class); for (TraditionalAnnoSchedule each : annotations) { System.out.println(Arrays.toString(each.hour())); } } } 使用JDK8的重复注解特性改造一下。\n@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface Schedules { Schedule[] value(); } // JDK8新增的@Repeatable @Repeatable(Schedules.class) public @interface Schedule { int hour() default 0; } @Schedule(hour = 0) @Schedule(hour = 8) @Schedule(hour = 12) public class Target { public static void main(String[] args) { // 推荐的方式 Schedule[] annotations = Target.class.getAnnotationsByType(Schedule.class); for (Schedule each : annotations) { System.out.println(each.hour()); } // 老的方式 Schedule[] schedules = Target.class.getAnnotation(Schedules.class).value(); for (Schedule each : schedules) { System.out.println(each.hour()); } } } 这里有个使用@Repeatable( Schedules.class )的注解类Schedule，Schedules仅仅是Schedule注解的数组，但Java编译器并不想让程序员意识到Schedules的存在。这样对使用者而言，Target就拥有了两个Schedule注解，而不是1个Schedules注解。同时，反射相关的API提供了新的函数getAnnotationsByType()来返回重复注解的类型。\n参考：\nhttps://blog.csdn.net/aitangyong/article/details/54346342 "},"title":"Java 8新特性 - (5)重复注解"},"/blog/2021/05/java8_type_annotation/":{"data":{"":"","什么是类型注解#什么是类型注解":"在java 8之前，注解只能是在声明的地方所使用，比如类，方法，属性；从java 8开始，注解可以应用在任何地方。但是需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。换句话说，仅提供定义这些类型的注释的功能，然后由框架和工具开发者来实际上使用它们。\n主要的场景：\n创建类实例： new @Interned MyObject(); 类型定义： @NotNull String str1 = ... @Email String str2 = ... 类型转换： myString = (@NonNull String) str; 泛型 List\u003c@Email String\u003e emails = ... 包括参数边界和通配符边界 class Folder\u003cF extends @Existing File\u003e { ... } Collection\u003c? super @Existing File\u003e c = ... List\u003c@Immutable ? extends Comparable\u003cT\u003e\u003e unchangeable = ... instanceof 语句 boolean isNonNull = myString instanceof @NonNull String; boolean isNonBlankEmail = myString instanceof @NotBlank @Email String; 继承 class UnmodifiableList\u003cT\u003e implements @Readonly List\u003c@Readonly T\u003e { ... } 抛出异常: void monitorTemperature() throws @Critical TemperatureException { ... } 方法引用 @Vernal Date::getDay List\u003c@English String\u003e::size Arrays::\u003c@NonNegative Integer\u003esort ","新增elementtypetype_use-和elementtypetype_parameter#新增ElementType.TYPE_USE 和ElementType.TYPE_PARAMETER":"新增的两个注释的程序元素类型 ElementType.TYPE_USE 和 ElementType.TYPE_PARAMETER 用来描述注解的新场合 。 ElementType.TYPE_PARAMETER 表示该注解能写在类型变量的声明语句中。 ElementType.TYPE_USE 表示该注解能写在使用类型的任何语句中（比如：声明语句、泛型和强制转换语句中的类型）。\n@Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE}) @interface MyAnnotation {} ","类型注解的作用#类型注解的作用":"类型注解被用来支持在Java的程序中做强类型检查。配合第三方插件工具Checker Framework，可以在编译的时候检测出runtime error（比如UnsupportedOperationException，NumberFormatException，NullPointerException异常等都是runtime error），以提高代码质量。这就是类型注解的作用。\n参考：\nhttps://my.oschina.net/benhaile/blog/179642 https://juejin.cn/post/6844903929914867719 https://blog.csdn.net/sun_promise/article/details/51315032 "},"title":"Java 8新特性 - (6)类型注解"},"/blog/2021/05/java8_type_inference/":{"data":{"":"","java-8的泛型类型推断改进#Java 8的泛型类型推断改进":"java 8里面泛型的目标类型推断主要2个：\n支持通过方法上下文推断泛型目标类型 支持在方法调用链路当中，泛型类型推断传递到最后一个方法 看看官网的例子：\nclass List\u003cE\u003e { static \u003cZ\u003e List\u003cZ\u003e nil() { ... }; static \u003cZ\u003e List\u003cZ\u003e cons(Z head, List\u003cZ\u003e tail) { ... }; E head() { ... } } 根据JEP101的特性，在调用上面方法的时候可以这样写\n//通过方法赋值的目标参数来自动推断泛型的类型 List\u003cString\u003e l = List.nil(); //而不是显示的指定类型 //List\u003cString\u003e l = List.\u003cString\u003enil(); //通过前面方法参数类型推断泛型的类型 List.cons(42, List.nil()); //而不是显示的指定类型 //List.cons(42, List.\u003cInteger\u003enil()); 参考：\nhttps://my.oschina.net/benhaile/blog/184390 ","泛型简介#泛型简介":"泛型由Java 1.5引入，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。通俗点将就是“类型的变量”。这种类型变量可以用在类、接口和方法的创建中。理解Java泛型最简单的方法是把它看成一种便捷语法，能节省某些Java类型转换(casting)上的操作.\n泛型的最大优点是提供了程序的类型安全同时可以向后兼容，但也有尴尬的地方，就是每次定义时都要写明泛型的类型，这样显示指定不仅感觉有些冗长。Java 7中对泛型做了改进，编译器会根据变量声明时的泛型类型自动推断.\n// Java 7之前的写法 Map\u003cString, String\u003e myMap = new HashMap\u003cString, String\u003e(); // Java 7及之后的写法 Map\u003cString, String\u003e myMap = new HashMap\u003c\u003e(); //注意后面的\"\u003c\u003e\" 但是，Java 7在创建泛型实例时的类型推断是有限制的：只有构造器的参数化类型在上下文中被显著的声明了，才可以使用类型推断，否则不行。例如：下面的例子在java 7无法正确编译（但在java8里面可以编译，因为根据方法参数来自动推断泛型的类型）：\nList\u003cString\u003e list = new ArrayList\u003c\u003e(); list.add(\"A\"); // 由于addAll期望获得Collection\u003c? extends String\u003e类型的参数，因此下面的语句在Java 7中无法编译无法通过 list.addAll(new ArrayList\u003c\u003e()); "},"title":"Java 8新特性 - (7)泛型的类型推断"},"/blog/2021/06/aliyun_waf_sni/":{"data":{"":"","sni兼容性#SNI兼容性":"SNI支持以下桌面版浏览器：\nChrome 5及以上版本 Chrome 6及以上版本（Windows XP） Firefox 2及以上版本 IE 7及以上版本（运行在Windows Vista/Server 2008及以上版本系统中，在XP系统中任何版本的IE浏览器都不支持SNI） Konqueror 4.7及以上版本 Opera 8及以上版本 Safari 3.0 on Windows Vista/Server 2008及以上版本，Mac OS X 10.5.6 及以上版本 SNI支持以下库：\nGNU TLS Java 7及以上版本，仅作为客户端 HTTP client 4.3.2及以上版本 libcurl 7.18.1及以上版本 NSS 3.1.1及以上版本 OpenSSL 0.9.8j及以上版本 OpenSSL 0.9.8f及以上版本，需配置flag Qt 4.8及以上版本 Python3、Python 2.7.9及以上版本 SNI支持以下手机端浏览器：\nAndroid Browser on 3.0 Honeycomb及以上版本 iOS Safari on iOS 4及以上版本 Windows Phone 7及以上版本 SNI支持以下服务器：\nApache 2.2.12及以上版本 Apache Traffic Server 3.2.0及以上版本 HAProxy 1.5及以上版本 IIS 8.0及以上版本 lighttpd 1.4.24及以上版本 LiteSpeed 4.1及以上版本 nginx 0.5.32及以上版本 SNI 支持以下命令行：\ncURL 7.18.1及以上版本 wget 1.14及以上版本 参考：\nhttps://help.aliyun.com/document_detail/43742.htm?spm=a2c4g.11186623.2.41.5c2360683Q5p84#concept-mrv-5wl-q2b https://www.cloudflare.com/zh-cn/learning/ssl/what-is-sni/ ","什么是sni#什么是SNI":"当多个网站托管在一台服务器上并共享一个IP地址，并且每个网站都有自己的SSL证书，在客户端设备尝试安全地连接到其中一个网站时，服务器可能不知道显示哪个SSL证书。这是因为SSL/TLS握手发生在客户端设备通过HTTP指示连接到某个网站之前。这个有点像邮寄包裹到公寓楼而不是独栋房子。将邮件邮寄到某人的独栋房子时，仅街道地址就足以将包裹发送给收件人。但是，当包裹进入公寓楼时，除了街道地址外，还需要公寓号码。否则，包裹可能无法送达收件人或根本无法交付。\n服务器名称指示（SNI，Server Name Indication）旨在解决此问题。 SNI是TLS协议（以前称为SSL协议）的扩展，该协议在HTTPS中使用。它包含在TLS/SSL握手流程中，以确保客户端设备能够看到他们尝试访问的网站的正确SSL证书。该扩展使得可以在TLS握手期间指定网站的主机名或域名，而不是在握手之后打开HTTP连接时指定。\nSNI在2003年被添加为TLS/SSL的扩展；它最初不是协议的一部分。几乎所有的浏览器、操作系统和Web服务器都支持它，除了一些仍在使用的最旧的浏览器和操作系统。如果客户端或者浏览器不支持SNI，用户可能无法访问某些网站，将返回错误消息，例如\"您的连接缺乏安全隐私。\"","阿里云waf对于sni的支持#阿里云WAF对于SNI的支持":"如下图，阿里云WAF支持多配置多个域名，并根据用户请求来返回对应域名的证书。同时阿里云有个默认证书，当无法确定证书的时候，就返回默认的证书。\n对于共享型的WAF，默认返回的是阿里云的SSL证书；对于独享型的WAF，用户可以在控制台配置默认的证书。\n这个对to-B的系统来说，会有一定的挑战。如果对方企业用的是比较老的SAP版本，可能http客户端不支持SNI，这样的话，共享版的WAF会返回默认的阿里云证书，客户端验证证书时候会报错。这种情况，可能就只能选择独享版WAF，毕竟用户可以自定义默认证书，将默认证书设置成所需要的证书即可。\n另外，在更新SSL证书的时候，如果使用的是独享版WAF，除了更新所配置域名的证书以外，也要更新默认的证书。否则，由于旧的默认证书过期，对于不支持SNI的客户端，会出现验证证书的错误。"},"title":"阿里云WAF与SNI问题"},"/blog/2021/06/docker_curl_ssl_certificate_fail/":{"data":{"":"使用debian:buster-slim镜像编写dockfile，在调用curl命令的时候，报下面的错误：\ncurl: (60) SSL certificate problem: unable to get local issuer certificate 这个是由于本地没有证书。其中一个解决办法是，在dockfile中加入类似下面的语句来安装证书，再调用curl命令\nRUN \\ apt-get update \u0026\u0026 \\ apt-get install ca-certificates \u0026\u0026 \\ apt-get clean "},"title":"Docker环境中curl报证书错误"},"/blog/2021/06/java8_base64/":{"data":{"":"早期处理BASE64编码, 需借助外部依赖：commons-codec，sun.misc.BASE64Decoder或JAXB的DatatypeConverter。Java 8实现了BASE64编解码API，它包含到java.util包。\njava.util.Base64工具类提供了一套静态方法获取下面三种BASE64编解码器：\nBasic编码 URL编码 MIME编码 ","basic编码#Basic编码":"Basic编码是标准的BASE64编码，用于处理常规的需求：输出的内容不添加换行符，而且输出的内容由字母加数字组成。\n// 编码 String asB64 = Base64.getEncoder().encodeToString(\"some string\".getBytes(\"utf-8\")); System.out.println(asB64); // 输出为: c29tZSBzdHJpbmc= // 解码 byte[] asBytes = Base64.getDecoder().decode(\"c29tZSBzdHJpbmc=\"); System.out.println(new String(asBytes, \"utf-8\")); // 输出为: some string ","mime编码#MIME编码":"MIME编码器会使用基本的字母数字产生BASE64输出，而且对MIME格式友好：每一行输出不超过76个字符，而且每行以“\\r\\n”符结束。\nStringBuilder sb = new StringBuilder(); for (int t = 0; t \u003c 10; ++t) { sb.append(UUID.randomUUID().toString()); } byte[] toEncode = sb.toString().getBytes(\"utf-8\"); String mimeEncoded = Base64.getMimeEncoder().encodeToString(toEncode); System.out.println(mimeEncoded); // 输出为: NDU5ZTFkNDEtMDVlNy00MDFiLTk3YjgtMWRlMmRkMWEzMzc5YTJkZmEzY2YtM2Y2My00Y2Q4LTk5 ZmYtMTU1NzY0MWM5Zjk4ODA5ZjVjOGUtOGMxNi00ZmVjLTgyZjctNmVjYTU5MTAxZWUyNjQ1MjJj NDMtYzA0MC00MjExLTk0NWMtYmFiZGRlNDk5OTZhMDMxZGE5ZTYtZWVhYS00OGFmLTlhMjgtMDM1 ZjAyY2QxNDUyOWZiMjI3NDctNmI3OC00YjgyLThiZGQtM2MyY2E3ZGNjYmIxOTQ1MDVkOGQtMzIz Yi00MDg0LWE0ZmItYzkwMGEzNDUxZTIwOTllZTJiYjctMWI3MS00YmQzLTgyYjUtZGRmYmYxNDA4 Mjg3YTMxZjMxZmMtYTdmYy00YzMyLTkyNzktZTc2ZDc5ZWU4N2M5ZDU1NmQ4NWYtMDkwOC00YjIy LWIwYWItMzJiYmZmM2M0OTBm ","url编码#URL编码":"URL编码也是经常的需求，但由于URL对反斜线“/”有特殊的意义，因此URL编码需要替换掉它，使用下划线替换\nString basicEncoded = Base64.getEncoder().encodeToString(\"subjects?abcd\".getBytes(\"utf-8\")); System.out.println(\"Using Basic Alphabet: \" + basicEncoded); String urlEncoded = Base64.getUrlEncoder().encodeToString(\"subjects?abcd\".getBytes(\"utf-8\")); System.out.println(\"Using URL Alphabet: \" + urlEncoded); // 输出为: Using Basic Alphabet: c3ViamVjdHM/YWJjZA== Using URL Alphabet: c3ViamVjdHM_YWJjZA== ","流的封装#流的封装":"java.util.Base64类封装了所有的BASE64编码器和解码器，还支持流的封装——这是一个非常优雅的构造——包括编码和效率都很高（无需缓冲Buffer）——即编码器和解码器的输入和输出无需缓冲Buffer。\n下面的例子来说明了编码器是怎样封装FileOutputStream，以及解码器是怎样封装FileInputStream的，两者皆不需要缓冲Buffer：\npublic void wrapping() throws IOException { String src = \"This is the content of any resource read from somewhere\" + \" into a stream. This can be text, image, video or any other stream.\"; // 编码器封装OutputStream, 文件/tmp/buff-base64.txt的内容是BASE64编码的形式 try (OutputStream os = Base64.getEncoder().wrap(newFileOutputStream(\"/tmp/buff-base64.txt\"))) { os.write(src.getBytes(\"utf-8\")); } // 解码器封装InputStream, 以及以流的方式解码, 无需缓冲 // is being consumed. There is no need to buffer the content of the file just for decoding it. try (InputStream is = Base64.getDecoder().wrap(newFileInputStream(\"/tmp/buff-base64.txt\"))) { int len; byte[] bytes = new byte[100]; while ((len = is.read(bytes)) != -1) { System.out.print(new String(bytes, 0, len, \"utf-8\")); } } } 参考：\nhttps://blog.csdn.net/chszs/article/details/17027649 "},"title":"Java 8新特性 - (11)Base64编解码"},"/blog/2021/06/java8_datetime_api/":{"data":{"":"","duration#Duration":"Duration的内部实现与Instant类似，也是包含两部分：seconds表示秒，nanos表示纳秒。两者的区别是Instant用于表示一个时间戳（或者说是一个时间点），而Duration表示一个时间段，所以Duration类中不包含now()静态方法。\n可以通过Duration.between()方法创建Duration对象\nLocalDateTime from = LocalDateTime.now(); LocalDateTime to = LocalDateTime.now().plusDays(1); Duration duration = Duration.between(from, to); // 区间统计换算 // 总天数 long days = duration.toDays(); // 小时数 long hours = duration.toHours(); // 分钟数 long minutes = duration.toMinutes(); // 秒数 long seconds = duration.getSeconds(); // 毫秒数 long milliSeconds = duration.toMillis(); // 纳秒数 long nanoSeconds = duration.toNanos(); Duration对象还可以通过of()方法创建，该方法参数为时间段长度和时间单位。\n// 7天 Duration duration1 = Duration.of(7, ChronoUnit.DAYS); // 60秒 Duration duration2 = Duration.of(60, ChronoUnit.SECONDS); ","instant#Instant":"Instant用于一个时间戳，与System.currentTimeMillis()类似，但Instant可以精确到纳秒（Nano-Second）。\n查看Instant源码，可以发现它的内部使用了两个常量：\nseconds表示从1970-01-01 00:00:00开始到现在的秒数 nanos表示纳秒部分（nanos的值不会超过999,999,999） Instant除了可以使用now()方法创建，还可以通过ofEpochSecond方法创建。\nInstant now = Instant.now(); Instant.ofEpochSecond(365 * 24 * 60, 100); 其中ofEpochSecond第一个参数表示秒，第二个参数表示纳秒。整体表示：从1970-01-01 00:00:00开始后的365天100纳秒的时间点。","localdate#LocalDate":"LocalDate类内只包含日期，不包含具体时间。只需要表示日期而不包含时间，就可以使用它。\n// 只获取日期 LocalDate today = LocalDate.now(); System.out.println(today); int year = today.getYear(); int month = today.getMonthValue(); int day = today.getDayOfMonth(); System.out.printf(\"Year : %d Month : %d day : %d \\t %n\", year, month, day); 同时，还可以通过LocalDate获取日期是月份的第几天、周的第几天，月份的天数，是否为闰年等。看下面的代码是不是非常方便。\nLocalDate today = LocalDate.now(); // 月份中的第几天 int dayOfMonth = today.getDayOfMonth(); // 一周的第几天 DayOfWeek dayOfWeek = today.getDayOfWeek(); // 月份的天数 int length = today.lengthOfMonth(); // 是否为闰年 boolean leapYear = today.isLeapYear(); 上面通过now获取LocalDate对象，也可以通过静态方法of()或parse创建任意一个日期。再也不用像之前一样年只能从1900年开始，月必须从0开始等。\nLocalDate oneDay = LocalDate.of(2019,10,1); System.out.println(oneDay); LocalDate parseDay = LocalDate.parse(\"2019-10-01\"); System.out.println(parseDay); // 打印输出：2019-10-01 LocalDate重写了equals方法，让日期的比较也变得简单了。\n// 定义任意日期 LocalDate oneDay = LocalDate.of(2019, 10, 1); System.out.println(oneDay); // 定义任意比较 LocalDate anyDay = LocalDate.of(2019, 10, 1); System.out.println(oneDay.equals(anyDay)); 同时，针对日期还可延伸出MonthDay或YearMonth类，顾名思义，只包含月天或年月。同样适用于equals方法来比较。\n另外使用before和after可以比较两个日期前后时间。\nboolean notBefore = LocalDate.parse(\"2019-10-01\").isBefore(LocalDate.parse(\"2019-10-02\")); boolean isAfter = LocalDate.parse(\"2019-10-01\").isAfter(LocalDate.parse(\"2019-10-02\")); 对日期进行前一天后一天或前一个月的加减也变得十分方便。\nLocalDate tomorrowDay = LocalDate.now().plusDays(1); LocalDate nextMonth = LocalDate.now().plusMonths(1); 还有，可以获取某一天的开始时间和当天所在月的第一天等。\nLocalDate.now().atStartOfDay(); LocalDate.now().with(TemporalAdjusters.firstDayOfMonth()); ","localdatetime#LocalDateTime":"LocalDateTime表示日期和时间组合。可以通过of()方法直接创建，也可以调用LocalDate的atTime()方法或LocalTime的atDate()方法将LocalDate或LocalTime合并成一个LocalDateTime。\n创建时间示例：\nLocalDateTime now = LocalDateTime.now(); LocalDateTime oneTime = LocalDateTime.of(2019,10,14,10,12,12); // 拼接日期 LocalTime.now().atDate(LocalDate.now()); LocalDateTime与LocalDate和LocalTime之间可以相互转化。其他日期增减等操作与上面的类似。","localtime#LocalTime":"LocalTime和LocalDate类似，区别在于LocalDate不包含具体时间，而LocalTime包含具体时间。同样可以使用now或of方法来获得对象。\nLocalTime localTime = LocalTime.now(); LocalTime oneTime = LocalTime.of(10,10,10); LocalDate类似它也拥有parse、isBefore、获取时间单元等方法，就不再赘述。\n需要注意的是，LocalTime获得的时间格式为：11:41:58.904。也就是，HH:mm:ss.nnn，这里nnn是纳秒。\n还有一个在实战中查询日期区间时我们经常定义的“23:59:59.99”常量再也不用自己定义了。\n// 23:59:59.999999999 LocalTime maxTime = LocalTime.MAX; // 00:00 LocalTime minTime = LocalTime.MIN; ","period#Period":"Period与Duration类似，获取一个日期段，只不过单位为年月日，也可以通过of方法和between方法创建，between方法接收的参数为LocalDate。\nPeriod period = Period.of(1, 10, 25); Period period1 = Period.between(LocalDate.now(), LocalDate.now().plusYears(1)); ","zoneddatetime#ZonedDateTime":"ZonedDateTime类，用于处理带时区的日期和时间。它由两部分构成，LocalDateTime和ZoneId\nZoneId表示不同的时区。大约有40不同的时区。\n// 获取所有时区集合 Set allZoneIds = ZoneId.getAvailableZoneIds(); // 创建时区 ZoneId zoneId = ZoneId.of(\"Asia/Shanghai\"); // 把LocalDateTime转换成特定的时区 ZonedDateTime zonedDateTime = ZonedDateTime.of(LocalDateTime.now(), zoneId); 另外和时区一起使用的类是OffsetDateTime类，OffsetDateTime是不变的，表示date-time偏移，存储所有日期和时间字段，精确至纳秒，从UTC/Greenwich计算偏移。","其他历法#其他历法":"Java中使用的历法是ISO 8601日历系统，它是世界民用历法，也就是我们所说的公历。平年有365天，闰年是366天。闰年的定义是：非世纪年，能被4整除；世纪年能被400整除。为了计算的一致性，公元1年的前一年被当做公元0年，以此类推。\n此外Java 8还提供了4套其他历法，每套历法都包含一个日期类，分别是：\nThaiBuddhistDate：泰国佛教历 MinguoDate：中华民国历 JapaneseDate：日本历 HijrahDate：伊斯兰历 每个日期类都继承ChronoLocalDate类，所以可以在不知道具体历法的情况下也可以操作。不过这些历法一般不常用，除非是有某些特殊需求情况下才会使用。\n这些不同的历法也可以用于向公历转换：\nLocalDate date = LocalDate.now(); JapaneseDate jpDate = JapaneseDate.from(date); 由于它们都继承ChronoLocalDate类，所以在不知道具体历法情况下，可以通过ChronoLocalDate类操作日期：\nChronology jpChronology = Chronology.ofLocale(Locale.JAPANESE); ChronoLocalDate jpChronoLocalDate = jpChronology.dateNow(); 我们在开发过程中应该尽量避免使用ChronoLocalDate，尽量用与历法无关的方式操作时间，因为不同的历法计算日期的方式不一样，比如开发者会在程序中做一些假设，假设一年中有12个月，如果是中国农历中包含了闰月，一年有可能是13个月，但开发者认为是12个月，多出来的一个月属于明年的。再比如假设年份是累加的，过了一年就在原来的年份上加一，但日本天皇在换代之后需要重新纪年，所以过了一年年份可能会从1开始计算。\n在实际开发过程中建议使用LocalDate，包括存储、操作、业务规则的解读；除非需要将程序的输入或者输出本地化，这时可以使用ChronoLocalDate类。\n参考：\nhttps://blog.csdn.net/wo541075754/article/details/102545627 https://lw900925.github.io/java/java8-newtime-api.html ","时区#时区":"Java 8中的时区操作被很大程度上简化了，新的时区类java.time.ZoneId是原有的java.util.TimeZone类的替代品。ZoneId对象可以通过ZoneId.of()方法创建，也可以通过ZoneId.systemDefault()获取系统默认时区：\nZoneId shanghaiZoneId = ZoneId.of(\"Asia/Shanghai\"); ZoneId systemZoneId = ZoneId.systemDefault(); of()方法接收一个“区域/城市”的字符串作为参数，你可以通过getAvailableZoneIds()方法获取所有合法的“区域/城市”字符串：\nSet\u003cString\u003e zoneIds = ZoneId.getAvailableZoneIds(); 对于老的时区类TimeZone，Java 8也提供了转化方法：\nZoneId oldToNewZoneId = TimeZone.getDefault().toZoneId(); 有了ZoneId，我们就可以将一个LocalDate、LocalTime或LocalDateTime对象转化为ZonedDateTime对象：\nLocalDateTime localDateTime = LocalDateTime.now(); ZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, shanghaiZoneId); 将zonedDateTime打印到控制台为：\n2017-01-05T15:26:56.147+08:00[Asia/Shanghai] 另一种表示时区的方式是使用ZoneOffset，它是以当前时间和世界标准时间（UTC）/格林威治时间（GMT）的偏差来计算，例如：\nZoneOffset zoneOffset = ZoneOffset.of(\"+09:00\"); LocalDateTime localDateTime = LocalDateTime.now(); OffsetDateTime offsetDateTime = OffsetDateTime.of(localDateTime, zoneOffset); ","时间日期格式化#时间日期格式化":"增加和减少日期 Java 8中的日期/时间类都是不可变的，这是为了保证线程安全。当然，新的日期/时间类也提供了方法用于创建对象的可变版本，比如增加一天或者减少一天：\nLocalDate date = LocalDate.of(2017, 1, 5); // 2017-01-05 LocalDate date1 = date.withYear(2016); // 修改为 2016-01-05 LocalDate date2 = date.withMonth(2); // 修改为 2017-02-05 LocalDate date3 = date.withDayOfMonth(1); // 修改为 2017-01-01 LocalDate date4 = date.plusYears(1); // 增加一年 2018-01-05 LocalDate date5 = date.minusMonths(2); // 减少两个月 2016-11-05 LocalDate date6 = date.plus(5, ChronoUnit.DAYS); // 增加5天 2017-01-10 上面例子中对于日期的操作比较简单，但是有些时候我们要面临更复杂的时间操作，比如将时间调到下一个工作日，或者是下个月的最后一天，这时候我们可以使用with()方法的另一个重载方法，它接收一个TemporalAdjuster参数，可以使我们更加灵活的调整日期：\nLocalDate date7 = date.with(nextOrSame(DayOfWeek.SUNDAY)); // 返回下一个距离当前时间最近的星期日 LocalDate date9 = date.with(lastInMonth(DayOfWeek.SATURDAY)); // 返回本月最后一个星期六 TemporalAdjusters类中包含了很多静态方法可以直接使用，下面的表格列出了一些方法：\n方法名 描述 dayOfWeekInMonth 返回同一个月中每周的第几天 firstDayOfMonth 返回当月的第一天 firstDayOfNextMonth 返回下月的第一天 firstDayOfNextYear 返回下一年的第一天 firstDayOfYear 返回本年的第一天 firstInMonth 返回同一个月中第一个星期几 lastDayOfMonth 返回当月的最后一天 lastDayOfNextMonth 返回下月的最后一天 lastDayOfNextYear 返回下一年的最后一天 lastDayOfYear 返回本年的最后一天 lastInMonth 返回同一个月中最后一个星期几 next / previous 返回后一个/前一个给定的星期几 nextOrSame / previousOrSame 返回后一个/前一个给定的星期几，如果这个值满足条件，直接返回 如果上面表格中列出的方法不能满足你的需求，你还可以创建自定义的TemporalAdjuster接口的实现，TemporalAdjuster也是一个函数式接口，所以我们可以使用Lambda表达式：\n@FunctionalInterface public interface TemporalAdjuster { Temporal adjustInto(Temporal temporal); } 比如给定一个日期，计算该日期的下一个工作日（不包括星期六和星期天）：\nLocalDate date = LocalDate.of(2017, 1, 5); date.with(temporal -\u003e { // 当前日期 DayOfWeek dayOfWeek = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); // 正常情况下，每次增加一天 int dayToAdd = 1; // 如果是星期五，增加三天 if (dayOfWeek == DayOfWeek.FRIDAY) { dayToAdd = 3; } // 如果是星期六，增加两天 if (dayOfWeek == DayOfWeek.SATURDAY) { dayToAdd = 2; } return temporal.plus(dayToAdd, ChronoUnit.DAYS); }); 格式化日期 Java 8对日期的格式化操作非常简单，首先看到上面的类大多都提供了parse方法，可以直接通过解析字符串得到对应的对象。\nString strDate6 = \"2017-01-05\"; String strDate7 = \"2017-01-05 12:30:05\"; LocalDate date = LocalDate.parse(strDate6, DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); LocalDateTime dateTime1 = LocalDateTime.parse(strDate7, DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")); Java 8的日期类有一个format()方法用于将日期格式化为字符串，该方法接收一个DateTimeFormatter类型参数。可以使用DateTimeFormatter预置的格式，也可以通过DateTimeFormatter.ofPattern方法来指定格式。\nLocalDateTime dateTime = LocalDateTime.now(); String str = dateTime.format(DateTimeFormatter.ISO_LOCAL_DATE_TIME); System.out.println(str); str = dateTime.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); System.out.println(str); // 今天是：2017年 一月 05日 星期四 str = dateTime.format(DateTimeFormatter.ofPattern(\"今天是：YYYY年 MMMM DD日 E\", Locale.CHINESE)); ","相关背景#相关背景":"Java对日期、日历及时间的处理一直以来都饱受诟病：\njava.util.Date和java.util.Calendar类易用性差，不支持时区，非线程安全 用于格式化日期的类DateFormat被放在java.text包中，它是一个抽象类，所以我们需要实例化一个SimpleDateFormat对象来处理日期格式化，并且DateFormat也是非线程安全，这意味着如果你在多线程程序中调用同一个DateFormat对象，会得到意想不到的结果。 对日期的计算方式繁琐，而且容易出错，因为月份是从0开始的，从Calendar中获取的月份需要加一才能表示当前月份。 由于以上这些问题，出现了一些三方的日期处理框架，例如Joda-Time，date4j等开源项目。但是，Java需要一套标准的用于处理时间和日期的框架，于是Java 8中引入了新的日期API。新的日期API是JSR-310规范的实现，Joda-Time框架的作者正是JSR-310的规范的倡导者，所以能从Java 8的日期API中看到很多Joda-Time的特性。","简介#简介":"新的API对时间日期的处理提供了更好的支持，清楚的定义了时间日期的一些概念，比如说，瞬时时间（Instant）,持续时间（duration），日期（date）,时间（time），时区（time-zone）以及时间段（Period）。\n新的时间日期API核心位于java.time内，另外也在java.time.chrono，java.time.format，java.time.temporal和java.time.zone有相关的API，但使用频次较少。时间与日期API中的所有类都是线程安全的。\nJava 8常用的日期和时间类主要包括包含：\nLocalDate：不包含时间的日期，比如2019-10-14。可以用来存储生日，周年纪念日，入职日期等。 LocalTime：与LocalDate想对照，它是不包含日期的时间。 LocalDateTime：包含了日期及时间，没有偏移信息（时区）。 ZonedDateTime：包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。 Instant：时间戳，与System.currentTimeMillis()类似。 Duration：表示一个时间段。 Period：用来表示以年月日来衡量一个时间段。 "},"title":"Java 8新特性 - (9)DateTime API"},"/blog/2021/06/java8_hotspot_remove_permgen/":{"data":{"":" ","jdk-6jdk-7jdk-8-内存模型演变#JDK 6、JDK 7、JDK 8 内存模型演变":"\n这些版本的JVM内存模型主要有以下差异：\nJDK 6：有永久代，静态变量存放在永久代上。 JDK 7：有永久代，但已经把字符串常量池、静态变量，存放在堆上。逐渐地减少永久代的使用。 JDK 8：无永久代，运行时常量池、类常量池，都保存在元数据区，也就是常说的元空间。但字符串常量池仍然存放在堆上。 ","为什么废弃永久代permgen#为什么废弃永久代（PermGen）":"参照官方说明 JEP122：http://openjdk.java.net/jeps/122：\nMotivation This is part of the JRockit and Hotspot convergence effort. JRockit customers do not need to configure the permanent generation (since JRockit does not have a permanent generation) and are accustomed to not configuring the permanent generation.\n即：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代。\n同时，在实际使用过程中，由于永久代内存经常不够用或发生内存泄露，容易爆出异常java.lang.OutOfMemoryError: PermGen。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。","内存模型各区域概要#内存模型各区域概要":"程序计数器 较小的内存空间、线程私有，记录当前线程所执行的字节码行号。 如果执行 Java 方法，计数器记录虚拟机字节码当前指令的地址，本地方法则为空。 这一块区域没有任何 OutOfMemoryError 定义。 Java虚拟机栈 每一个方法在执行的同时，都会创建出一个栈帧，用于存放局部变量表、操作数栈、动态链接、方法出口、线程等信息。 方法从调用到执行完成，都对应着栈帧从虚拟机中入栈和出栈的过程。 最终，栈帧会随着方法的创建到结束而销毁。 本地方法栈 本地方法栈与Java虚拟机栈作用类似，唯一不同的就是本地方法栈执行的是Native方法，而虚拟机栈是为JVM执行Java方法服务的。 与 Java 虚拟机栈一样，本地方法栈也会抛出 StackOverflowError 和 OutOfMemoryError 异常。 Java 8 HotSpot虚拟机直接就把本地方法栈和虚拟机栈合二为一。 堆和元空间 Java 8 JVM 的内存结构主要由三大块组成：堆内存、元空间和栈，Java 堆是内存空间占据最大的一块区域。\nJava 堆，由年轻代和年老代组成，分别占据1/3和2/3。 而年轻代又分为三部分，Eden、From Survivor、To Survivor，占据比例为8:1:1，可调。 这里特意画出了元空间，也就是直接内存区域。在 Java 8 之后就不在堆上分配方法区了。 元空间从虚拟机Java堆中转移到本地内存，默认情况下，元空间的大小仅受本地内存的限制，说白了也就是以后不会因为永久代空间不够而抛出OOM异常出现了。Java 8以前版本的 class和JAR包数据存储在 PermGen下面 ，PermGen 大小是固定的，而且项目之间无法共用，公有的 class，所以比较容易出现OOM异常。 常量池 从 Java 7开始把常量池从永久代中剥离，直到 Java 8 去掉了永久代。而字符串常量池一直放在堆空间，用于存储字符串对象，或是字符串对象的引用。","深入理解元空间metaspace#深入理解元空间（Metaspace）":"元空间的内存大小 元空间是方法区的在HotSpot jvm 中的实现，方法区主要用于存储类的信息、常量池、方法数据、方法代码等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。\n元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。，理论上取决于32位/64位系统可虚拟的内存大小。可见也不是无限制的，需要配置参数。\n常用配置参数 MetaspaceSize\n初始化的Metaspace大小，控制元空间发生GC的阈值。GC后，动态增加或降低MetaspaceSize。在默认情况下，这个值大小根据不同的平台在12M到20M浮动。使用Java -XX:+PrintFlagsInitial命令查看本机的初始化参数 MaxMetaspaceSize\n限制Metaspace增长的上限，防止因为某些情况导致Metaspace无限的使用本地内存，影响到其他程序。在本机上该参数的默认值为4294967295B（大约4096MB）。 MinMetaspaceFreeRatio\n当进行过Metaspace GC之后，会计算当前Metaspace的空闲空间比，如果空闲比小于这个参数（即实际非空闲占比过大，内存不够用），那么虚拟机将增长Metaspace的大小。默认值为40，也就是40%。设置该参数可以控制Metaspace的增长的速度，太小的值会导致Metaspace增长的缓慢，Metaspace的使用逐渐趋于饱和，可能会影响之后类的加载。而太大的值会导致Metaspace增长的过快，浪费内存。 MaxMetasaceFreeRatio\n当进行过Metaspace GC之后， 会计算当前Metaspace的空闲空间比，如果空闲比大于这个参数，那么虚拟机会释放Metaspace的部分空间。默认值为70，也就是70%。 MaxMetaspaceExpansion\nMetaspace增长时的最大幅度。在本机上该参数的默认值为5452592B（大约为5MB）。 MinMetaspaceExpansion\nMetaspace增长时的最小幅度。在本机上该参数的默认值为340784B（大约为330KB）。 参考：\nhttps://www.cnblogs.com/paddix/p/5309550.html https://www.cnblogs.com/dennyzhangdd/p/6770188.html https://segmentfault.com/a/1190000038862239 "},"title":"Java 8新特性 - (14)Hotspot删除永久代"},"/blog/2021/06/java8_optional/":{"data":{"":" 相关文章： Java 9对Optional类的改进\nJava 8中引入了Optional类来解决 NullPointerException 与繁琐的 null 检查。它是一个封装值的类，用于保存类型为T的值，从本质上说它就是一个容器。\n变量存在时，Optional类只是对类简单封装。变量不存在时，缺失的值会被建模成一个“空” 的Optional对象，由方法Optional.empty()返回。那null和 Optional.empty()的区别在哪呢？从语义上，可以把它们当作一回事儿，但是实际中它们之间的差别非常大：如果尝试解引用一个null， 一定会触发NullPointerException，而使用Optional.empty()就完全没事，它是 Optional类的一个有效对象。","创建-optional-对象#创建 Optional 对象":"空Optional 可以通过静态工厂方法 Optional.empty，创建一个空的 Optional 对象：\nOptional\u003cCar\u003e option = Optional.empty(); 因为 empty() 本身代表的就是空对象，所以调用 get 方法会抛出 NoSuchElementException 异常。\n非空Optional 可以使用静态工厂方法 Optional.of，依据一个非空值创建一个 Optional 对象：\nOptional\u003cCar\u003e optional = Optional.of(car); 如果 car 是一个 null，这段代码会立即抛出一个 NullPointerException，而不是等到试图访问car的属性值时才返回一个错误。\n可为null的Optional 使用静态工厂方法 Optional.ofNullable，可以创建一个允许 null 值的 Optional 对象：\nOptional\u003cCar\u003e optional = Optional.ofNullable(car); 如果 car 是 null，那么得到的 Optional 对象就是个空对象。我们可以查看一下它的实现原理：\npublic static \u003cT\u003e Optional\u003cT\u003e ofNullable(T value) { return value == null ? empty() : of(value); } 根据它的实现方式，传入的值是空值时，会返回 Optional.empty() 空对象。这有利于封装那些可能为 null 的值。例如，有一个 Map\u003cString, Object\u003e 实例，访问 key 索引时，如果没有与 key 关联的值，则会返回一个 null。因此，可以使用 Optional.ofNullable 方法封装返回值：\nOptional\u003cObject\u003e value = Optional.ofNullable(map.get(\"key\")); ","对值进行转换#对值进行转换":"map Optional 提供了 map 方法用于从对象中提取信息，它的工作原理如下：\npublic\u003cU\u003e Optional\u003cU\u003e map(Function\u003c? super T, ? extends U\u003e mapper) { Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else { return Optional.ofNullable(mapper.apply(value)); } } map 操作会将提供的函数应用于流的每个元素。可以把 Optional 对象看成一种特殊的集合数据，它至多包含一个元素。如果 Optional 包含一个值，那通过实现了 Function 接口的 Lambda 表达式对值进行转换。map 方法示例如下：\nclass Car { private String name; private String type; //...省略getter与setter... } Optional\u003cCar\u003e optional = Optional.ofNullable(car); Optional\u003cString\u003e name = optional.map(Car::getName); flatMap 看下面这段代码，它想使用 map 方法来从被 Optional 类包装的 Person 类中获取 Car 的名称：\nclass Person { private Optional\u003cCar\u003e car; public Person(Car car) { this.car = Optional.of(car); } //...省略getter与setter... } Person person = new Person(new Car()); Optional\u003cPerson\u003e optPerson = Optional.of(person); Optional\u003cString\u003e name = optPerson.map(Person::getCar).map(Car::getName); 不幸的是，这段代码无法通过编译。为什么呢？optPerson 是 Optional 类型的变量，调用 map 方法应该没有问题。但 getCar 返回的是一个 Optional 类型的对象，这意味着 map 操作的结果是一个 Optional\u003cOptional\u003e 类型的对象。因此，它对 getName 的调用是非法的，因为最外层的 optional 对象包含了另一个 optional 对象的值，而它当然不会支持 getName 方法。\n这里，需要使用 flatMap 方法。该方法接受一个函数作为参数，这个函数的返回值是另一个流。\npublic \u003cU\u003e Optional\u003cU\u003e flatMap(Function\u003c? super T, ? extends Optional\u003c? extends U\u003e\u003e mapper) { Objects.requireNonNull(mapper); if (!isPresent()) { return empty(); } else { @SuppressWarnings(\"unchecked\") Optional\u003cU\u003e r = (Optional\u003cU\u003e) mapper.apply(value); return Objects.requireNonNull(r); } } 参照 map 函数，使用 flatMap 重写上述的示例：\nOptional\u003cString\u003e name = optPerson.flatMap(Person::getCar).map(Car::getName); filter 有时候我们需要对 Optional 中的值进行过滤，获得我们需要的结果，我们就可以使用 filter 方法：\npublic Optional\u003cT\u003e filter(Predicate\u003c? super T\u003e predicate) { Objects.requireNonNull(predicate); if (!isPresent()) return this; else return predicate.test(value) ? this : empty(); } 该方法接受 Predicate 谓词作为参数。如果 Optional 对象的值存在，并且符合谓词的条件，即操作结果为true，filter 方法不做任何改变并返回其值；否则就将该值过滤掉并返回一个空的 Optional 对象。\nOptional\u003cString\u003e optionalS = Optional.of(\"13846901234\"); optionalS = optionalS.filter(s -\u003e s.contains(\"138\")); /** * 上述 `filter` 方法满足条件可以返回同一个Optional，否则返回空Optional */ ","注意事项#注意事项":" Optional的包装和访问都有成本，因此不适用于一些特别注重性能和内存的场景。 不要将null赋给Optional，应赋以Optional.empty()。 避免调用isPresent()和get()方法，而应使用ifPresent()、orElse()、 orElseGet()和orElseThrow()。举一isPresent()用法示例： private static boolean isIntegerNumber(String number) { number = number.trim(); String intNumRegex = \"\\\\-{0,1}\\\\d+\"; if (number.matches(intNumRegex)) { return true; } else { return false; } } // Optional写法1（含NPE修复及正则表达式优化） private static boolean isIntegerNumber1(String number) { return Optional.ofNullable(number) .map(String::trim) .filter(n -\u003e n.matches(\"-?\\\\d+\")) .isPresent(); } // Optional写法2（含NPE修复及正则表达式优化，不用isPresent） private static boolean isIntegerNumber2(String number) { return Optional.ofNullable(number) .map(String::trim) .map(n -\u003e n.matches(\"-?\\\\d+\")) .orElse(false); } Optional应该只用处理返回值，而不应作为类的字段(Optional类型不可被序列化)或方法(包括constructor)的参数。 不要为了链式方法而使用Optional，尤其是在仅仅获取一个值时。例如： // good return variable == null ? \"blablabla\" : variable; // bad return Optional.ofNullable(variable).orElse(\"blablabla\"); // bad Optional.ofNullable(someVariable).ifPresent(this::blablabla) 滥用Optional不仅影响性能，可读性也不高。应尽可能避免使用null引用。 避免使用Optional返回空的集合或数组，而应返回Collections.emptyList()、emptyMap()、emptySet()或new Type[0]。注意不要返回null，以便调用者可以省去繁琐的null检查。 避免在集合中使用Optional，应使用getOrDefault()或computeIfAbsent()等集合方法。 针对基本类型，使用对应的OptionalInt、OptionalLong和OptionalDouble类。 切忌过度使用Optional，否则可能使代码难以阅读和维护。 常见的问题是Lambda表达式过长，例如： private Set\u003cString\u003e queryValidUsers() { Set\u003cString\u003e userInfo = new HashSet\u003cString\u003e(10); Optional.ofNullable(toJSonObject(getJsonStrFromSomewhere())) .map(cur -\u003e cur.optJSONArray(\"data\")) .map(cur -\u003e { // 大段代码割裂了\"思路\" for (int i = 0; i \u003c cur.length(); i++) { JSONArray users = cur.optJSONObject(i).optJSONArray(\"users\"); if (null == users || 0 == users.length()) { continue; } for (int j = 0; j \u003c users.length(); j++) { JSONObject userObj = users.optJSONObject(j); if (!userObj.optBoolean(\"stopUse\")) { // userObj可能为null! userInfo.add(userObj.optString(\"userId\")); } } } return userInfo; }); return userInfo; } 通过简单的抽取方法，可读性得到很大提高：\nprivate Set\u003cString\u003e queryValidUsers() { return Optional.ofNullable(toJSonObject(getJsonStrFromSomewhere())) .map(cur -\u003e cur.optJSONArray(\"data\")) .map(this::collectNonStopUsers) .orElse(Collections.emptySet()); } private Set\u003cString\u003e collectNonStopUsers(JSONArray dataArray) { Set\u003cString\u003e userInfo = new HashSet\u003cString\u003e(10); for (int i = 0; i \u003c dataArray.length(); i++) { JSONArray users = dataArray.optJSONObject(i).optJSONArray(\"users\"); Optional.ofNullable(users).ifPresent(cur -\u003e { for (int j = 0; j \u003c cur.length(); j++) { Optional.ofNullable(cur.optJSONObject(j)) .filter(user -\u003e !user.optBoolean(\"stopUse\")) .ifPresent(user -\u003e userInfo.add(user.optString(\"userId\"))); } }); } return userInfo; } 参考：\nhttps://segmentfault.com/a/1190000038471657 https://www.jianshu.com/p/63830b7cb743 https://www.cnblogs.com/clover-toeic/p/10906824.html ","访问optional对象的值#访问Optional对象的值":"isPresent \u0026 get 在 Optional 类中，isPresent 方法对 Optional 实例进行判断，是否包含值，如果存在值，就返回 true，否则返回 false；与之相对的是 isEmpty 方法Optional 类中还有 get 方法，它是用来获取 Optional 实例中的值。\nOptional\u003cString\u003e optional = Optional.of(\"is present\"); if (optional.isPresent()) { System.out.println(\"the value is \" + optional.get()); } isPresent 与 get 一般组合使用来避免 NullPointerException：\npublic boolean isPresent() { return value != null; } public T get() { if (value == null) { throw new NoSuchElementException(\"No value present\"); } return value; } 从源码中可看出，get 方法在取值时，要进行判空操作，如果不使用 isPresent 方法，可能会出现空指针异常。但是这种方式和在代码中if(null != value) 没有区别，因此要尽量避免使用该组合\nifPresent 除了 isPresent 的简洁方法，Optional 还提供了接收函数式参数的接口 ifPresent：\npublic void ifPresent(Consumer\u003c? super T\u003e action) { if (value != null) { action.accept(value); } } 该方法会接收一个消费型函数。如果 Optional 实例中的值不为空，则调用 Consumer 的 accept 方法对 value 进行消费，若为空则不做处理。上面的例子可以使用 ifPresent 重写：\nOptional\u003cString\u003e optional = Optional.of(\"is present\"); optional.isPresent((val) -\u003e System.out.println(\"the value is \" + val)); 返回默认值 orElse 还可以使用 orElse 方法读取 Optional 中的值。\npublic T orElse(T other) { return value != null ? value : other; } 使用这种方式可以定义一个默认值，这种方式当遭遇 Optional 中的变量为空时，默认值会作为该方法的返回值。\nString optGet = null; String orElse = Optional.ofNullable(optGet).orElse(\"Default\"); orElseGet 还可以使用另一种方式 orElseGet：\npublic T orElseGet(Supplier\u003c? extends T\u003e supplier) { return value != null ? value : supplier.get(); } 该方法与 orElse 的区别就是值不存在时，调用实现 Supplier 接口的方法或Lambda表达式来返回默认值。\nString optGet = null; String orElse = Optional.ofNullable(optGet).orElse(() -\u003e \"Default\"); 返回异常 orElseThrow orElseThrow方法是在有值时返回其值，无值的时候会抛出由 Supplier 创建的异常。我们看一下它的实现原理：\npublic \u003cX extends Throwable\u003e T orElseThrow(Supplier\u003c? extends X\u003e exceptionSupplier) throws X { if (value != null) { return value; } else { throw exceptionSupplier.get(); } } 可以看到，它会传入一个Lambda表达式或方法，如果值不存在来抛出异常：\nclass NoValueException extends RuntimeException { public NoValueException() { super(); } @Override public String getMessage() { return \"No value present in the Optional instance\"; } } public static Integer orElseThrow() { return (Integer) Optional.empty().orElseThrow(NoValueException::new); } public static void main(String[] args) { orElseThrow(); } orElseThrow 与 orElseGet 的区别就是一个在无值的时候抛出异常，一个在无值的时候使用Lambda表达式来实现默认值。\norElseThrow 只是在无值的时候抛出异常，那本身会抛出异常的方法呢？\n现在拿 Integer.parseInt(String) 做个例子：\npublic static Integer toInt(String s) { try { // 如果String能转换为对应的Integer，将其封装在Optional对象中返回 return Integer.parseInt(s); } catch (NumberFormatException e) { return null; // 返回null 或者抛出异常 } } 在将 String 转换为 int 时，如果无法解析到对应的整型，该方法会抛出 NumberFormatException 异常。我们在该方法中使用 try/catch 语句捕获了该异常，不能使用 if 条件判断来控制一个变量的值是否为空。\n这时，可以使用 Optional 类，来对无法转换的 String 时返回的非法值进行建模，因此可以对上述方法进行改进：\npublic static Optional\u003cInteger\u003e toInt(String s) { try { // 如果String能转换为对应的Integer，将其封装在Optional对象中返回 return Optional.of(Integer.parseInt(s)); } catch (NumberFormatException e) { return Optional.empty(); // 否则返回一个空的 Optional 对象 } } 这种返回 Optional 的方式适用很多方法，我们只需要获取被 Optional 包装的值的实例即可。"},"title":"Java 8新特性 - (15)Optional类"},"/blog/2021/06/java8_parallel_sort/":{"data":{"":"在Java 7中已经有了Arrays.sort()方法可对对象进行排序，而在Java 8中，引入了新的并行排序，它比前者的排序速度更快，且遵循了Java 7引入的Fork/Join框架，可以把排序任务分配给线程池中可用的多个线程。 Java 8在java.util.Arrays类中新增了并行排序功能，能够更充分地利用多线程机制，最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序\n并行排序算法：\n将给定的数组划分为子数组，将子数组进一步划分为子数组，直到子数组达到最小粒度为止。 子数组由多个线程单独排序。并行排序使用 Fork / Join Framework 并行地对子数组进行排序。 已合并的已排序子数组。 // 对原始数据类型进行并行排序 // 输出：1 5 19 22 32 89 int numbers[] = {22, 89, 1, 32, 19, 5}; Arrays.parallelSort(numbers); // 通过指定开始和结束索引进行并行排序。 // 在这种情况下，从开始索引开始并在结束索引结束的子数组被排序，数组的其余部分被忽略并且不被排序。 // 输出：22 1 19 32 89 5 int numbers[] = {22, 89, 1, 32, 19, 5}; Arrays.parallelSort(numbers, 1, 5); 参考：\nhttps://www.jianshu.com/p/2f038115de06 https://www.yuque.com/apachecn/beginnersbook-zh/docs_java_69 "},"title":"Java 8新特性 - (10)并行数组排序"},"/blog/2021/06/java8_stamped_lock/":{"data":{"":"","lock#Lock":"","stampedlock#StampedLock":" synchronized 在java5之前，实现同步主要是使用synchronized。它是Java语言的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。 有四种不同的同步块:\n实例方法 静态方法 实例方法中的同步块 静态方法中的同步块 在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，性能上也有所提升。\nLock 它是Java 5在java.util.concurrent.locks新增的一个API。\nLock是一个接口，核心方法是lock()，unlock()，tryLock()，实现类有ReentrantLock, ReentrantReadWriteLock.ReadLock, ReentrantReadWriteLock.WriteLock； ReentrantReadWriteLock, ReentrantLock 和synchronized锁都有相同的内存语义。\n与synchronized不同的是，Lock完全用Java写成，在java这个层面是无关JVM实现的。Lock提供更灵活的锁机制，很多synchronized 没有提供的许多特性，比如锁投票，定时锁等候和中断锁等候，但因为lock是通过代码实现的，要保证锁定一定会被释放，就必须将unLock()放到finally{}中\nStampedLock StampedLock是java.util.concurrent.locks包里面jdk 8版本新增的一个锁，该锁提供了三种模式的读写控制，三种模式分别如下：\n写锁 writeLock\n是个排它锁或者叫独占锁，同时只有一个线程可以获取该锁，当一个线程获取该锁后，其它请求的线程必须等待，当目前没有线程持有读锁或者写锁的时候才可以获取到该锁，请求该锁成功后会返回一个stamp票据变量用来表示该锁的版本，当释放该锁时候需要unlockWrite并传递参数stamp。 悲观读锁 readLock\n是个共享锁，在没有线程获取独占写锁的情况下，同时多个线程可以获取该锁，如果已经有线程持有写锁，其他线程请求获取该读锁会被阻塞。这里讲的悲观其实是参考数据库中的乐观悲观锁的，这里说的悲观是说在具体操作数据前悲观的认为其他线程可能要对自己操作的数据进行修改，所以需要先对数据加锁，这是在读少写多的情况下的一种考虑,请求该锁成功后会返回一个stamp票据变量用来表示该锁的版本，当释放该锁时候需要unlockRead并传递参数stamp。 乐观读锁 tryOptimisticRead\n是相对于悲观锁来说的，在操作数据前并没有通过CAS设置锁的状态，如果当前没有线程持有写锁，则简单的返回一个非0的stamp版本信息，获取该stamp后在具体操作数据前还需要调用validate验证下该stamp是否已经不可用，也就是看当调用tryOptimisticRead返回stamp后到到当前时间间是否有其他线程持有了写锁，如果是那么validate会返回0，否者就可以使用该stamp版本的锁对数据进行操作。由于tryOptimisticRead并没有使用CAS设置锁状态所以不需要显示的释放该锁。该锁的一个特点是适用于读多写少的场景，因为获取读锁只是使用与或操作进行检验，不涉及CAS操作，所以效率会高很多，但是同时由于没有使用真正的锁，在保证数据一致性上需要拷贝一份要操作的变量到方法栈，并且在操作数据时候可能其他写线程已经修改了数据，而我们操作的是方法栈里面的数据，也就是一个快照，所以最多返回的不是最新的数据，但是一致性还是得到保障的。 class Point { // 成员变量 private double x, y; // 锁实例 private final StampedLock sl = new StampedLock(); // 排它锁-写锁（writeLock） void move(double deltaX, double deltaY) { long stamp = sl.writeLock(); try { x += deltaX; y += deltaY; } finally { sl.unlockWrite(stamp); } } // 乐观读锁（tryOptimisticRead） double distanceFromOrigin() { // 尝试获取乐观读锁（1） long stamp = sl.tryOptimisticRead(); // 将全部变量拷贝到方法体栈内（2） double currentX = x, currentY = y; // 检查在（1）获取到读锁票据后，锁有没被其他写线程排它性抢占（3） if (!sl.validate(stamp)) { // 如果被抢占则获取一个共享读锁（悲观获取）（4） stamp = sl.readLock(); try { // 将全部变量拷贝到方法体栈内（5） currentX = x; currentY = y; } finally { // 释放共享读锁（6） sl.unlockRead(stamp); } } // 返回计算结果（7） return Math.sqrt(currentX * currentX + currentY * currentY); } // 使用悲观锁获取读锁，并尝试转换为写锁 void moveIfAtOrigin(double newX, double newY) { // 这里可以使用乐观读锁替换（1） long stamp = sl.readLock(); try { // 如果当前点在原点则移动（2） while (x == 0.0 \u0026\u0026 y == 0.0) { // 尝试将获取的读锁升级为写锁（3） long ws = sl.tryConvertToWriteLock(stamp); // 升级成功，则更新票据，并设置坐标值，然后退出循环（4） if (ws != 0L) { stamp = ws; x = newX; y = newY; break; } else { // 读锁升级写锁失败则释放读锁，显示获取独占写锁，然后循环重试（5） sl.unlockRead(stamp); stamp = sl.writeLock(); } } } finally { // 释放锁（6） sl.unlock(stamp); } } } 使用乐观读锁还是很容易犯错误的，必须要小心，必须要保证如下的使用顺序：\nlong stamp = lock.tryOptimisticRead(); //非阻塞获取版本信息 copyVaraibale2ThreadMemory();//拷贝变量到线程本地堆栈 if(!lock.validate(stamp)){ // 校验 long stamp = lock.readLock();//获取读锁 try { copyVaraibale2ThreadMemory();//拷贝变量到线程本地堆栈 } finally { lock.unlock(stamp);//释放悲观锁 } } useThreadMemoryVarables();//使用线程本地堆栈里面的数据进行操作 ","synchronized#synchronized":"","总结#总结":" synchronized是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized的锁定，而且在代码执行时出现异常，JVM会自动释放锁定 ReentrantLock、ReentrantReadWriteLock,、StampedLock都是对象层面的锁定，要保证锁定一定会被释放，就必须将unLock()放到finally{}中 StampedLock 对吞吐量有巨大的改进，特别是在读线程越来越多的场景下 StampedLock有一个复杂的API，对于加锁操作，很容易误用其他方法 当只有少量竞争者的时候，synchronized是一个很好的通用的锁实现 当线程增长能够预估，ReentrantLock是一个很好的通用的锁实现 参考：\nhttps://www.pdai.tech/md/java/java8/java8-stampedlock.html https://ifeve.com/jdk8%E4%B8%ADstampedlock%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/ "},"title":"Java 8新特性 - (13)StampedLock"},"/blog/2021/06/java8_unsigned_arithmetic/":{"data":{"":"Java 8为整型包装类，增加类支持无符号运算的方法。注意：仅仅是在新增的运算方法中将long或者int当做无符号的数做运算，而本身java并不支持无符号的数据类型\nJava 8为Integer，Long新增如下方法:\n// 该方法将指定int货long型整数转换为无符号整数对应的字符串 static String toUnsignedString(int/long i) // 该方法将指定int或long型整数转换为指定进制的无符号整数对应的字符串 static String toUnsignedString(int i/long,int radix) // 该方法将指定字符串解析成无符号整数。当调用类为Integer时，xxx代表int；当调用类是Long时，xxx代表long static xxx parseUnsignedXxx(String s) // 该方法将指定字符串按指定进制解析成无符号整数。当调用类为Integer时，xxx代表int；当调用是Long时，xxx代表long static xxx parseUnsignedXxx(String s,int radix) // 该方法将x，y两个整数转换为无符号整数后比较大小。当调用类为Integer时，xxx代表int；当调用类是Long时，xxx代表long static int compareUnsigned(xxx x,xxx y) // 该方法将x、y两个整数转换为无符号整数后计算他们相除的商。当调用类为Integer时，xxx代表int；当调用类是Long时，xxx代表long static long divideUnsigned(long dividend,long divisor) // 该方法将x、y两个整数转换为无符号整数后计算他们相除的余数。当调用类为Integer是，xxx代表int；当调用类是Long时，xxx代表long static long remainderUnsigned(long dividend,long divisor) java 8还为Byte、Short增加了toUnsignedInt(xxx x) utoUnsignedLong(yyy x)两个方法，这两个方法用于将指定byte或short类型的变量或值转换成无符号的int或long值\n参考：\nhttps://blog.csdn.net/weixin_39788792/article/details/114201083 "},"title":"Java 8新特性 - (12)无符号运算"},"/blog/2021/06/java9_anonymous_inner_class_and_diamond_operator/":{"data":{"":"","java-9对菱形运算符的改进#Java 9对菱形运算符的改进":"Java 9 改进了菱形运算符的使用，并允许我们将菱形运算符与匿名内部类一起使用。用上面的例子，在 Java 9 中运行此代码，输出：\n201 参考：\nhttps://awesome.dbyun.net/study/details?mid=197\u0026id=9878 ","什么是菱形运算符#什么是菱形运算符":"菱形操作符是作为 java SE 7 中的新功能引入的。菱形操作符的目的是通过将泛型类型保留在表达式的右侧来避免冗余代码。\n// Java 7之前的写法 List\u003cstring\u003e myList = new ArrayList\u003cstring\u003e(); // Java 7及之后的写法 List\u003cstring\u003e myList = new ArrayList\u003c\u003e(); Java 7 允许我们在普通类中使用菱形运算符，但它不允许我们在匿名内部类中使用它们。\nabstract class MyClass\u003cT\u003e{ abstract T add(T num, T num2); } public class JavaExample { public static void main(String[] args) { MyClass\u003cInteger\u003e obj = new MyClass\u003c\u003e() { Integer add(Integer x, Integer y) { return x+y; } }; Integer sum = obj.add(100,101); System.out.println(sum); } } 上面的例子用Java 8编译会报错\n$javac JavaExample.java JavaExample.java:7: error: cannot infer type arguments for MyClass MyClass obj = new MyClass\u003c\u003e() { ^ reason: cannot use '\u003c\u003e' with anonymous inner classes where T is a type-variable: T extends Object declared in class MyClass 1 error "},"title":"Java 9新特性 - (2)匿名内部类与菱形运算符"},"/blog/2021/06/java9_interface_private_method/":{"data":{"":"在Java 7或更早版本中，一个接口中只能定义如下两种：\n常量 抽象方法 在Java 8中接口引入了默认方法和静态方法。可以在接口中编写方法实现，仅仅需要使用default关键字来定义它们。\nJava 9提供了新的功能,可以在接口中使用private关键字定义私有方法和私有静态方法，这些私有方法的作用是用于改善接口内部的代码可重用性。例如，如果需要两个默认方法来共享代码，则私有接口方法将允许它们共享代码，但不将该私有方法暴露给它的实现类调用。\n截止至Java 9，一个接口中能定义如下几种：\n常量 (Java 7及以前版本支持) 抽象方法 (Java 7及以前版本支持) 默认方法 （Java 8+） 静态方法 （Java 8+） 私有方法 （Java 9+） 私有静态方法 （Java 9+） 可以使用private访问修饰符在接口中编写私有方法。在接口中使用私有方法有四个规则：\n接口中private方法不能是abstract抽象方法。因为abstract抽象方法是公开的用于给接口实现类实现的方法，所以不能是private。 接口中私有方法只能在接口内部的方法里面被调用。 接口中私有静态方法可以在其他静态和非静态接口方法中使用。 接口中私有非静态方法不能在私有静态方法内部使用。 interface CustomInterface { public abstract void abstractMethod(); //抽象方法不能是私有的 public default void defaultMethod() { privateMethod(); //可以调用接口中的私有方法 privateStaticMethod(); //可以调用接口中的私有静态方法 System.out.println(\"普通方法被调用\"); } public static void staticMethod() { privateStaticMethod(); //public静态方法可以调用private静态方法 System.out.println(\"静态方法被调用\"); } private void privateMethod() { System.out.println(\"private私有方法被调用\"); } private static void privateStaticMethod() { System.out.println(\"private私有静态方法被调用\"); } } 参考：\nhttps://blog.csdn.net/tracydragonlxy/article/details/78082600 https://blog.csdn.net/hanxiaotongtong/article/details/109043531 "},"title":"Java 9新特性 - (1)接口中的私有方法"},"/blog/2021/06/java9_optional_enhancement/":{"data":{"":" 相关文章： Java 8引入Optional类\nOptional 类在 Java 8 中引入，Optional 类的引入很好的解决空指针异常。。在 java 9 中, 添加了三个方法来改进它的功能.","ifpresentorelse-方法#ifPresentOrElse() 方法":"语法\npublic void ifPresentOrElse(Consumer\u003c? super T\u003e action, Runnable emptyAction) ifPresentOrElse 方法的改进就是有了 else，接受两个参数 Consumer 和 Runnable。\nifPresentOrElse 方法的用途是，如果一个 Optional 包含值，则对其包含的值调用函数 action，即 action.accept(value)，这与 ifPresent 一致；与 ifPresent 方法的区别在于，ifPresentOrElse 还有第二个参数 emptyAction —— 如果 Optional 不包含值，那么 ifPresentOrElse 便会调用 emptyAction，即 emptyAction.run()。\n实例\nOptional\u003cInteger\u003e optional = Optional.of(1); optional.ifPresentOrElse( x -\u003e System.out.println(\"Value: \" + x), () -\u003e System.out.println(\"Not Present.\")); optional = Optional.empty(); optional.ifPresentOrElse( x -\u003e System.out.println(\"Value: \" + x), () -\u003e System.out.println(\"Not Present.\")); 执行输出结果为：\nValue: 1 Not Present. ","or-方法#or() 方法":"语法\npublic Optional\u003cT\u003e or(Supplier\u003c? extends Optional\u003c? extends T\u003e\u003e supplier) 如果值存在，返回 Optional 指定的值，否则返回一个预设的值。\n实例\nOptional\u003cString\u003e optional1 = Optional.of(\"Mahesh\"); Supplier\u003cOptional\u003cString\u003e\u003e supplierString = () -\u003e Optional.of(\"Not Present\"); optional1 = optional1.or( supplierString); optional1.ifPresent( x -\u003e System.out.println(\"Value: \" + x)); optional1 = Optional.empty(); optional1 = optional1.or( supplierString); optional1.ifPresent( x -\u003e System.out.println(\"Value: \" + x)); 执行输出结果为：\nValue: Mahesh Value: Not Present 参考java文档可以看出来or, orElse, orElseGet 区别，主要是在返回值与方法参数上\nModifier and Type Method Description Optional or​(Supplier\u003c? extends Optional\u003c? extends T» supplier) If a value is present, returns an Optional describing the value, otherwise returns an Optional produced by the supplying function. T orElse​(T other) If a value is present, returns the value, otherwise returns other. T orElseGet​(Supplier\u003c? extends T\u003e supplier) If a value is present, returns the value, otherwise returns the result produced by the supplying function. 参考：\nhttps://www.jianshu.com/p/63830b7cb743 https://www.jishuchi.com/read/java-lang/3033 https://docs.oracle.com/javase/9/docs/api/java/util/Optional.html ","stream-方法#stream() 方法":"语法\npublic Stream\u003cT\u003e stream() stream 方法的作用就是将 Optional 转为一个 Stream，如果该 Optional 中包含值，那么就返回包含这个值的 Stream，否则返回一个空的 Stream（Stream.empty()）。\n实例\nList\u003cOptional\u003cString\u003e\u003e list = Arrays.asList ( Optional.empty(), Optional.of(\"A\"), Optional.empty(), Optional.of(\"B\")); //filter the list based to print non-empty values //if optional is non-empty, get the value in stream, otherwise return empty List\u003cString\u003e filteredList = list.stream() .flatMap(o -\u003e o.isPresent() ? Stream.of(o.get()) : Stream.empty()) .collect(Collectors.toList()); //Optional::stream method will return a stream of either one //or zero element if data is present or not. List\u003cString\u003e filteredListJava9 = list.stream() .flatMap(Optional::stream) .collect(Collectors.toList()); System.out.println(filteredList); System.out.println(filteredListJava9); 执行输出结果为：\n[A, B] [A, B] "},"title":"Java 9新特性 - (5)Optional类中新增几个方法"},"/blog/2021/06/java9_safevarargs_enhancement/":{"data":{"":"Java 7 引入了@SafeVarargs注解来抑制当方法具有varargs（可变数量的参数）时出现的不安全操作警告,比如具有模糊类型（比如：泛型）的可变参数。@SafeVarargs注解只能用于无法覆盖的方法（final方法、static方法或构造函数），因为重写方法仍然可以对其 varargs（可变数量的参数）执行不安全操作。\nJava 9 扩展了@SafeVarargs注解的使用，它现在也可以与私有方法一起使用。这是因为私有方法也是无法覆盖的。\nJava 9 示例 - 当不使用@SafeVarargs注解时\nimport java.util.ArrayList; import java.util.List; public class JavaExample{ // We are not using @SafeVarargs annotation - Java 9 private void print(List... names) { for (List\u003cString\u003e name : names) { System.out.println(name); } } public static void main(String[] args) { JavaExample obj = new JavaExample(); List\u003cString\u003e list = new ArrayList\u003cString\u003e(); list.add(\"Kevin\"); list.add(\"Rick\"); list.add(\"Negan\"); obj.print(list); } } 编译时候，可以看到警告\nType safety: Potential heap pollution via varargs parameter names Type safety: A generic array of List is created for a varargs parameter 在Java 9中，使用@SafeVarargs注解后再次运行相同的代码, 没有看到警告信息\nimport java.util.ArrayList; import java.util.List; public class JavaExample{ @SafeVarargs private void print(List... names) { for (List\u003cString\u003e name : names) { System.out.println(name); } } public static void main(String[] args) { JavaExample obj = new JavaExample(); List\u003cString\u003e list = new ArrayList\u003cString\u003e(); list.add(\"Kevin\"); list.add(\"Rick\"); list.add(\"Negan\"); obj.print(list); } } 参考：\nhttps://www.kancloud.cn/apachecn/beginnersbook-zh/1955514 "},"title":"Java 9新特性 - (3)@SafeVarargs注解支持私有方法"},"/blog/2021/06/java9_unique_jvm_log/":{"data":{"":"Java 9新增了新的命令行选项-Xlog, 用于所有日志记录设置和统一的JVM日志记录\nXlog的参数遵循以下规则：\n已按照在命令行中显示的顺序应用了多个参数。 最后的配置规则：对于相同的输出，多个参数可以按给定的顺序相互覆盖。 -Xlog[:option] option := [\u003cwhat\u003e][:[\u003coutput\u003e][:[\u003cdecorators\u003e][:\u003coutput-options\u003e]]] 'help' 'disable' what := \u003cselector\u003e[,...] selector := \u003ctag-set\u003e[*][=\u003clevel\u003e] tag-set := \u003ctag\u003e[+...] 'all' tag := name of tag level := trace debug info warning error output := 'stderr' 'stdout' [file=]\u003cfilename\u003e decorators := \u003cdecorator\u003e[,...] 'none' decorator := time uptime timemillis uptimemillis timenanos uptimenanos pid tid level tags output-options := \u003coutput_option\u003e[,...] output-option := filecount=\u003cfile count\u003e filesize=\u003cfile size in kb\u003e parameter=values 下面的例子中，tag为gc，level为trace，rotate文件数为5，每个文件1M，文件名为gctrace.txt，decrotators为uptimemillis和pid\n-Xlog:gc=trace:file=gctrace.txt:uptimemillis,pid:filecount=5,filesize=1024 得到输出\n[1110ms][1867] GC(2) Pause Remark 17M-\u003e17M(256M) 2.024ms [1110ms][1867] GC(2) Finalize Live Data 0.000ms [1110ms][1867] GC(2) Pause Cleanup 17M-\u003e17M(256M) 0.177ms [1112ms][1867] GC(2) Concurrent Cycle 7.470ms [2951ms][1867] GC(3) Pause Initial Mark (Metadata GC Threshold) 149M-\u003e30M(256M) 27.175ms [2951ms][1867] GC(4) Concurrent Cycle [2972ms][1867] GC(4) Pause Remark 32M-\u003e32M(256M) 5.132ms [2974ms][1867] GC(4) Finalize Live Data 0.000ms [2974ms][1867] GC(4) Pause Cleanup 32M-\u003e32M(256M) 0.214ms [2976ms][1867] GC(4) Concurrent Cycle 25.422ms 旧版GC相关参数迁移，可以参考 https://docs.oracle.com/javase/9/tools/java.htm#JSWOR624\n参考：\nhttps://www.nhooo.com/note/qa0hdj.html https://segmentfault.com/a/1190000013475524 "},"title":"Java 9新特性 - (4)统一的JVM日志系统"},"/blog/2021/06/manjaro_installation_failure/":{"data":{"":"Manjaro 安装软件时报错：\n:: (1/1) Parsing SRCINFO: wps-office ==\u003e ERROR: Cannot find the strip binary required for object file stripping. error downloading sources: wps-office 这个是由于某些基础包没装，执行下面命令安装基础包，然后再次安装需要的软件即可\nsudo pacman -Sy base-devel "},"title":"Manjaro安装软件时找不到strip binary"},"/blog/2021/06/true_form_and_complement/":{"data":{"":"","位移运算#位移运算":"位移运算需要使用按位移动操作符，它有两个操作数：第一个是要被移动的数字，而第二个是要移动的长度。移动的方向根据操作符的不同而不同。\n按位移动会先将操作数转换为大端字节序顺序（big-endian order）的 32 位整数，并返回与左操作数相同类型的结果。右操作数应小于 32 位，否则只有最低 5 个字节会被使用。\n左移(«) 该操作符会将第一个操作数向左移动指定的位数。向左被移出的位被丢弃，右侧用 0 补充。以 9 « 2 为例：\n9 (base 10): 00000000000000000000000000001001 (base 2) -------------------------------- 9 \u003c\u003c 2 (base 10): 00000000000000000000000000100100 (base 2) = 36 (base 10) 在数字 x 上左移 y 位时，得出的结果是 x * 2^y，即 9 « 2 = 9 * 2^2。\n有符号右移(») 该操作符会将第一个操作数向右移动指定的位数。向右被移出的位被丢弃，拷贝最左侧的位以填充左侧。由于新的最左侧的位总是和以前相同，符号位没有被改变。所以被称作 “符号传播”。\n例如， 9 » 2 得到 2：\n9 (base 10): 00000000000000000000000000001001 (base 2) -------------------------------- 9 \u003e\u003e 2 (base 10): 00000000000000000000000000000010 (base 2) = 2 (base 10) 相比之下， -9 » 2 得到 -3，因为符号被保留了。\n-9 (base 10): 11111111111111111111111111110111 (base 2) -------------------------------- -9 \u003e\u003e 2 (base 10): 11111111111111111111111111111101 (base 2) = -3 (base 10) 无符号右移(»\u003e) 该操作符会将第一个操作数向右移动指定的位数。向右被移出的位被丢弃，左侧用 0 填充。因为符号位变成了 0，所以结果总是非负的。\n对于非负数，有符号右移和无符号右移总是返回相同的结果。例如 9 »\u003e 2 和 9 » 2 一样返回 2：\n9 (base 10): 00000000000000000000000000001001 (base 2) -------------------------------- 9 \u003e\u003e\u003e 2 (base 10): 00000000000000000000000000000010 (base 2) = 2 (base 10) 但是对于负数却不尽相同。 -9 »\u003e 2 产生 1073741821 这和 -9 » 2 不同：\n-9 (base 10): 11111111111111111111111111110111 (base 2) -------------------------------- -9 \u003e\u003e\u003e 2 (base 10): 00111111111111111111111111111101 (base 2) = 1073741821 (base 10) -9 \u003e\u003e 2 (base 10): 11111111111111111111111111111101 (base 2) = -3 (base 10) 参考：\nhttps://segmentfault.com/a/1190000021511009 ","原码反码和补码#原码、反码和补码":"为运算方便，机器数有 3 种表示法，即原码、反码和补码。\n原码 原码是一种计算机中对数字的二进制定点表示法。原码表示法在数值前面增加了一位符号位（即最高位为符号位）：正数该位为 0，负数该位为 1（0 有两种表示：+0 和 -0），其余位表示数值的大小。\n反码 一个数字用原码表示是容易理解的，但是需要单独一个位来表示符号位，并且在进行加法时，计算机需要先识别某个二进制原码是正数还是负数，识别出来之后再进行相应的运算。这样效率不高，能不能让计算机在进行运算时不用去管符号位，也就是让符号位参与运算。要实现这个功能，就要用到反码。\n反码是一种在计算机中数的机器码表示。对于单个数值（二进制的 0 和 1）而言，对其进行取反操作就是将 0 变为 1，1 变为 0。正数的反码和原码一样，负数的反码就是在原码的基础上符号位保持不变，其他位取反。\n十进制 原码 反码 6 0000 0110 0000 0110 -3 1000 0011 1111 1100 下面我们来看一下，用反码直接运算会是什么情况，我们以 6 - 3 为例，6 - 3 等价于 6 + (-3)。\n6 - 3 ==\u003e 6 + (-3) 0000 0110 // 6(反码) + 1111 1100 // -3(反码) ---------------------- 0000 0010 // (反码) 0000 0010 // 2(原码) 很明显通过反码进行 6 + (-3) 加法运算时，输出值比预期值差了一个 1。接着再来看下 1 + (-1) 的运算结果：\n1 - 1 ==\u003e 1 + (-1) 0000 0001 // 1(反码) + 1111 1110 // -1(反码) ---------------------- 1111 1111 // (反码) 1000 0000 // -0(原码) 由上可知 1 + (-1) 的运算结果为 -0，而我们预期的值是 +0。我们继续看个示例 0 + 0：\n0 + 0 ==\u003e 0 + 0 0000 0000 // 0(反码) + 0000 0000 // 0(反码) ---------------------- 0000 0000 // (反码) 0000 0000 // 0(原码) 这里可以知道 -0 对应的原码是 1000 0000，而 +0 对应的原码是 0000 0000。虽然 -0 和 +0 代表的数值是一样的，但是在用原码和反码表示时它们是不同的。通过以上的多个示例，我们发现使用反码进行加法运算并不能保证得出正确的结果。原因是用一个字节表示数字的取值范围时，这些数字中多了一个 -0。为了解决反码出现的问题，就出现了补码。\n补码 补码是一种用二进制表示有符号数的方法。正数和 0 的补码就是该数字本身。负数的补码则是将其对应正数按位取反再加 1。\n补码系统的最大优点是可以在加法或减法处理中，不需因为数字的正负而使用不同的计算方式。只要一种加法电路就可以处理各种有符号数加法，而且减法可以用一个数加上另一个数的补码来表示，因此只要有加法电路和补码电路即可以完成各种有符号数加法和减法，在电路设计上相当方便。\n另外，补码系统的 0 就只有一个表示方式，这和反码系统不同（在反码系统中，0 有两种表示方式），因此在判断数字是否为 0 时，只要比较一次即可。下图是一些 8 位补码系统的整数，它可表示的范围包括 -128 到 127，总共 256 个整数。\n既然说补码可以解决反码在运算中遇到的问题，继续以 6 + (-3) 为例来验证一下这个结论。\n十进制\t原码\t反码\t补码 6\t0000 0110\t0000 0110\t0000 0110 -3\t1000 0011\t1111 1100\t1111 1101 6 + (-3) 以补码形式的计算过程如下： 6 - 3 ==\u003e 6 + (-3) 0000 0110 // 6(补码) + 1111 1101 // -3(补码) ---------------------- 0000 0011 // 3(补码) 很明显这时得到了正确的结果，那么再来看一下以补码形式计算 1 - 1 的计算过程：\n1 - 1 ==\u003e 1 + (-1) 0000 0001 // 1(补码) + 1111 1111 // -1(补码) ---------------------- 0000 0000 // 0(补码) 可以发现，补码完美解决了反码的问题"},"title":"原码、反码、补码和位移运算"},"/blog/2021/07/dbeaver_jdk/":{"data":{"":"新版的DBeaver需要JDK 11才能执行，如果机器中默认的JDK版本低于11，那启动的时候就会报错。\n除了将默认的JDK版本设置成11以上版本之外，还有办法就是修改DBeaver配置文件中的启动参数。\n编辑/usr/lib/dbeaver/dbeaver.ini，添加参数指定jdk的路径：\n-vm /usr/lib/jvm/java-11-openjdk/bin 最终的配置文件内容样例：\n-startup plugins/org.eclipse.equinox.launcher_1.6.100.v20201223-0822.jar --launcher.library plugins/org.eclipse.equinox.launcher.gtk.linux.x86_64_1.2.100.v20210209-1541 -vm /usr/lib/jvm/java-11-openjdk/bin -vmargs -XX:+IgnoreUnrecognizedVMOptions --add-modules=ALL-SYSTEM -Dosgi.requiredJavaVersion=11 -Xms64m -Xmx1024m "},"title":"DBeaver自定义JDK路径"},"/blog/2021/07/manjaro_nutstore_gui_blank/":{"data":{"":"修改 /opt/nutstore/conf/nutstore.properties\n# 将下面设置修改成false webui.enable=false 如果发现界面大小不能修改，则执行下面命令安装相关程序\nyay -S gvfs libappindicator-gtk3 python-gobject "},"title":"Manjaro升级后打开坚果云界面显示空白"},"/blog/2021/07/threadpool_oom/":{"data":{"":"","小结#小结":"不推荐将线程池作为局部变量使用，而要作为全局变量。一般都会把线程池作为类的静态成员或者单例成员，毕竟生命周期和进程一致。\n如果业务场景非要这样用的话，并且线程池有核心线程的情况下，要注意做两件事情防止对象泄漏：\n对核心线程设置超时时间。 主动调用 shutdown 或 shutdownNow 来关闭线程池。 示例:\npublic class TestThread { public static void main(String[] args) { while (true) { ExecutorService service = Executors.newFixedThreadPool(1); try { service.submit(new Runnable() { public void run() { try { Thread.sleep(2000); } catch (InterruptedException e) { } } }); } catch (Exception e) { }finally{ // 调用shutdown来关闭 service.shutdown(); } try { Thread.sleep(2000); } catch (InterruptedException e) { } } } } 参考:\nhttps://dzone.com/articles/troubleshoot-outofmemoryerror-unable-to-create-new https://blog.csdn.net/firefile/article/details/80747569 ","问题剖析#问题剖析":"当对象实例不再使用或者方法执行完毕后，什么时候会释放线程与关闭线程池？不同的线程池的实现方式可能不一样，但是主要还是看是否设置了核心线程数。\n如果没有设置核心线程数，比如 newCachedThreadPool ，在线程池的线程空闲时间到达 60s 后，线程会关闭，所有线程关闭后线程池也相应关闭回收。 如果设置了核心线程数，比如 newSingleThreadExecutor 和 newFixedThreadPool，如果没有主动去关闭，或者设置核心线程的超时时间，核心线程会一直存在不会被关闭，这个线程池就不会被释放回收。 可以通过下面的ThreadPoolExecutor源码中runWorker方法，看到要执行线程退出processWorkerExit需要这几种情况：\n线程池的状态 \u003e= STOP。对于这个情况，线程池的状态要达到 STOP，需要调用shutdown或者shutdownNow方法 getTask 获取到空任务 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026\u0026 runStateAtLeast(ctl.get(), STOP))) \u0026\u0026 !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } 对于第二种情况，先看看getTask方法的源码。\nprivate Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs \u003e= SHUTDOWN \u0026\u0026 (rs \u003e= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc \u003e corePoolSize; if ((wc \u003e maximumPoolSize || (timed \u0026\u0026 timedOut)) \u0026\u0026 (wc \u003e 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } 从方法中可以看到：\n当前线程数大于核心线程，会调用poll超时后返回空任务。 当前线程数小于等于核心线程，并且调用了allowCoreThreadTimeOut方法允许核心线程超时关闭的情况下，也是调用poll，超时后返回空任务。 其他情况，调用take阻塞等待。 任务队列以阻塞队列BlockingQueue为例，该队列提供了两种方法来获取任务：\npoll，可以设置超时时间，当超时后会得到一个空任务。 take，阻塞住，直到有任务出现。 在没有任务的情况下，核心线程正处于getTask，调用阻塞队列BlockingQueue的 take方法阻塞等待获取到任务，从而导致线程池包括里面的核心线程迟迟不被关闭并且回收。","问题描述#问题描述":"线上环境某个服务经常性地抛出内存溢出，看日志是下面的错误\njava.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) ~[?:1.8.0_112] at java.lang.Thread.start(Thread.java:714) ~[?:1.8.0_112] at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950) ~[?:1.8.0_112] at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1357) ~[?:1.8.0_112] at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[?:1.8.0_112] 造成这个错误主要有2个原因：\n剩余的系统内存不足，导致无法创建新的线程 总线程数达到操作系统允许的上限 看了代码后，发现开发人员把线程池作为一个方法的局部变量，由于这方法是被定时任务调用的，也就意味着线程池局部变量会被实例化N次，如果线程池没有被回收，那么最终总线程数会达到操作系统的上限。"},"title":"线程池原因导致java.lang.OutOfMemoryError"},"/blog/2023/02/change_car_navi/":{"data":{"":"最近自己动手改装了车子的大屏导航，之前花了一些时间查了一些资料，也参考了网上不少的帖子，很有帮助。所以特定把它记录一下，希望对其他人也有一定的帮助。\n旧的导航屏幕\n换了之后的大屏导航\n自己的车子的15年的，原车的导航是小屏幕，操作系统是wince。当前的智能车机发展的如火如荼，已经脱节太多了。一直以来都是用手机做导航，就是需要一直插着充电口，而且如果有电话打进来就比较麻烦。后来看到网上的一些方案，主要有3种：\n拿旧的大屏手机，拆掉电池，改装成电源直接供电 拿旧的平板改装 用安卓导航替换原车的 后来选择了第三种，因为最省事，而且现在商家可以提供转接线束，安装的时候不需要破线，直接对插。如果插上协议盒，就可以直接支持原车的各种功能，包括原车方向盘按键、倒车影像、右侧盲区摄像头等等。注意，有些商家可能无法支持所有原车的功能，比如右侧盲区摄像头，这个需要询问清楚，避免后面满足不了自己的要求。\n因为主要的需求是导航，所以在预算的范围内，选择了 2+32G 的 4G 全网通版本。2+32G 是给机器留点资源的余量，相比 1+16g 来说，可以避免卡顿。选择 4G 版本是因为实时的道路交通流量信息对导航来说是比较重要的功能，车机可以直接联网比较方便点。如果用 wifi 版，通过手机开热点来上网，手机会额外耗电。还有另外一个原因是，目前我的手机套餐，支持免费的副卡，不需要额外付手机流量的费用。车机主板上自带了4G卡芯片，送一定时间的免费定向流量，超出之后需要在车机上扫码充值。因为我用自己的4G卡，就直接将车机自带的 sim 卡关闭了。\n网上有很多人分享了如何自己动手把原车导航更换成安卓大屏，就不重复说明了。下面仅分享一些主要的事项：\n安装的时候，有个小插曲，商家发错了协议盒。插上错误的协议盒，导致车子无法启动，后面重新发一个匹配的就好了。（拔掉协议盒是可以启动的，只是无法支持原车的功能） 4G天线可以安装在副驾驶A柱里面。安装的时候，注意安装的位置不要妨碍侧边气囊。 4G版本的GPS天线是双模的，同时支持GPS与北斗。据网上的帖子与商家的反馈，GPS天线要放在副驾驶的中控台面，那边信号最好。可以通过A柱走线，从前挡风玻璃的一个缝隙中穿出来，然后贴在副驾驶的中控台面上，这样看不到线。 如果按照上面的方法安装4G天线与GPS天线，需要拆掉A柱、副驾驶抽屉与挡板，会方便走线。 可以用原车的GPS天线，网上有转接线，很多商家都有，很容易找 原车的倒车摄像头与右侧盲区摄像头是CCD的，分辨率比较低，而安卓大屏的分辨率高，因此图像会有些模糊。如果介意清晰度的话，需要换成 AHD 的。多数AHD的摄像头是莲花接口，与原车的不匹配。看了一些网上的资料，车尾的倒车摄像头如果不想再走线，可以用原车的线，但是需要破线。我暂时没去折腾 AHD 摄像头的事情。 车机支持休眠，这样在汽车启动的时候，直接唤醒，实现1秒开机。但是需要注意的是，休眠会消耗电瓶的电量。可以根据自己用车的频率与电瓶的状况来设置休眠的时长，避免电瓶亏电 可以考虑买一下汽车线束绒布胶带，这个胶带是耐高温的。用它把大屏后面的线束整理并包扎一下，一定程度上避免开车过程中因为抖动导致的异响。也可以用来包扎一下莲花头的对插处，避免将来松动后还需要拆大屏重新插一次。大屏的线束对插完之后，原车会留下1-2线不需要接，也可以把裸露的接头部分包扎一下。 如果可以支持原车功能，比如方向盘按键、USB、右侧盲区、测距雷达等，体验会好很多。包括可以在大屏中看到车门未关，雷达提示等等。这个应该是需要原车协议盒 安装完大屏后提升体验的地方：\n大屏导航。可以与手机一样显示道路的实时流量信息 可以语音操作车机 手机与车机联动。上车之前，可以用手机提前规划好目的地。手机导航app可以直接发送位置到车机导航，上车之后在车机上直接选择导航到该位置。微信也可以发送位置到车机 导航app可以自主升级 通过FM app有两种方式听广播。一个是通过在线FM频道，在app中的电台列表，直接根据电台名称选择需要收听的频道，可以收听国内其他城市的广播，不受地理位置限制。这种是使用手机流量，不受收音机天线影响，没有杂音，但是受手机信号影响，在市区开车适用。另外一个就是传统的方式 ，通过收音机天线 如何修改导航启动logo\n通用的做法：首先需要知道自己车机的屏幕分辨率，然后找到讲对应分辨率的 bmp 或者 png 格式的图片，复制到 U 盘的根目录。在安卓导航上点击 “工厂” -\u003e “扩展设置” -\u003e “设置logo”，选择对应的图片即可。然后重启车机，可以看到开机的logo。具体细节可以参考：https://bbs.dofun.cc/wiki/1310/49980\n但是这个方法对我来说没有用，我的车机系统是TS8，不知道什么原因，“设置logo”界面就只有一张图，可选择的列表中没有显示 U 根目录的图片。\n但是我找到另外一个办法, 可能需要车机联网。“工厂” -\u003e “扩展设置” -\u003e “车辆设置” 中选择好对应的车型之后，会下载对应车型的一些文件，相应的logo文件会被保存在目录 /storage/emulated/0/logo 下面。原先在工厂” -\u003e “扩展设置” -\u003e “车辆设置” -\u003e“Logo列表” 中可以看到两张图片“默认”与“默认1”（仅仅是安卓相关的图片），分别对应目录下的文件：logo_00_FE000000_0000_00_220811.bmp, logo_00_FE000000_1000_00_220811.bmp。可以将需要的图片复制到这个目录中，按照一样的格式来命名成 logo_00_FE000000_2000_00_220811.bmp。\n复制好之后，重新打开“工厂” -\u003e “扩展设置” -\u003e “车辆设置” -\u003e “Logo列表”，看到列表中多了一个“默认2”。它就是刚刚自己复制过去的文件。选择它，点击确认，重启后就可以看到开机logo已经更改。（忽略下图中的默认三，是做测试用的）\n如何让原车右侧盲区实体按键功能生效\n接好协议盒，右侧盲区的摄像头是可用的。但是需要在屏幕中点击 AUX，然后再按下原车右侧盲区实体按键，才可以在大屏中看到图像。这个操作起来就有点麻烦。\n有一个办法可以跟更换大屏导航之前的体验一样，只需要按下原车右侧盲区实体按键，就可以开启或者关闭大屏中的视频显示。在“车辆设置” -\u003e “右视开关” 中，改成“打开”即可\n一些图片\n右侧盲区视频的实际效果，有些模糊，但是还能接受，对实际使用不影响。\n倒车影像也有些模糊，但是还能接受，对实际使用不影响。如果在意清晰度，可以考虑改装成AHD\n原车雷达，可以在大屏上显示出效果\n一些参考材料\n【南京长安CS75车友会】大胆尝试 自己动手更换10.2寸横屏版智能导航车机 【河北石家庄cs75联盟】详解【拆装中控】\u0026【导航扩容】 CS75大屏接线方式 长安cs75改装10.4寸中控导航 CS75 14款CE导航15,16款低配安卓导航改装高配安卓导航教程第二季 PAD3改装14款长安CS75终极导航 关于CS75中控导航的倒车检测线 车机尾线定义图\n导航改装，实际上只要线路对接正确就可以了，只是需要花时间尝试与折腾。网上的一些商家直接提供他们弄好的转接头，就可以省去了车主的时间。\n如果是动手能力强的朋友，或者说喜欢自己研究，可以参考下面的尾线定义图\n安卓车机尾线定义图\n某一款CS75 CD机总成端子列表"},"title":"更换安卓智能车机"},"/blog/2023/05/access-new-bing/":{"data":{"":"微软的 new bing 已经接入 GPT-4, 这几天已经开放给用户免费免费，不用预约排队体验。但是大陆地区无法直接访问，即使安装了Edge 的 dev 版本也没用，需要借助工具。但是呢，即使通过魔法可能也无法访问，因为 ip 可能在微软的黑名单中。\n目前有人开发了 NewBingGoGo 这个工具，可以不需要通过魔法来使用。目前这个工具有2个版本：\n插件版：https://gitee.com/jja8/NewBingGoGo web版：https://github.com/jianjianai/NewBingGoGo-Web 使用的时候，可以目前免费的云服务提供商来部署。可以参考 使用免费的的云服务提供商创建魔法链接\n嫌麻烦的话，可以直接用这个工具作者的演示网站, 只是有点慢：https://bingweb.jja8.cn/web/NewBingGoGo.html"},"title":"不用魔法直接访问 New Bing"},"/blog/2023/05/mouse_wheel_issue/":{"data":{"":"最近使用鼠标时候，发现滚轮失灵，滚动时一直上下乱跳。原先想是不是只能换鼠标了，但查了网上的资料，说是滚轮编码器的问题。参照网上的说法，拆开鼠标，用酒精擦拭滚轮解码器脏的地方，重新装好，果然鼠标复活了。\n然后又去网上看了一下解码器的价格，如果将来这个坏了，其实可以自己买一个新的焊接上去。\n当时没有拍照片，下面是网上找的图"},"title":"鼠标滚轮上下乱跳"},"/blog/2023/11/on-premise-vs-private-cloud/":{"data":{"":"On-Premises 与 Private Cloud 有一定的区别：\nOn-Premises 可以认为是本地部署，本地数据中心是指位于组织场所的物理基础设施。这些数据中心由组织的 IT 团队构建和维护，可以完全控制基础设施和数据管理流程。数据中心可以定制以满足特定需求，并且只能由授权人员访问。 Private Cloud 是私有云部署。私有云是虚拟化环境，提供与本地数据中心相同的功能。然而，与本地数据中心不同，私有云托管在远程基础设施上，可以从任何有互联网连接的地方访问。私有云可以由组织的 IT 团队或第三方服务提供商管理。 这两种方法都有其优点和缺点，需要权衡它们以确定哪种方法最适合自己的组织。以下是一些需要考虑的关键因素：\n私有云的优势：\n可扩展性：私有云环境可以根据不断变化的业务需求轻松扩展或缩减。 灵活性：私有云提供了设计和定制 IT 基础架构的灵活性，以满足特定的业务需求。 节省成本：与本地数据中心相比，私有云可以节省成本，因为企业无需购买和维护物理硬件和基础设施。 提高安全性：私有云提供比本地数据中心更高的安全级别，因为提供商可以提供防火墙、入侵检测和防御系统等高级安全功能。 可及性：私有云可以从任何地方访问，使远程团队能够轻松协作和访问共享资源。 私有云的缺点：\n初始设置成本：由于需要购买硬件和软件许可证，以及与部署和配置环境相关的成本，因此设置私有云可能成本高昂。 对服务提供商的依赖：私有云提供商负责维护和管理底层基础架构。这意味着企业必须依靠提供商进行维护、升级和安全性。 可能的延迟：如果资源位于远程数据中心，私有云可能会出现延迟问题，从而导致应用程序性能降低。 本地数据中心的优势：\n控制：本地数据中心提供对 IT 基础设施的完全控制，使企业能够自由设计和定制环境以满足其特定需求。 安全：本地数据中心提供更高级别的控制和安全性，因为企业可以管理和配置自己的安全功能。 可预测的成本：借助本地数据中心，企业无需担心带宽或存储使用等可变成本，因此成本可预测。 性能：与私有云相比，本地数据中心通常提供更快的性能，因为资源位于本地，可以针对特定工作负载进行优化。 本地数据中心的缺点：\n维护和升级：本地数据中心需要定期维护和升级，这可能既耗时又昂贵。 可扩展性：与私有云相比，本地数据中心的可扩展性较低，因为企业必须购买和安装额外的硬件来增加容量。 成本：本地数据中心需要在硬件、软件许可证和基础设施方面进行大量前期投资。此外，持续的维护和升级可能很昂贵。 "},"title":"On-Premise 与 Private Cloud 区别"},"/blog/2023/11/spring-boot-cve-2015-5211/":{"data":{"":"在某次排查问题的时候，发现接口返回值的 Response Header 中居然多了下面这个值。\nContent-Disposition:inline;filename=f.txt Content-disposition 是 MIME 协议的扩展，它指示 MIME 用户代理如何显示附加的文件。上面的值就相当于告诉客户端将文件内容直接显示在页面，同时这个文件名为 f.txt。\n排查了接口代码与 nginx 等设置，并没有发现显式设置它的地方，很疑惑它是什么时候被设置上去的，即使显式设置了 Reponse 的 content-type 也没有用。\n最终在查找资料的时候发现，Spring boot 为了修复 CVE-2015-5211 漏洞，当 URL Path 中包含文件扩展名的时候，就会自动设置这个 Response Header\n看到这个描述就马上知道原因了。自己的接口请求是类似下面这种结构的，spring boot 将 aaaa.bbbb.cccc 当作是文件名\nhttp://xxxxx/yyyyy/aaaa.bbbb.cccc 虽然说大部分情况下，即使有这个 Response Header 不会有什么影响，但是在某些特殊的场景，就会出现问题。比如，某个客户在他们的公司内部中部署了网络安全工具，这个网络工具检测到它返回值是个文件，自动将返回的报文加密。这个就导致网页请求接口的时候报错，在浏览器的开发者工具中可以看到下面的返回内容，完全是二进制的形式而不是json字符串\n为了避免这个问题，可以将接口的地址改成下面这种形式，也就是通过 Query Parameter 的方式来传递带有\".“的数据。这样spring boot就不认为它要返回文件，不会自动加上那个 Response Header。\nhttp://xxxxx/yyyyy?code=aaaa.bbbb.cccc 这其实也是个编程习惯的问题。对于简单的查询参数，最好就用 GET 请求，以 Query Parameter 的方式来传值，而不是放在 URL Path 中。对于复杂的查询参数，就用 POST 请求，在 Body 中传值。\n参考资料：\nhttps://docs.spring.io/spring-framework/reference/web/webmvc/mvc-controller/ann-requestmapping.html#mvc-ann-requestmapping-rfd https://spring.io/security/cve-2015-5211 https://github.com/spring-projects/spring-framework/issues/18220 https://github.com/spring-projects/spring-boot/issues/4220 "},"title":"Spring Boot 自动设置响应头引发的问题"},"/blog/2023/12/docker-mount-file-not-sync/":{"data":{"":"","解决办法#解决办法":"1. 方法一 使用 echo 修改文件，而不是使用 vim 或者 vi。\n2. 方法二 使用 cat 重定向来修改文件，而不是使用 vim 或者 vi。\ncp /tmp/nginx.conf /tmp/nginx.conf2 vi /tmp/nginx.conf2 cat /tmp/nginx.conf2 \u003e /tmp/nginx.conf 3. 方法三（不推荐） 修改 vim 配置。执行 vim 命令，输入 :scriptnames 查看 vim 配置文件路径，这边配置文件路径是 /etc/vimrc ，在配置文件最后添加如下两行。\nset backup set backupcopy=yes 这样可以解决问题，不过也有一个很大的副作用，那就是每次用vim编辑文件保存之后，vim会生成一个类似该被修改文件，但末尾增加了一个\"~“后缀，用以保存修改之前的文件内容。此方法不推荐。\n4. 方法四 (推荐) 修改文件权限，文件默认权限是 644，把权限修改为 666。修改完权限后，再次通过 vim 修改并保存后，原文件的 inode 不会发生变化\nchmod 666 /root/test.txt 5. 方法五 (推荐) 挂载目录，不要挂载文件。挂载目录不会出现宿主机文件更新，而容器中文件没有更新。\n参考链接：\nhttps://www.cnblogs.com/barneywill/p/10424530.html https://cloud.tencent.com/developer/article/1708294 https://forums.docker.com/t/modify-a-file-which-mount-as-a-data-volume-but-it-didnt-change-in-container/2813/13 https://www.cnblogs.com/lylex/p/12781007.html ","问题分析#问题分析":"Docker 中，mount volume 的原理是借用了 Linux Namespace 中的 Mount NameSpace 来隔离系统中不同进程的挂载点视图，实际文件是没有变化。比如，在container中，bash 实际就是一个运行在宿主机上的进程，被 Docker 用 Linux 分别隔离了 Mount Namespace、UTS Namespace、IPC Namespace、PID Namespace、Network Namespace 和 User Namespace，使得它看上去好像运行在了一个独立的、相对隔离的系统上，但实际它的一切资源都是宿主机在不同 Namespace 中的一个投影，文件也不例外。\nLinux中，证明文件是否相同的根本途径是，判断其 inode，如果两个文件的inode相同，两个文件必定为同一文件，从而两个文件的内容也必然相同。\n可以使用下面任意一个命令来查看文件inode：\nstat /path/to/file ls -i /path/to/file Linux 默认情况下，vi 或 vim 为了防止在修改文件的过程中，由于磁盘或者系统出现问题而导致当前被修改的文件的损坏，它做了类似如下逻辑：\n复制出一个需要修改文件的副本，命名为在原来文件的基础上增加 “.swp” 后缀以及 “.” 前缀。 修改内容保存到有 .swp 后缀的文件，并 flush 到磁盘 执行 :wq 就会交换原文件和 swp 文件的名称 删除临时 swp 文件 从上面可以看出，原来的文件已经被删除，虽然新保存的文件名与原先的相同，但 inode 值是不同的。而容器还是会一直记录以前的文件，保持着与原先 inode 值一样的副本。只有当 restart 容器时，容器才会重新读取新的文件。宿主机上修改的内容才会更新。","问题描述#问题描述":"使用 Docker 时，有时需要挂载一个宿主机目录或者文件。但是有时候发现通过 vi 或者 vim 修改完宿主机上的文件之后，容器中对应的文件并没有变化，看不到修改的内容。"},"title":"Docker挂载文件，宿主机修改后容器里文件没有同步更新"},"/blog/2023/12/es-order-search-evolution/":{"data":{"":"这里总结一下过去曾参与的一个系统中，对于订单查询设计的演变过程","第一阶段仅数据库查询#第一阶段：仅数据库查询":"这个是最初始的阶段，数据查询直接走数据库查询。这种方式会完全依赖于数据库的性能，随着数据越来越来，查询效率也会越来越低","第三阶段引入-kafka#第三阶段：引入 Kafka":"引入消息队列中间件可以解决上面的问题，将保证消息消费的任务交给中间件，而不需要在业务应用上实现这个功能。\n写 ES 与原先的方案相比，做了一些改动。hibernate 拦截器检测到订单数据变化后，将数据先写入到 Kafka，然后订单的 ES 查询服务去消费 kafka 的数据。\n写入到 kafka 的数据与原先也有些变化。原先的方案中，将变更的数据与操作类型都作为参数，ES 查询服务直接根据这些参数修改 ES 中的文档数据。新的方案中，kafka 中只放租户 ID 与订单 ID，通过这两个参数查询数据库来获取信息，如果数据库中没有数据，则表示订单被删除，就删除 ES 中的文档；如果数据库中有数据，则创建或者更新ES 文档。这么做的好处就是：\nkafka 中的数据少 不用关心对数据进行了什么操作，不需要为增删改分开写逻辑，都合并为一个逻辑，就是查询数据库，根据查询结果来来处理。这样就简化了代码逻辑 如果将来 ES 索引中需要增加新的字段，只需要修改查询数据库的 SQL 与写 ES 这两个部分的代码即可，降低了一些复杂度。另外，通过订单 ID 来查询数据库，本身的耗时也不会有多少。 读 ES 这个部分没有变化","第二阶段hibernate-拦截器检测数据变化并更新-es#第二阶段：hibernate 拦截器检测数据变化并更新 ES":"随着订单数据量的增多，原先直接查询数据库的方式已经无法满足对性能的要求。因此引入了 Elastic Search 来作为快速订单查询这个功能的支撑，同时增加了一个ES查询服务，用来对ES做读写操作。\n考虑到某些租户的数据量很小，直接查询数据库就满足业务上的客户端响应需求。因此，增加了一个租户级别上的配置，用来开启或者关闭 ES 查询。\n写 ES 由于这个系统使用的是 hibernate 来做数据的持久化，因此添加了一个 hibernate 拦截器，用来监听数据持久化的事件，根据不同的数据变更操作（新增、更新或删除），在 Elastic Search 中做不同的处理：\n如果是在数据库中新增一个订单， 则在 ES 中创建一个文档 如果是在数据库中更新一个订单， 则在 ES 中更新对应文档 如果是在数据库中删除一个订单， 则在 ES 中删除对应文档 如果租户没有开启 ES 查询，那么订单数据更新的时候，也不会写 ES 数据，这样就可以节省存储资源。\n读 ES 在读取订单数据的时候，会先判断某个租户是否开启了 ES 查询，如果未开启就查数据库，开启则通过 ES 查询服务来获取订单数据。\n存在的问题 利用 ES 查询，响应速度明显得到提升。但是在实际的运行过程中，发现了另外一个问题：应用如果重启（比如新迭代发布），有些在内存中未处理的数据就无法同步到 ES，这就导致 ES 中的数据没有及时更新。","第五阶段拆分搜索服务#第五阶段：拆分搜索服务":"采用上面的方案，运行起来基本上已经没有问题了。只是从保持系统功能的稳定，与运维的角度来看，把原先 ES 同步服务拆分成下面三个，让每个服务专注于自己的事情：\n订单查询 (order-es-search)：这个服务仅包含查询的逻辑。因为查询功能在较长时间内会保持稳定，将这个功能独立拆分出来是为了保持查询服务的高可用。其他部分功能的更新与重新部署，就与它无关了。 订单增量同步（order-es-sync）：这个服务是用来消费 kafka 消息，增量同步订单数据到 ES 中，仅处理最新变更的订单 订单全量同步 (order-es-reload)：这个服务是用来重新同步某个租户的所有订单的。适用于 ES 索引中需要新增字段时，将已有的存量数据全部更新。在部署层面，它仅在需要的时候才临时启动，在平时都是不需要部署的。出需要的时候，临时部署，而且可以给它临时分配较高的硬件资源，加快处理速度，数据处理完后立即关闭服务，回收资源。 写 ES 读 ES ","第四阶段按照租户拆分成不同的索引#第四阶段：按照租户拆分成不同的索引":"公司的业务与系统设计，订单数据增长是非常快的。随着租户数量、业务量的增加，ES 索引中的文档数量越来越多，ES 查询也越来越慢。原先的方案里面，所有的租户数据都是放在一个 ES 索引里面的。因此需要将数据做拆分，不同租户的数据，放在不同的 ES 索引中\n写 ES 写数据的时候，根据租户 ID, 写入不同的 ES 索引。\n读 ES 读数据的时候，也是根据租户 ID，从不同的 ES 索引中读取"},"title":"数据查询ES设计演变"},"/blog/2023/12/jvm-args/":{"data":{"":"JVM 包含多种不同类型的参数选项：\n-D 用来设置系统属性，属于标准选项 -X 设置非标准选项，支持的选项范围跟具体的 JVM 实现有关 -XX 设置高级选项，允许开发者调整 JVM 的行为、性能、输出调试信息，支持的选项范围也跟具体的 JVM 实现有关 ","标准选项standard-options-d#标准选项（standard options）-D":"标准选项是所有 JVM 实现都会支持。在控制台输入 java 这个命令，除了能看到 java 命令的使用手册，还能看到机器上默认的 JVM 所支持的所有标准选项。\nJava 允许我们以 -D= 这种键值对的形式设置系统属性。注意，这个不是环境变量。\n可以在命令行中带入参数:\n-Dfoo=bar1 也可以在java代码中，设置或者读取值\n// 设置值 System.getProperty(\"foo\"); // 读取值 System.setProperty(\"foo\", \"bar2\"); ","非标准选项non-standard-options或者-extra-options--x#非标准选项（non-standard options，或者 extra-options） -X":"和标准选项类似，可以直接通过 java -X 命令获取 JVM 支持的所有非标准选项。比如下面两个最常见的选项：-Xms 和 -Xmx\n非标准选项的支持是与 JVM 的具体实现紧密相关的，并且它们在不同的版本可能会发生改变。","高级选项advanced-options-xx#高级选项（advanced options）-XX":"高级选项以 -XX 开头，这些选项一般用于开发者调整 JVM 的行为、性能或输出调试信息等。\n根据参数值类型的不同，高级选项又可以分为两类：布尔类型的选项和带参数的选项。\n(1) 布尔选项 布尔类型的选项不带参数，只是一个开关。开关是不需要参数的，可以通过 + 启用某个功能（-XX:+Option），而通过 - 禁用某个功能（-XX:-Option）。\n例如，在 HotSpot JVM 中，通过 -XX:+Inline 启用方法内联。不过 HotSpot 为了提高性能，默认是开启了方法内联的，所以可以通过 -XX:-Inline 关闭方法内联。\n(2) 带参选项 还有一类高级选项是需要设置相应的参数值的，形式一般为：-XX:OptionName=OptionValue。\n下面是一些例子：\n-XX:ErrorFile=file.log 告诉 JVM：当不可恢复的错误发生时，将错误信息写入 file.log 这个文件。 -XX:TreadStackSize=256k 将线程栈的大小设置为 256k。 -XX:MaxHeapSize=1g 将堆的最大大小限制为 1GB，等价于 -Xmx1g 使用 java -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+PrintFlagsFinal -version 命令可以查看 JVM 所有的选项\n参考：\nhttps://zhuanlan.zhihu.com/p/638545993 "},"title":"JVM 参数项区别：-D、-X、-XX"},"/blog/2023/12/unsafe_http_methods/":{"data":{"":"在安全扫描工具中，会验证服务器是否开启了不安全的 http 方法。\n从资源的角度看，GET、HEAD、OPTIONS、TRACE，这些方法不会产生什么动作，不会在服务器上产生结果，只是简单获取信息。相对的，能产生动作的方法就会被认为是不安全的HTTP方法。\n在上面认为的那些不安全的HTTP方法中，安全界认为 PUT、DELETE、TRACE 是不安全的，另外 WebDAV 中的几个方法，RFC 5789 中的 PATCH 方法也被认为是不安全的。（TRACE容易引发XST攻击，PATCH修改资源的部分内容，PUT/DELETE没有认证机制等原因，不仅仅因为它们会产生结果）。\n下面的方法可能会被利用，向应用程序实施有效攻击：\nPUT：利用PUT方法可以向服务器上传文件，所以恶意攻击者可以上传木马等恶意文件。 DELETE：利用DELETE方法可以删除服务器上特定的资源文件，造成恶意攻击。 OPTIONS：将会造成服务器信息暴露，如中间件版本、支持的HTTP方法等。 TRACE：可以回显服务器收到的请求，主要用于测试或诊断，一般都会存在反射型跨站漏洞 COPY：将指定的资源复制到Destination消息头指定的位置 MOVE：将指定的资源移动到Destination消息头指定的位置 SEARCH：在一个目录路径中搜索资源 PROPFIND：获取与指定资源有关的信息，如作者、大小与内容类型 如果没有必要，最好关闭这些不安全的 HTTP 方法和 WebDAV。\n参考链接：\nhttps://developer.aliyun.com/article/790150 https://cloud.tencent.com/developer/article/1937077 https://www.cnblogs.com/qmfsun/p/6169641.html https://noob-sec.github.io/%E6%AF%8F%E6%97%A5%E6%BC%8F%E6%B4%9E-%E4%B8%8D%E5%AE%89%E5%85%A8%E7%9A%84HTTP%E6%96%B9%E6%B3%95/ "},"title":"不安全的http方法"},"/blog/2023/12/wecom-dev-tool/":{"data":{"":"请参考企业微信开发者中心的文档：常见问题#客户端调试\n这个工具目前有个局限性，它只适用于企业微信浏览器加载完页面之后，才能可以介入排查问题，因为在此之前无法打开企微浏览器的开发者工具。如果要测试企微单点登录的问题，还是要借助于 fiddler 等抓包工具。"},"title":"企业微信调试工具"},"/blog/2024/01/gateway-modify-request-response/":{"data":{"":"有个需求，要求在前端调用接口时，将请求数据与响应数据做加密。做了一下调研，可以用下面的方式来实现：\npublic class EncryptGatewayFilter implements GlobalFilter, Ordered { private static final String BODY_ENCRYPT_HEADER = \"X-ENCRYPTED\"; private static final String ENCRYPT_VERSION_1 = \"1.0\"; @Override public int getOrder() { return -99; } @Override public Mono\u003cVoid\u003e filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 请求头中标识了该请求是加密过的 HttpHeaders httpHeaders = exchange.getRequest().getHeaders(); String bodyEncryptHeader = httpHeaders.getFirst(BODY_ENCRYPT_HEADER); if (bodyEncryptHeader != null \u0026\u0026 bodyEncryptHeader.equals(ENCRYPT_VERSION_1)) { // 这里可以处理一些自定义的逻辑，并且将参数传到后续的方法中 CustomParam step1Param = this.prepareCustomParam(); // 处理加密的请求 return processEncryptRequest(exchange, chain, step1Param); } // 处理未加密的请求 return chain.filter(exchange); } private Mono\u003cVoid\u003e processEncryptRequest(ServerWebExchange exchange, GatewayFilterChain chain, CustomParam step1Param) { // 这里可以做一些前置校验，确定是否需要对请求解密 boolean needProcess = checkIfNeedProcess(step1Param); if (needProcess) { try { // 这里可以处理 step1Param，并且将生成下个阶段需要用的参数 step2Param, 传到后续的方法中 CustomParam step2Param = this.handleCustomParam(step1Param); // 修改请求内容 return new ModifiedRequestDecorator(new Config() // 可以移除表示加密的请求头 .addHeaderToRemove(BODY_ENCRYPT_HEADER) // 设置 request 重写方法，解密请求 .setRewriteFunction(String.class, String.class, (ex, requestData) -\u003e Mono.just(decryptRequestBody(requestData, step2Param)) )).filter(exchange.mutate().response( // 修改响应内容 new ModifiedResponseDecorator(exchange, new Config() // 添加响应头，告知调用者该响应已加密 .addHeaderToAdd(BODY_ENCRYPT_HEADER, ENCRYPT_VERSION_1) // 设置 response 重写方法，加密响应 .setRewriteFunction(String.class, String.class, (ex, responseData) -\u003e Mono.just(encryptResponseBody(responseData, step2Param)) ))).build(), chain); } catch (Exception e) { log.error(\"Failed to process the request body\", e); // 处理失败，返回错误的响应 return buildFailResult(exchange.getResponse(), HttpStatus.BAD_REQUEST); } } // 验证未通过，则不处理，直接将原始请求传到链条中的下一个处理器 return chain.filter(exchange); } private String decryptRequestBody(Object originalRequest, CustomParam step2Param) { try { // 这里需要实现解密的方法 ... return decryptedRequest; } catch (Exception e) { log.warn(\"Error when decrypting request.\", e); return null; } } private String encryptResponseBody(String originalResponse, CustomParam step2Param) { try { // 这里需要实现加密的方法 ... return oencryptedResponse; } catch (Exception e) { log.warn(\"Error when encrypting response.\", e); return null; } } } 其中 ModifiedRequestDecorator 这个类的实现可以参考 org.springframework.cloud.gateway.filter.factory.rewrite.ModifyRequestBodyGatewayFilterFactory。稍微有点不同的是，ModifyRequestBodyGatewayFilterFactory 这个类是作用于 route，而这里需要的是一个全局过滤器。当然，如果不想自己实现，更简便的办法是只做个代理类，直接调用 ModifyRequestBodyGatewayFilterFactory。稍微有点不同的是，ModifyRequestBodyGatewayFilterFactory的方法。详细的细节可以参考： https://blog.csdn.net/cqyhuaming/article/details/105280720\n同理，ModifiedResponseDecorator 的实现可以参考 org.springframework.cloud.gateway.filter.factory.rewrite.ModifyResponseBodyGatewayFilterFactory 这类的逻辑。\n上面示例代码中 Config 类，也就是 ModifyRequestBodyGatewayFilterFactory 与 ModifyResponseBodyGatewayFilterFactory 中用到的 config 类，可以仿照他们的实现合并成一个。\n但是，后续在使用过程中，Spring Cloud Gateway 运行一段时间之后，不时地出现 OutOfDirectMemoryError 的错误。代码里面对于使用 dataBuffer 的地方都特地添加了释放的逻辑，但是没有起到任何作用，问题依然存在。去网上查了一些资料，发现是 gateway 版本的问题，升级到 Hoxton.SR11 之后就解决了。\nreactor.netty.ReactorNetty$InternalNettyException: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 32768 byte(s) of direct memory (used: 5222041, max: 5242880) Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: Error has been observed at the following site(s): |_ checkpoint ⇢ com.dtstack.gateway.log.RequestLoggingFilter [DefaultWebFilterChain] |_ checkpoint ⇢ org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter [DefaultWebFilterChain] |_ checkpoint ⇢ org.springframework.cloud.sleuth.instrument.web.TraceWebFilter [DefaultWebFilterChain] |_ checkpoint ⇢ org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain] |_ checkpoint ⇢ HTTP POST \u0026#34;/api/gateway/ky_directMemory_test\u0026#34; [ExceptionHandlingWebHandler] Stack trace: Caused by: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 32768 byte(s) of direct memory (used: 5222041, max: 5242880) at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:754) at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:709) at io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.allocateDirect(UnpooledUnsafeNoCleanerDirectByteBuf.java:30) at io.netty.buffer.UnpooledDirectByteBuf.\u0026lt;init\u0026gt;(UnpooledDirectByteBuf.java:64) at io.netty.buffer.UnpooledUnsafeDirectByteBuf.\u0026lt;init\u0026gt;(UnpooledUnsafeDirectByteBuf.java:41) at io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.\u0026lt;init\u0026gt;(UnpooledUnsafeNoCleanerDirectByteBuf.java:25) at io.netty.buffer.UnsafeByteBufUtil.newUnsafeDirectByteBuf(UnsafeByteBufUtil.java:625) at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:381) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:178) at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:139) at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:150) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 参考链接：\nSpring Cloud Gateway 修改响应数据 完美解决spring cloud gateway 获取body内容并修改 spring-cloud-gateway修改request param与body spring cloud gateway在GatewayFilter中获取并修改请求参数 优雅的实现spring-cloud-gateway修改请求和响应体 SpringCloud-Gateway OutOfDirectMemoryError排查 "},"title":"通过SpringGateway对接口请求进行加解密"},"/blog/2024/01/kafka-invalid-pid-mapping/":{"data":{"":"有个开发组不时地在测试环境中遇到下面的问题：\nCaused by: org.apache.kafka.common.errors.InvalidPidMappingException: The producer attempted to use a producer id which is not currently assigned to its transactional id 经过排查发现，这个开发组在代码中使用了 Kafka 的事务。这个错误的抛出与使用了事务有关系。\nSpring kafka 支持一个叫做“僵尸围栏”的机制，用于处理在事务中参与的生产者或消费者与协调器之间的连接丢失或发生故障的情况。这个机制的目的是防止由于参与者变成无法通信的 “僵尸” 状态而导致事务状态不一致。具体来说，当一个生产者或消费者在参与 Kafka 事务期间与协调器失去联系时，它可能处于一种无法确认其事务状态的状态。“Zombie fencing” 的任务是在检测到这种情况时，将这个参与者标记为 “僵尸” 并且不再考虑其在事务中的状态。\n为了识别和解决僵尸实例的问题，Kafka 为每个事务生产者分配一个称为 transaction id 的惟一标识符。这用于跨流程重新启动标识相同的生产者实例。事务生产者的第一个操作必须是在 kafka 集群中是显式地注册其 transaction id，接着 Kafka 代理会用给定的 transaction id 来检查已开启的事务并结束他们。它还增加与 transaction id 关联的 epoch 值。这个 epoch 是存储在每个 transaction id 中的内部元数据。一旦 epoch 发生碰撞，任何具有相同 transaction id 的生产者，只要带有老的 epoch 值都被认为是僵尸并且被隔离，同时来自这些生产者的未来事务写将被拒绝。\nkafka 中有个 transactional.id.expiration.ms 配置，当生产者与集群超过这个时间长度没有通讯的话，transaction id 就会被设置成过期，这个就意味着被标记成“僵尸”状态。如果该生产者后面再次与 Kafka 代理通讯，就会接收到本文开头的那个异常。\n解决这个问题的也比较简单，在 producer factory 中设置一下 max age 这个属性值，比 transactional.id.expiration.ms 属性值小就可以了。\nStarting with version 2.5.8, you can now configure the maxAge property on the producer factory. This is useful when using transactional producers that might lay idle for the broker’s transactional.id.expiration.ms. With current kafka-clients, this can cause a ProducerFencedException without a rebalance. By setting the maxAge to less than transactional.id.expiration.ms, the factory will refresh the producer if it is past it’s max age.\n参考链接：\nhttps://stackoverflow.com/questions/59398186/facing-org-apache-kafka-common-errors-invalidpidmappingexception-in-spring-kafka https://docs.spring.io/spring-kafka/docs/2.8.11/reference/html/#transactions https://www.confluent.io/blog/transactions-apache-kafka/ "},"title":"Kafka 报 InvalidPidMappingException 问题解决"},"/blog/2024/10/caffeine/":{"data":{"":"","caffeine-基础#Caffeine 基础":"使用Caffeine，需要在工程中引入如下依赖\n\u003cdependency\u003e \u003cgroupId\u003ecom.github.ben-manes.caffeine\u003c/groupId\u003e \u003cartifactId\u003ecaffeine\u003c/artifactId\u003e \u003c!--https://mvnrepository.com/artifact/com.github.ben-manes.caffeine/caffeinez找最新版--\u003e \u003cversion\u003e3.0.5\u003c/version\u003e \u003c/dependency\u003e 1. 缓存加载策略 1.1 Cache手动创建 最普通的一种缓存，无需指定加载方式，需要手动调用 put()进行加载。需要注意的是 put() 方法对于已存在的 key 将进行覆盖，这点和 Map 的表现是一致的。\n在获取缓存值时，如果想要在缓存值不存在时，原子地将值写入缓存，则可以调用 get(key, k -\u003e value) 方法，该方法将避免写入竞争。在多线程情况下，当使用 get(key, k -\u003e value) 时，如果有另一个线程同时调用本方法进行竞争，则后一线程会被阻塞，直到前一线程更新缓存完成；而若另一线程调用getIfPresent()方法，则会立即返回null，不会被阻塞。\n调用 invalidate() 方法，将手动移除缓存。\nCache\u003cObject, Object\u003e cache = Caffeine.newBuilder() //初始数量 .initialCapacity(10) //最大条数 .maximumSize(10) //expireAfterWrite 和 expireAfterAccess同时存在时，以 expireAfterWrite 为准 //最后一次写操作后经过指定时间过期 .expireAfterWrite(1, TimeUnit.SECONDS) //最后一次读或写操作后经过指定时间过期 .expireAfterAccess(1, TimeUnit.SECONDS) //监听缓存被移除 .removalListener((key, val, removalCause) -\u003e { }) //记录命中 .recordStats() .build(); cache.put(\"1\",\"张三\"); //张三 System.out.println(cache.getIfPresent(\"1\")); //存储的是默认值 System.out.println(cache.get(\"2\", o -\u003e \"默认值\")); /** * 手动加载 * @param key * @return */ public Object manulOperator(String key) { Cache\u003cString, Object\u003e cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.SECONDS) .expireAfterAccess(1, TimeUnit.SECONDS) .maximumSize(10) .build(); //如果一个key不存在，那么会进入指定的函数生成value Object value = cache.get(key, t -\u003e setValue(key).apply(key)); cache.put(\"hello\",value); //判断是否存在如果不存返回null Object ifPresent = cache.getIfPresent(key); //移除一个key cache.invalidate(key); return value; } public Function\u003cString, Object\u003e setValue(String key){ return t -\u003e key + \"value\"; } 1.2 Loading Cache自动创建 LoadingCache 是一种自动加载的缓存。其和普通缓存不同的地方在于，当缓存不存在/缓存已过期时，若调用 get() 方法，则会自动调用 CacheLoader.load() 方法加载最新值。调用getAll() 方法将遍历所有的 key 调用 get()，除非实现了 CacheLoader.loadAll() 方法。\n使用 LoadingCache 时，需要指定 CacheLoader ，并实现其中的 load() 方法供缓存缺失时自动加载。\n在多线程情况下，当两个线程同时调用 get()，则后一线程将被阻塞，直至前一线程更新缓存完成。\nLoadingCache\u003cString, String\u003e loadingCache = Caffeine.newBuilder() //创建缓存或者最近一次更新缓存后经过指定时间间隔，刷新缓存；refreshAfterWrite 仅支持 LoadingCache .refreshAfterWrite(10, TimeUnit.SECONDS) .expireAfterWrite(10, TimeUnit.SECONDS) .expireAfterAccess(10, TimeUnit.SECONDS) .maximumSize(10) //根据key查询数据库里面的值，这里是个lamba表达式 .build(key -\u003e new Date().toString()); /** * 同步加载 * @param key * @return */ public Object syncOperator(String key){ LoadingCache\u003cString, Object\u003e cache = Caffeine.newBuilder() .maximumSize(100) .expireAfterWrite(1, TimeUnit.MINUTES) .build(k -\u003e setValue(key).apply(key)); return cache.get(key); } public Function\u003cString, Object\u003e setValue(String key){ return t -\u003e key + \"value\"; } 1.3 Async Cache异步获取 AsyncCache 是 Cache 的一个变体，其响应结果均为 CompletableFuture，通过这种方式，AsyncCache 对异步编程模式进行了适配。\n默认情况下，缓存计算使用 ForkJoinPool.commonPool() 作为线程池，如果想要指定线程池，则可以覆盖并实现 Caffeine.executor(Executor) 方法。\nsynchronous() 提供了阻塞直到异步缓存生成完毕的能力，它将以Cache进行返回。\n在多线程情况下，当两个线程同时调用 get(key, k -\u003e value)，则会返回同一个 CompletableFuture 对象。由于返回结果本身不进行阻塞，可以根据业务设计自行选择阻塞等待或者非阻塞。\nAsyncLoadingCache\u003cString, String\u003e asyncLoadingCache = Caffeine.newBuilder() //创建缓存或者最近一次更新缓存后经过指定时间间隔刷新缓存；仅支持LoadingCache .refreshAfterWrite(1, TimeUnit.SECONDS) .expireAfterWrite(1, TimeUnit.SECONDS) .expireAfterAccess(1, TimeUnit.SECONDS) .maximumSize(10) //根据key查询数据库里面的值 .buildAsync(key -\u003e { Thread.sleep(1000); return new Date().toString(); }); //异步缓存返回的是CompletableFuture CompletableFuture\u003cString\u003e future = asyncLoadingCache.get(\"1\"); future.thenAccept(System.out::println); /** * 异步加载 * * @param key * @return */ public Object asyncOperator(String key){ AsyncLoadingCache\u003cString, Object\u003e cache = Caffeine.newBuilder() .maximumSize(100) .expireAfterWrite(1, TimeUnit.MINUTES) .buildAsync(k -\u003e setAsyncValue(key).get()); return cache.get(key); } public CompletableFuture\u003cObject\u003e setAsyncValue(String key){ return CompletableFuture.supplyAsync(() -\u003e { return key + \"value\"; }); } 2. 驱逐策略 驱逐策略(回收策略)在创建缓存的时候进行指定。\n常用的有基于容量的驱逐和基于时间的驱逐。\n基于容量的驱逐需要指定缓存容量的最大值，当缓存容量达到最大时，Caffeine将使用LRU策略对缓存进行淘汰； 基于时间的驱逐策略如字面意思，可以设置在最后访问/写入一个缓存经过指定时间后，自动进行淘汰。 驱逐策略可以组合使用，任意驱逐策略生效后，该缓存条目即被驱逐。\nFIFO：先进先出 LRU：最近最少使用，淘汰最长时间没有被使用的条目 LFU：最不经常使用，淘汰一段时间内使用次数最少的条目 Caffeine有4种缓存淘汰设置:\n大小 （LFU算法进行淘汰） 权重 （大小与权重 只能二选一） 时间 引用 （不常用，本文不介绍） 2.1 基于大小的过期 Cache\u003cInteger, Integer\u003e cache = Caffeine.newBuilder() //超过10个后会使用W-TinyLFU算法进行淘汰 .maximumSize(10) .evictionListener((key, val, removalCause) -\u003e { log.info(\"淘汰缓存：key:{} val:{}\", key, val); }) .build(); for (int i = 1; i \u003c 20; i++) { cache.put(i, i); } Thread.sleep(500);//缓存淘汰是异步的 // 打印还没被淘汰的缓存 System.out.println(cache.asMap()); // 根据缓存的计数进行驱逐 LoadingCache\u003cString, Object\u003e cache = Caffeine.newBuilder() .maximumSize(10000) .build(key -\u003e function(key)); 2.2 基于权重的过期 maximumWeight与maximumSize不可以同时使用\nCache\u003cInteger, Integer\u003e cache = Caffeine.newBuilder() //限制总权重，若所有缓存的权重加起来\u003e总权重就会淘汰权重小的缓存 .maximumWeight(100) .weigher((Weigher\u003cInteger, Integer\u003e) (key, value) -\u003e key) .evictionListener((key, val, removalCause) -\u003e { log.info(\"淘汰缓存：key:{} val:{}\", key, val); }) .build(); //总权重其实是=所有缓存的权重加起来 int maximumWeight = 0; for (int i = 1; i \u003c 20; i++) { cache.put(i, i); maximumWeight += i; } System.out.println(\"总权重=\" + maximumWeight); Thread.sleep(500);//缓存淘汰是异步的 // 打印还没被淘汰的缓存 System.out.println(cache.asMap()); // 根据缓存的权重来进行驱逐（权重只是用于确定缓存大小，不会用于决定该缓存是否被驱逐） LoadingCache\u003cString, Object\u003e cache1 = Caffeine.newBuilder() .maximumWeight(10000) .weigher(key -\u003e function1(key)) .build(key -\u003e function(key)); 2.3 基于时间的过期 /** * 访问后到期（每次访问都会重置时间，也就是说如果一直被访问就不会被淘汰） */ @Test public void expireAfterAccessTest() throws InterruptedException { Cache\u003cInteger, Integer\u003e cache = Caffeine.newBuilder() .expireAfterAccess(1, TimeUnit.SECONDS) //可以指定调度程序来及时删除过期缓存项，而不是等待Caffeine触发定期维护 //若不设置scheduler，则缓存会在下一次调用get的时候才会被动删除 .scheduler(Scheduler.systemScheduler()) .evictionListener((key, val, removalCause) -\u003e { log.info(\"淘汰缓存：key:{} val:{}\", key, val); }) .build(); cache.put(1, 2); System.out.println(cache.getIfPresent(1)); Thread.sleep(3000); System.out.println(cache.getIfPresent(1));//null } /** * 写入后到期 */ @Test public void expireAfterWriteTest() throws InterruptedException { Cache\u003cInteger, Integer\u003e cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.SECONDS) //可以指定调度程序来及时删除过期缓存项，而不是等待Caffeine触发定期维护 //若不设置scheduler，则缓存会在下一次调用get的时候才会被动删除 .scheduler(Scheduler.systemScheduler()) .evictionListener((key, val, removalCause) -\u003e { log.info(\"淘汰缓存：key:{} val:{}\", key, val); }) .build(); cache.put(1, 2); Thread.sleep(3000); System.out.println(cache.getIfPresent(1));//null } // 基于固定的到期策略进行退出 LoadingCache\u003cString, Object\u003e cache = Caffeine.newBuilder() .expireAfterAccess(5, TimeUnit.MINUTES) .build(key -\u003e function(key)); LoadingCache\u003cString, Object\u003e cache1 = Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .build(key -\u003e function(key)); // 基于不同的到期策略进行退出 LoadingCache\u003cString, Object\u003e cache2 = Caffeine.newBuilder() .expireAfter(new Expiry\u003cString, Object\u003e() { @Override public long expireAfterCreate(String key, Object value, long currentTime) { return TimeUnit.SECONDS.toNanos(seconds); } @Override public long expireAfterUpdate(@Nonnull String s, @Nonnull Object o, long l, long l1) { return 0; } @Override public long expireAfterRead(@Nonnull String s, @Nonnull Object o, long l, long l1) { return 0; } }).build(key -\u003e function(key)); Caffeine提供了三种定时驱逐策略:\nexpireAfterAccess(long, TimeUnit):在最后一次访问或者写入后开始计时，在指定的时间后过期。假如一直有请求访问该key，那么这个缓存将一直不会过期。 expireAfterWrite(long, TimeUnit): 在最后一次写入缓存后开始计时，在指定的时间后过期。 expireAfter(Expiry): 自定义策略，过期时间由Expiry实现独自计算。 缓存的删除策略使用的是惰性删除和定时删除。这两个删除策略的时间复杂度都是o(1)。\n3. 刷新机制 refreshAfterWrite() 表示x秒后自动刷新缓存的策略可以配合淘汰策略使用，注意的是刷新机制只支持 LoadingCache 和 AsyncLoadingCache\nprivate static int NUM = 0; @Test public void refreshAfterWriteTest() throws InterruptedException { LoadingCache\u003cInteger, Integer\u003e cache = Caffeine.newBuilder() .refreshAfterWrite(1, TimeUnit.SECONDS) //模拟获取数据，每次获取就自增1 .build(integer -\u003e ++NUM); //获取ID=1的值，由于缓存里还没有，所以会自动放入缓存 System.out.println(cache.get(1));// 1 // 延迟2秒后，理论上自动刷新缓存后取到的值是2 // 但其实不是，值还是1，因为refreshAfterWrite并不是设置了n秒后重新获取就会自动刷新 // 而是x秒后\u0026\u0026第二次调用getIfPresent的时候才会被动刷新 Thread.sleep(2000); System.out.println(cache.getIfPresent(1));// 1 //此时才会刷新缓存，而第一次拿到的还是旧值 System.out.println(cache.getIfPresent(1));// 2 } 4. 移除事件监听 Cache\u003cString, Object\u003e cache = Caffeine.newBuilder() .removalListener((String key, Object value, RemovalCause cause) -\u003e System.out.printf(\"Key %s was removed (%s)%n\", key, cause)) .build(); 5. 写入外部存储 CacheWriter 方法可以将缓存中所有的数据写入到第三方。\nLoadingCache\u003cString, Object\u003e cache2 = Caffeine.newBuilder() .writer(new CacheWriter\u003cString, Object\u003e() { @Override public void write(String key, Object value) { // 写入到外部存储 } @Override public void delete(String key, Object value, RemovalCause cause) { // 删除外部存储 } }) .build(key -\u003e function(key)); 如果你有多级缓存的情况下，这个方法还是很实用。注意：CacheWriter不能与弱键或AsyncLoadingCache一起使用。\n6. 统计 LoadingCache\u003cString, String\u003e cache = Caffeine.newBuilder() //创建缓存或者最近一次更新缓存后经过指定时间间隔，刷新缓存；refreshAfterWrite仅支持LoadingCache .refreshAfterWrite(1, TimeUnit.SECONDS) .expireAfterWrite(1, TimeUnit.SECONDS) .expireAfterAccess(1, TimeUnit.SECONDS) .maximumSize(10) //开启记录缓存命中率等信息 .recordStats() //根据key查询数据库里面的值 .build(key -\u003e { Thread.sleep(1000); return new Date().toString(); }); cache.put(\"1\", \"shawn\"); cache.get(\"1\"); /* * hitCount :命中的次数 * missCount:未命中次数 * requestCount:请求次数 * hitRate:命中率 * missRate:丢失率 * loadSuccessCount:成功加载新值的次数 * loadExceptionCount:失败加载新值的次数 * totalLoadCount:总条数 * loadExceptionRate:失败加载新值的比率 * totalLoadTime:全部加载时间 * evictionCount:丢失的条数 */ System.out.println(cache.stats()); 5. 总结 上述一些策略在创建时都可以进行自由组合，一般情况下有两种方法\n设置 maxSize、refreshAfterWrite，不设置 expireAfterWrite/expireAfterAccess。设置 expireAfterWrite 当缓存过期时会同步加锁获取缓存，所以设置 expireAfterWrite 时性能较好，但是某些时候会取旧数据，适合允许取到旧数据的场景 设置 maxSize、expireAfterWrite/expireAfterAccess，不设置 refreshAfterWrite。数据一致性好，不会获取到旧数据，但是性能没那么好（对比起来），适合获取数据时不耗时的场景 ","caffine-cache-在算法上的优点w-tinylfu#Caffine Cache 在算法上的优点：W-TinyLFU":"说到优化，Caffine Cache到底优化了什么呢？\n常见的缓存淘汰算法还有FIFO，LRU，LFU：\nFIFO：先进先出，在这种淘汰算法中，先进入缓存的会先被淘汰，会导致命中率很低。 LRU：最近最少使用算法，每次访问数据都会将其放在我们的队尾，如果需要淘汰数据，就只需要淘汰队首即可。仍然有个问题，如果有个数据在 1 分钟访问了 1000次，再后 1 分钟没有访问这个数据，但是有其他的数据访问，就导致了我们这个热点数据被淘汰。 LFU：最近最少频率使用，利用额外的空间记录每个数据的使用频率，然后选出频率最低进行淘汰。这样就避免了 LRU 不能处理时间段的问题。 上面三种策略各有利弊，实现的成本也是一个比一个高，同时命中率也是一个比一个好。Guava Cache虽然有这么多的功能，但是本质上还是对LRU的封装，如果有更优良的算法，并且也能提供这么多功能，相比之下就相形见绌了。\nLFU 的局限性 ：在 LFU 中只要数据访问模式的概率分布随时间保持不变时，其命中率就能变得非常高。比如有部新剧出来了，我们使用 LFU 给他缓存下来，这部新剧在这几天大概访问了几亿次，这个访问频率也在我们的 LFU 中记录了几亿次。但是新剧总会过气的，比如一个月之后这个新剧的前几集其实已经过气了，但是他的访问量的确是太高了，其他的电视剧根本无法淘汰这个新剧，所以在这种模式下是有局限性。\nLRU 的优点和局限性 ：LRU可以很好的应对突发流量的情况，因为他不需要累计数据频率。但LRU通过历史数据来预测未来是局限的，它会认为最后到来的数据是最可能被再次访问的，从而给与它最高的优先级。\n在现有算法的局限性下，会导致缓存数据的命中率或多或少的受损，而命中略又是缓存的重要指标。HighScalability网站刊登了一篇文章，由前Google工程师发明的W-TinyLFU——一种现代的缓存 。Caffine Cache就是基于此算法而研发。Caffeine 因使用 Window TinyLfu 回收策略，提供了一个近乎最佳的命中率。\n当数据的访问模式不随时间变化的时候，LFU的策略能够带来最佳的缓存命中率。然而LFU有两个缺点：首先，它需要给每个记录项维护频率信息，每次访问都需要更新，这是个巨大的开销；其次，如果数据访问模式随时间有变，LFU的频率信息无法随之变化，因此早先频繁访问的记录可能会占据缓存，而后期访问较多的记录则无法被命中。因此，大多数的缓存设计都是基于LRU或者其变种来进行的。相比之下，LRU并不需要维护昂贵的缓存记录元信息，同时也能够反应随时间变化的数据访问模式。然而，在许多负载之下，LRU依然需要更多的空间才能做到跟LFU一致的缓存命中率。因此，一个“现代”的缓存，应当能够综合两者的长处。\nTinyLFU维护了近期访问记录的频率信息，作为一个过滤器，当新记录来时，只有满足TinyLFU要求的记录才可以被插入缓存。如前所述，作为现代的缓存，它需要解决两个挑战：\n一个是如何避免维护频率信息的高开销； 另一个是如何反应随时间变化的访问模式。 首先来看前者，TinyLFU借助了数据流Sketching技术，Count-Min Sketch显然是解决这个问题的有效手段，它可以用小得多的空间存放频率信息，而保证很低的False Positive Rate。但考虑到第二个问题，就要复杂许多了，因为我们知道，任何Sketching数据结构如果要反应时间变化都是一件困难的事情，在Bloom Filter方面，我们可以有Timing Bloom Filter，但对于CMSketch来说，如何做到Timing CMSketch就不那么容易了。TinyLFU采用了一种基于滑动窗口的时间衰减设计机制，借助于一种简易的reset操作：每次添加一条记录到Sketch的时候，都会给一个计数器上加1，当计数器达到一个尺寸W的时候，把所有记录的Sketch数值都除以2，该reset操作可以起到衰减的作用。\nW-TinyLFU 主要用来解决一些稀疏的突发访问元素。在一些数目很少但突发访问量很大的场景下，TinyLFU将无法保存这类元素，因为它们无法在给定时间内积累到足够高的频率。因此W-TinyLFU就是结合LFU和LRU，前者用来应对大多数场景，而LRU用来处理突发流量。\n在处理频率记录的方案中，你可能会想到用hashMap去存储，每一个key对应一个频率值。那如果数据量特别大的时候，是不是这个hashMap也会特别大呢。由此可以联想到 Bloom Filter，对于每个key，用n个byte每个存储一个标志用来判断key是否在集合中。原理就是使用k个hash函数来将key散列成一个整数。\n在W-TinyLFU中使用Count-Min Sketch记录我们的访问频率，而这个也是布隆过滤器的一种变种.\n如果需要记录一个值，那我们需要通过多种Hash算法对其进行处理hash，然后在对应的hash算法的记录中+1，为什么需要多种hash算法呢？由于这是一个压缩算法必定会出现冲突，比如我们建立一个byte的数组，通过计算出每个数据的hash的位置。比如张三和李四，他们两有可能hash值都是相同，比如都是1那byte[1]这个位置就会增加相应的频率，张三访问1万次，李四访问1次那byte[1]这个位置就是1万零1，如果取李四的访问评率的时候就会取出是1万零1，但是李四命名只访问了1次啊，为了解决这个问题，所以用了多个hash算法可以理解为long[][]二维数组的一个概念，比如在第一个算法张三和李四冲突了，但是在第二个，第三个中很大的概率不冲突，比如一个算法大概有1%的概率冲突，那四个算法一起冲突的概率是1%的四次方。通过这个模式我们取李四的访问率的时候取所有算法中，李四访问最低频率的次数。所以他的名字叫Count-Min Sketch。\n参考链接：\nhttps://mp.weixin.qq.com/s/ttAmorvQBTzY8DvIgSFSVA https://mp.weixin.qq.com/s/m8DwlimtJs8ezl5hOXj37w ","springboot整合caffeine#SpringBoot整合Caffeine":"1. 相关注解 1.1 相关依赖 如果要使用@Cacheable注解，需要引入相关依赖，并在任一配置类文件上添加@EnableCaching注解\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-cache\u003c/artifactId\u003e \u003c/dependency\u003e 1.2 常用注解 @Cacheable ：表示该方法支持缓存。当调用被注解的方法时，如果对应的键已经存在缓存，则不再执行方法体，而从缓存中直接返回。当方法返回null时，将不进行缓存操作。 @CachePut ：表示执行该方法后，其值将作为最新结果更新到缓存中，每次都会执行该方法。 @CacheEvict ：表示执行该方法后，将触发缓存清除操作。 @Caching ：用于组合前三个注解，例如 @Caching(cacheable = @Cacheable(\"CacheConstants.GET_USER\"), evict = {@CacheEvict(\"CacheConstants.GET_DYNAMIC\",allEntries = true)} public User find(Integer id) { return null; } 1.3 常用注解属性 cacheNames/value ：缓存组件的名字，即cacheManager中缓存的名称。 key ：缓存数据时使用的key。默认使用方法参数值，也可以使用SpEL表达式进行编写。 keyGenerator ：和key二选一使用。 cacheManager ：指定使用的缓存管理器。 condition ：在方法执行开始前检查，在符合condition的情况下，进行缓存 unless ：在方法执行完成后检查，在符合unless的情况下，不进行缓存 sync ：是否使用同步模式。若使用同步模式，在多个线程同时对一个key进行load时，其他线程将被阻塞。 1.4 缓存同步模式 sync 开启或关闭，在 Cache 和 LoadingCache 中的表现是不一致的：\nCache中，sync表示是否需要所有线程同步等待 LoadingCache中，sync表示在读取不存在/已驱逐的key时，是否执行被注解方法 2. 实战 2.1 引入依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-cache\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.github.ben-manes.caffeine\u003c/groupId\u003e \u003cartifactId\u003ecaffeine\u003c/artifactId\u003e \u003c/dependency\u003e 2.2 添加注解开启缓存支持 添加@EnableCaching注解：\n@SpringBootApplication @EnableCaching public class SingleDatabaseApplication { public static void main(String[] args) { SpringApplication.run(SingleDatabaseApplication.class, args); } } 2.3 配置文件的方式注入相关参数 properties文件\nspring.cache.cache-names=cache1 spring.cache.caffeine.spec=initialCapacity=50,maximumSize=500,expireAfterWrite=10s 或Yaml文件\nspring: cache: type: caffeine cache-names: - userCache caffeine: spec: maximumSize=1024,refreshAfterWrite=60s 如果使用refreshAfterWrite配置,必须指定一个CacheLoader.不用该配置则无需这个bean,如上所述,该CacheLoader将关联被该缓存管理器管理的所有缓存，所以必须定义为CacheLoader\u003cObject, Object\u003e，自动配置将忽略所有泛型类型。\nimport com.github.benmanes.caffeine.cache.CacheLoader; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author: rickiyang * @date: 2019/6/15 * @description: */ @Configuration public class CacheConfig { /** * 相当于在构建LoadingCache对象的时候 build()方法中指定过期之后的加载策略方法 * 必须要指定这个Bean，refreshAfterWrite=60s属性才生效 * @return */ @Bean public CacheLoader\u003cString, Object\u003e cacheLoader() { CacheLoader\u003cString, Object\u003e cacheLoader = new CacheLoader\u003cString, Object\u003e() { @Override public Object load(String key) throws Exception { return null; } // 重写这个方法将oldValue值返回回去，进而刷新缓存 @Override public Object reload(String key, Object oldValue) throws Exception { return oldValue; } }; return cacheLoader; } } Caffeine常用配置说明：\ninitialCapacity=[integer]: 初始的缓存空间大小 maximumSize=[long]: 缓存的最大条数 maximumWeight=[long]: 缓存的最大权重 expireAfterAccess=[duration]: 最后一次写入或访问后经过固定时间过期 expireAfterWrite=[duration]: 最后一次写入后经过固定时间过期 refreshAfterWrite=[duration]: 创建缓存或者最近一次更新缓存后经过固定的时间间隔，刷新缓存 weakKeys: 打开key的弱引用 weakValues：打开value的弱引用 softValues：打开value的软引用 recordStats：开发统计功能 注意： expireAfterWrite和expireAfterAccess同时存在时，以expireAfterWrite为准。 maximumSize和maximumWeight不可以同时使用 weakValues和softValues不可以同时使用 需要说明的是，使用配置文件的方式来进行缓存项配置，一般情况能满足使用需求，但是灵活性不是很高，如果我们有很多缓存项的情况下写起来会导致配置文件很长。所以一般情况下你也可以选择使用bean的方式来初始化Cache实例。\n下面的演示使用bean的方式来注入：\npackage com.rickiyang.learn.cache; import com.github.benmanes.caffeine.cache.CacheLoader; import com.github.benmanes.caffeine.cache.Caffeine; import org.apache.commons.compress.utils.Lists; import org.springframework.cache.CacheManager; import org.springframework.cache.caffeine.CaffeineCache; import org.springframework.cache.support.SimpleCacheManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Primary; import java.util.ArrayList; import java.util.List; import java.util.concurrent.TimeUnit; /** * @author: rickiyang * @date: 2019/6/15 * @description: */ @Configuration public class CacheConfig { /** * 创建基于Caffeine的Cache Manager * 初始化一些key存入 * @return */ @Bean @Primary public CacheManager caffeineCacheManager() { SimpleCacheManager cacheManager = new SimpleCacheManager(); ArrayList\u003cCaffeineCache\u003e caches = Lists.newArrayList(); List\u003cCacheBean\u003e list = setCacheBean(); for(CacheBean cacheBean : list){ caches.add(new CaffeineCache(cacheBean.getKey(), Caffeine.newBuilder().recordStats() .expireAfterWrite(cacheBean.getTtl(), TimeUnit.SECONDS) .maximumSize(cacheBean.getMaximumSize()) .build())); } cacheManager.setCaches(caches); return cacheManager; } /** * 初始化一些缓存的 key * @return */ private List\u003cCacheBean\u003e setCacheBean(){ List\u003cCacheBean\u003e list = Lists.newArrayList(); CacheBean userCache = new CacheBean(); userCache.setKey(\"userCache\"); userCache.setTtl(60); userCache.setMaximumSize(10000); CacheBean deptCache = new CacheBean(); deptCache.setKey(\"userCache\"); deptCache.setTtl(60); deptCache.setMaximumSize(10000); list.add(userCache); list.add(deptCache); return list; } class CacheBean { private String key; private long ttl; private long maximumSize; public String getKey() { return key; } public void setKey(String key) { this.key = key; } public long getTtl() { return ttl; } public void setTtl(long ttl) { this.ttl = ttl; } public long getMaximumSize() { return maximumSize; } public void setMaximumSize(long maximumSize) { this.maximumSize = maximumSize; } } } 创建了一个SimpleCacheManager作为Cache的管理对象，然后初始化了两个Cache对象，分别存储user，dept类型的缓存。当然构建Cache的参数设置我写的比较简单，你在使用的时候酌情根据需要配置参数。\n2.4 使用注解来对 cache 增删改查 我们可以使用spring提供的 @Cacheable、@CachePut、@CacheEvict等注解来方便的使用caffeine缓存。\n如果使用了多个cahce，比如redis、caffeine等，必须指定某一个CacheManage为@primary，在@Cacheable注解中没指定 cacheManager 则使用标记为primary的那个。\ncache方面的注解主要有以下5个：\n@Cacheable 触发缓存入口（这里一般放在创建和获取的方法上， @Cacheable注解会先查询是否已经有缓存，有会使用缓存，没有则会执行方法并缓存） @CacheEvict 触发缓存的eviction（用于删除的方法上） @CachePut 更新缓存且不影响方法执行（用于修改的方法上，该注解下的方法始终会被执行） @Caching 将多个缓存组合在一个方法上（该注解可以允许一个方法同时设置多个注解） @CacheConfig 在类级别设置一些缓存相关的共同配置（与其它缓存配合使用） 说一下@Cacheable 和 @CachePut的区别：\n@Cacheable：它的注解的方法是否被执行取决于Cacheable中的条件，方法很多时候都可能不被执行。 @CachePut：这个注解不会影响方法的执行，也就是说无论它配置的条件是什么，方法都会被执行，更多的时候是被用到修改上。 简要说一下Cacheable类中各个方法的使用\nublic @interface Cacheable { /** * 要使用的cache的名字 */ @AliasFor(\"cacheNames\") String[] value() default {}; /** * 同value()，决定要使用那个/些缓存 */ @AliasFor(\"value\") String[] cacheNames() default {}; /** * 使用SpEL表达式来设定缓存的key，如果不设置默认方法上所有参数都会作为key的一部分 */ String key() default \"\"; /** * 用来生成key，与key()不可以共用 */ String keyGenerator() default \"\"; /** * 设定要使用的cacheManager，必须先设置好cacheManager的bean，这是使用该bean的名字 */ String cacheManager() default \"\"; /** * 使用cacheResolver来设定使用的缓存，用法同cacheManager，但是与cacheManager不可以同时使用 */ String cacheResolver() default \"\"; /** * 使用SpEL表达式设定出发缓存的条件，在方法执行前生效 */ String condition() default \"\"; /** * 使用SpEL设置出发缓存的条件，这里是方法执行完生效，所以条件中可以有方法执行后的value */ String unless() default \"\"; /** * 用于同步的，在缓存失效（过期不存在等各种原因）的时候，如果多个线程同时访问被标注的方法 * 则只允许一个线程通过去执行方法 */ boolean sync() default false; } 基于注解的使用方法：\npackage com.rickiyang.learn.cache; import com.rickiyang.learn.entity.User; import org.springframework.cache.annotation.CacheEvict; import org.springframework.cache.annotation.CachePut; import org.springframework.cache.annotation.Cacheable; import org.springframework.stereotype.Service; /** * @author: rickiyang * @date: 2019/6/15 * @description: 本地cache */ @Service public class UserCacheService { /** * 查找 * 先查缓存，如果查不到，会查数据库并存入缓存 * @param id */ @Cacheable(value = \"userCache\", key = \"#id\", sync = true) public void getUser(long id){ //查找数据库 } /** * 更新/保存 * @param user */ @CachePut(value = \"userCache\", key = \"#user.id\") public void saveUser(User user){ //todo 保存数据库 } /** * 删除 * @param user */ @CacheEvict(value = \"userCache\",key = \"#user.id\") public void delUser(User user){ //todo 保存数据库 } } 如果你不想使用注解的方式去操作缓存，也可以直接使用SimpleCacheManager获取缓存的key进而进行操作。注意: 上面的key使用了spEL 表达式，这个可以查阅spring的官方文档。","介绍#介绍":"Caffeine 是基于Java 1.8 的高性能本地缓存库，由 Guava 改进而来，而且在 Spring5 开始的默认缓存实现就将 Caffeine 代替原来的Google Guava，官方说明指出，其缓存命中率已经接近最优值。\n实际上Caffeine这样的本地缓存和 ConcurrentMap 很像，即支持并发，并且支持O(1)时间复杂度的数据存取。二者的主要区别在于：\nConcurrentMap 将存储所有存入的数据，直到你显式将其移除 Caffeine将通过给定的配置，自动移除“不常用”的数据，以保持内存的合理占用。 因此，一种更好的理解方式是：Cache是一种带有存储和移除策略的Map。"},"title":"本地缓存Caffeine"},"/blog/2024/10/short-link-service/":{"data":{"":"","状态码-301-和-302-的区别#状态码 301 和 302 的区别":"301 301 是永久重定向。301 跳转会默认被浏览器缓存，当用户第一次访问某个短链后，如果服务器返回 301 状态码，则这个用户在后后续多次访问同一短链接地址，浏览器会直接请求缓存中的跳转地址，不会再请求短链服务重新获取地址。这么做的优点是降低了服务器的压力，但是无法统计短链接的点击次数。\n302 302 是临时重定向。302 跳转默认不会被浏览器缓存，除非提示浏览器缓存。因此用户每次访问同一短链地址，浏览器都会去短链服务器上重新取长链接的地址。此方式优点是能够统计到短链接被点击的次数，但是服务器的压力变大了。","短链接和长链接映射的是实现方案#短链接和长链接映射的是实现方案":"哈希法 哈希法推荐 Google 出品的 MurmurHash 算法，MurmurHash 是一种非加密型哈希函数，非加密性能较高。\n哈希法的会存在哈希冲突的问题（即就是两个不同的URL可能会生成相同的短链接），为了解决这个问题可以采用增加salt字段。也就是将短链字段设置为唯一键，重复短链插入数据库抛出异常时候进行处理: 增加盐值到长链后面，然后重新使用这个拼接的长链进行hash计算。此方式最多重试三次，尽最大努力解决哈希冲突问题。访问短链时，一并取出salt值，将长链处理后进行返回。\nredis方案 在Redis中创建一个键，使用INCR命令递增该键的值，并将递增后的值作为唯一ID返回。由于Redis的INCR命令是原子性操作，所以可以确保每次生成的ID都是唯一的。为了增加ID的安全性，一般不建议使用Redis自增的数值，而是拼接一些其它信息，\nuuid方案 UUID是通过一系列算法生成的128位数字，通常基于时间戳、计算机硬件标识符、随机数等元素；uuid方案实现简单，无需网络交互就能保证了ID的唯一性。\n雪花算法 ID 雪花算法的生效id的效率高，但是雪花算法要避免时钟回拨的问题（会出现id重复的问题）","设计短链服务#设计短链服务":"由于是访问量很大，所以我们在设计的时候采用了LVS+Nginx扛住第一层的大流量。\nLVS使用keepalived来保证高可用，LVS是工作在第四层并且其负载能力强，它负责将请求分发到nginx上 nginx单机的并发5万，针对百万的并发至少需要20台nginx来处理大的流量，nginx将请求转发到公司的网关上 网关根据服务的URL来解析地址找到对应的服务器，由于是百万流量所以网关也需要做集群来处理请求。 网关将请求转发到真实的短链服务上，短链服务自身使用了sentinel来限流、使用本地缓存（常见的是Guava、caffeine）、分布式缓存（如redis）来缓存数据，使用布隆过滤器过滤无效的请求。 有效的请求未命中缓存，此时就查询数据库，由于数据库抗并发能力弱，所以对数据库做了主从模式、读写分离方式来应对高并发。 数据库中查询出来的数据要同步到缓存中，以便于下次同样的短链请求可以不查询数据库而直接给消费者提供数据响应。 参考链接：\nhttps://mp.weixin.qq.com/s/_6neJlc0Jc0w8JMfqnTr-g "},"title":"设计百万链路服务"},"/links/java_feature/":{"data":{"":" 最后更新日期：2021-06-24","java-10#Java 10":" 局部变量类型推断（Local-Variable Type Inference） //之前的代码格式 URL url = new URL(\"http://www.oracle.com/\"); URLConnection conn = url.openConnection(); Reader reader = new BufferedReader( new InputStreamReader(conn.getInputStream())) //java10中用var来声明变量 var url = new URL(\"http://www.oracle.com/\"); var conn = url.openConnection(); var reader = new BufferedReader( new InputStreamReader(conn.getInputStream())); var是一个保留类型名称，而不是关键字。所以之前使用var作为变量、方法名、包名的都没问题，但是如果作为类或接口名，那么这个类和接口就必须重命名了。\nvar的使用场景主要有以下四种：\n本地变量初始化。 增强for循环中。 传统for循环中声明的索引变量。 Try-with-resources 变量。​ 2.Optional类添加了新的方法orElseThrow(无参数版)。相比于已经存在的get方法，这个方法更推荐使用。","java-11#Java 11":" 支持Unicode 10.0,在jdk10中是8.0。 标准化HTTP Client 编译器线程的延迟分配。添加了新的命令-XX:+UseDynamicNumberOfCompilerThreads动态控制编译器线程的数量。 新的垃圾收集器—ZGC。一种可伸缩的低延迟垃圾收集器(实验性)。 Epsilon。一款新的实验性无操作垃圾收集器。Epsilon GC 只负责内存分配，不实现任何内存回收机制。这对于性能测试非常有用，可用于与其他GC对比成本和收益。 Lambda参数的局部变量语法。java10中引入的var字段得到了增强，现在可以用在lambda表达式的声明中。如果lambda表达式的其中一个形式参数使用了var，那所有的参数都必须使用var。 参考：\nhttps://www.jianshu.com/p/38985b61ea83 ","java-7#Java 7":"Java语法特性:\n二进制前缀0b或者0B。整型（byte, short, int, long）可以直接用二进制表示 字面常量数字的下划线。用下划线连接整数提升其可读性，自身无含义，不可用在数字的起始和末尾。 switch 支持String类型。 泛型实例化类型自动推断。 try-with-resources语句。 单个catch中捕获多个异常类型（用| 分割）并通过改进的类型检查重新抛出异常。 ","java-8#Java 8":" Lamda表达式(Lambda Expressions)。Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中)。 方法引用（Method references）。方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与Lambda联合使用，可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法（Default methods）。默认方法允许将新功能添加到库的接口中，并确保兼容实现老版本接口的旧有代码。 重复注解（Repeating Annotations）。重复注解提供了在同一声明或类型中多次应用相同注解类型的能力。 类型注解（Type Annotation）。在任何地方都能使用注解，而不仅仅在声明的地方。 类型推断增强。 方法参数反射（Method Parameter Reflection）。 Stream API 。新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。Stream API集成到了Collections API里。 HashMap改进，在键值哈希冲突时能有更好表现。 Date Time API。加强对日期和时间的处理。 java.util 包下的改进，提供了几个实用的工具类： 并行数组排序 标准的Base64编解码 支持无符号运算 Optional类 java.util.concurrent 包下增加了新的类和方法。 java.util.concurrent.ConcurrentHashMap 类添加了新的方法以支持新的StreamApi和lambada表达式。 java.util.concurrent.atomic 包下新增了类以支持可伸缩可更新的变量。 java.util.concurrent.ForkJoinPool类新增了方法以支持 common pool。 新增了java.util.concurrent.locks.StampedLock类，为控制读/写访问提供了一个基于性能的锁，且有三种模式可供选择。 HotSpot 删除了永久代. 方法调用的字节码指令支持默认方法。 ","java-9#Java 9":" Java模块系统 （Java Platform Module System）。 新的版本号格式。$MAJOR.$MINOR.$SECURITY.$PATCH java shell，交互式命令行控制台。 在private instance methods方法上可以使用@SafeVarargs注解。 支持diamond语法与匿名内部类结合使用。 下划线_不能单独作为变量名使用。 支持私有接口方法 Javadoc 简化Doclet API。 支持生成HTML5格式。 加入了搜索框,使用这个搜索框可以查询程序元素、标记的单词和文档中的短语。 支持新的模块系统。 JVM 增强了Garbage-First(G1)并用它替代Parallel GC成为默认的垃圾收集器。 统一了JVM 日志，为所有组件引入了同一个日志系统。 删除了JDK 8中弃用的GC组合。（DefNew + CMS，ParNew + SerialOld，Incremental CMS）。 properties文件支持UTF-8编码,之前只支持ISO-8859-1。 支持Unicode 8.0，在JDK8中是Unicode 6.2。 Optional类新增三个方法 "},"title":"Java各版本特性"},"/links/learning_material/":{"data":{"":"","ansible#Ansible":" Ansible中文权威指南 - https://ansible-tran.readthedocs.io/en/latest/ ","kubernetes#Kubernetes":" k8s官方文档 - https://kubernetes.io/zh/docs/home/ "},"title":"在线学习资源"},"/links/mirror/":{"data":{"":" 最近更新日期：2021-02-24","docker-hub#Docker Hub":"镜像列表 无需登录：\nAzure 中国镜像 - https://dockerhub.azk8s.cn 科大镜像站 - https://docker.mirrors.ustc.edu.cn 七牛云 - https://reg-mirror.qiniu.com 网易云 - https://hub-mirror.c.163.com 腾讯云 - https://mirror.ccs.tencentyun.com 需登录：\nDaoCloud - http://\u003cyour_code\u003e.m.daocloud.io 阿里云 - https://\u003cyour_code\u003e.mirror.aliyuncs.com 本地配置 创建或编辑 /etc/docker/daemon.json：\n{ \"registry-mirrors\": [ \"https://docker.mirrors.ustc.edu.cn\", \"https://reg-mirror.qiniu.com\" ] } 执行下面命令\nsudo systemctl daemon-reload sudo systemctl restart docker ","gcrio-和-k8sgcrio#gcr.io 和 k8s.gcr.io":"k8s.gcr.io 是 gcr.io/google-containers 的别名，所以 k8s.gcr.io/: 等同于 gcr.io/google-containers/:\n目前未找到这两个源的通用镜像站，只能去国内镜像站找别人传上来的副本：\nhttps://hub.docker.com/u/googlecontainersmirror (从 gcr.io 同步到Docker Hub的镜像, 只包含核心的几个镜像和版本, 能保障K8S正常运行) registry.aliyuncs.com/google_containers (阿里云第三方用户上传的镜像，镜像比较多) 最好是自己同步镜像而不直接使用现有的第三方个人镜像库，因为需要避免生产的K8S集群遭遇到安全问题","python3-pip#Python3 pip":"本地配置 临时使用时用参数 -i\npip install \u003c包名\u003e -i https://mirrors.aliyun.com/pypi/simple 指定全局安装源\npip config set global.index-url https://mirrors.aliyun.com/pypi/simple 镜像列表 阿里云：https://mirrors.aliyun.com/pypi/simple/ 中国科技大学 ：https://pypi.mirrors.ustc.edu.cn/simple/ 清华大学： https://pypi.tuna.tsinghua.edu.cn/simple/ ","quayio#quay.io":"镜像列表 quay-mirror.qiniu.com (七牛云, 推荐, 但没有找到长期支持的声明) quay.mirrors.ustc.edu.cn (中科大, 经常不可用, 不推荐) 本地配置 将镜像中的 quay.io 替换成国内镜像地址，例如：\nquay.io/prometheus/node-exporter:v0.18.1 # 替换成如下格式 quay-mirror.qiniu.com/prometheus/node-exporter:v0.18.1 "},"title":"国内常用镜像地址"}}
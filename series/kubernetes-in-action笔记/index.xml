<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes in Action笔记 on 保罗札记</title>
    <link>https://www.zengxi.net/series/kubernetes-in-action%E7%AC%94%E8%AE%B0/</link>
    <description>Recent content in Kubernetes in Action笔记 on 保罗札记</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Sun, 27 Dec 2020 23:08:00 +0800</lastBuildDate><atom:link href="https://www.zengxi.net/series/kubernetes-in-action%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes in Action笔记 - (12) Deployment</title>
      <link>https://www.zengxi.net/2020/12/k8s_deployment/</link>
      <pubDate>Sun, 27 Dec 2020 23:08:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_deployment/</guid>
      <description>Deployment是一种更高阶资源, 用于部署应用程序并以声明的方式升级应用。
在使用 Deployment 时, 实际的 pod是由 Deployment 的 Replicaset 创建和管理的, 而不是由 Deployment 直接创建和管理的。
在升级应用过程中，部署新版本的应用时，会创建新的Replicaset用于管理版本的pod。升级过程中的某个时刻，就会存在新旧两个版本的Replicaset。因此，需要引入Deployment来协调。
与Replicaset类似，Deployment也是由标签选择器、期望副数和pod模板组成的。此外,它还包含另一个字段，用于指定一 个部署策略，表示在修改Deployment资源时应该如何执行更新。
创建Deployment 1appVersion:apps/v1beta12kind:Deployment 3metadata:4name:kubia5spec:6replicas:37template:8metadata:9name:kubia10labels:11app:kubia12spec:13containers:14- image:luksa/kubia:vl15name:nodejs创建一个Deployment
1# 确保在创建时使用了 --record 选项。 这个选项会记录历史版本号, 在之后的操作中非常有用 2kubectl create -f kubia-deployment-v1.yaml --record 查看 Deployment 的详细信息
1kubectl get deployment 2 3kubectl describe de­ployment 查看部署状态
1 kubectl rollout status deployment kubia 升级deployment 只需修改 Deployment 资源中定义的 pod 模板, k8s 会自动将实际的系统状态收敛为资源中定义的状态
不同的 Deployment 升级策略：
 RollingUpdate：执行滚动更新，默认值。如果应用能够支持多个版本同时对外提供服务, 则推荐使用这个策略来升级应用 Recreate：一次性删除所有旧版本的 pod, 然后创建新的 pod。如果应用程序不支持多个版本同时对外提供服务, 需要在启动新版本之前完全停用旧版本, 那么需要使用这种策略。但是会导致应用程序出现短暂的不可用。  下面是修改 Deployment 或其他资源的不同方式。这些方式在操作 Deployment 资源时效果都是一样的。 它们无非就是修改Deployment 的规格定义, 修改后会触发滚动升级过程。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (11) 从应用访问pod元数据及其他资源</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_meta_data/</link>
      <pubDate>Sat, 26 Dec 2020 14:53:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_meta_data/</guid>
      <description>通过Downward API传递元数据 对于pod调度、运行前预设的数据，可以通过环境变量或者configMap和secret卷向应用传递配置数据。但是对于那些不能预先知道的数据, 比如pod的IP、 主机名或者是通过ReplicaSet等控制生成的pod名称，该如何获取呢？这种类型的数据，可以通过使用Kubernetes Downward API解决。
Downward API可以给在pod中运行的进程暴露pod的元数据。目前可以给容器传递以下数据:
 pod的名称 pod的IP pod所在的命名空间 pod运行节点的名称 pod运行所归属的服务账户的名称 每个容器请求的CPU和内存的使用量 每个容器可以使用的CPU和内存的限制 pod的标签 pod的注解  通过环境变量暴露元数据 1env:2- name:POD_NAME3# 引用pod manifest中的元数据名称字段,而不是设定一个具体的值4valueFrom:5fieldRef:6fieldPath:metadata.name7- name:POD_NAMESPACE8valueFrom:9fieldRef:10fieldPath:metadata.namespace11- name:POD_IP12valueFrom:13fieldRef:14fieldPath:status.podIP15- name:NODE_NAME16valueFrom:17fieldRef:18fieldPath:spec.nodeName19- name:SERVICE_ACCOUNT20valueFrom:21fieldRef:22fieldPath:spec.serviceAccountName23- name:CONTAINER_CPU_REQUEST_MILLICORES24valueFrom:25# 容器请求的CPU和内存使用量是使用resourceFieldRef字段而不是feildRef字段26resourceFieldRef:27resource:requests.cpu28divisor:1m # 对于资源相关字段，定义一个基数单位，从而生成每一部分的值29- name:CONTAINER MEMORY LIMIT KIBIBYTES30valueFrom:31resourceFieldRef:32resource:limits.memory33divisor:1Ki34对于暴露资源请 和使用限制的环境变量, 我们会设定一个基数单位。实际的资源请求值和限制值除以这个基数单位, 所得的结果通过环境变量暴露出去。在上面的例子中, 我们设定 CPU 请求的基数为1m (即1 millicore, 也就是千分之一核CPU)。当我们设置资源请求为15m时, 环境变量CONTAINER_CPU_REQUEST_MILLICORES的值就是15
在完成创建pod后, 我们可以使用kubectl exec命令来查看容器中的所有环境变量
1kubectl exec downward env 通过卷传递元数据 可以定义一个downwardAPI卷，并以文件的方式挂载在容器中。
1apiVersion:v12kind:Pod3metadata:4# 后面会添加定义，通过downwardAPI卷来暴露这些标签5name:downward6labels:7foo:bar8annotations:9key1:value110key2:|11multi 12line 13value14spec:15containers:16- name:main17image:busybox18command:[&amp;#34;sleep&amp;#34;,&amp;#34;9999999&amp;#34;]19resources:20requests:21cpu:15m22memory:l00Ki23limits:24cpu:100m25memory:4Mi26volumeMounts:27# 挂载卷28- name:downward29mountPath:/etc/downward30volumes:31# 定义一个名字为downward的downwardAPI卷32- name:downward33downwardAPI:34items:35# Pod名称（来自manifest文件中的metadata.name字段）将被写入podName这个文件36- path:&amp;#34;podName&amp;#34;37fieldRef:38fieldPath:metadata.name39- path:&amp;#34;podNamespace&amp;#34;40fieldRef:41fieldPath:metadata.namespace42- path:&amp;#34;labels&amp;#34;43fieldRef:44fieldPath:metadata.labels45- path:&amp;#34;annotations&amp;#34;46fieldRef:47fieldPath:metadata.annotations48- path:&amp;#34;containerCpuRequestMilliCores&amp;#34;49resourceFieldRef:50containerName:main51resource:requests.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (10) 使用ConfigMap与Secret传递应用配置</title>
      <link>https://www.zengxi.net/2020/12/k8s_config_map_secret/</link>
      <pubDate>Fri, 25 Dec 2020 16:14:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_config_map_secret/</guid>
      <description>向容器传递应用程序的配置参数 方法：
 向容器传递命令行参数 为每个容器设置自定义环境变量 通过特殊类型的卷将配置文件挂载到容器中  向容器传递命令行参数 在Docker中定义命令与参数 容器中运行的完整指令由两部分组成:命令与参数。Dockerfile中的两种指令分别定义命令与参数这两个部分：
 ENTRYPOINT: 定义容器启动时被调用的可执行程序 CMD: 指定传递给ENTRYPOINT的参数。  尽管可以直接使用CMD指令指定镜像运行时想要执行的命令, 正确的做法依旧 是借助ENTRYPOINT指令, 仅仅用CMD指定所需的默认参数。 这样, 镜像可以直 接运行, 无须添加任何参数
1docker run &amp;lt;image&amp;gt; 或者是添加一些参数, 覆盖Dockerile中任何由CMD指定的默认参数值:
1docker run &amp;lt;image&amp;gt; &amp;lt;arguments&amp;gt; shell与exec的区别 上述两条指令均支持以下两种形式。两者的区别在于指定的命令是否是在shell中被调用。
 shell形式。如ENTRYPOINT node app.js。 exec形式。如ENTRYPOINT [&amp;quot;node&amp;quot;, &amp;quot;app.js&amp;quot;]。  下面用例子来看他们的区别
1# exec形式 2# 从返回的进程列表看出:这里是直接运行node进程,而并非在shell中执行。 3$ docker exec 4675d ps x 4PID TTY STAT TIME COMMAND 51 ? Ssl 0:00 node app.Js 612 ? Rs 0:00 ps x 7 8# shell形式 9# 可以看出,主进程(PID 1)是shell进程而非node进程,node进程(PID 7)于shell中启动。  10$ docker exec -it e4bad ps x 11PID TTY STAT TIME COMMAND 121 ?</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (9) 卷</title>
      <link>https://www.zengxi.net/2020/12/k8s_volume/</link>
      <pubDate>Tue, 22 Dec 2020 22:16:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_volume/</guid>
      <description>卷 卷是 pod 的一个组成部分，不是独立的 Kubernetes 对象, 不能单独创建或删除。 pod 中的所有容器都可以使用卷, 但必须先将它挂载在每个需要访问它的容器中。
卷类型 主要类型：
 emptyDir:用于存储临时数据的简单空目录。 hostPath: 用于将目录从工作节点的文件系统挂载到pod中 gitRepo: 通过检出Git仓库的内容来初始化的卷 nfs: 挂载到pod中的NFS共享卷 用于挂载云服务商提供的特定存储类型。比如，gcePersistentDi sk (Google 高效能型存储磁盘卷)、 awsElasticBlockStore (AmazonWeb 服务弹性块存储卷)、 azureDisk (Microsoft Azure 磁盘卷) 用于挂载其他类型的网络存储。比如，cinder、cephfs、iscsi、flocker、glusterfs、quobyte、rbd、flexVolume、vsphere-Volume、photonPersistentDisk 、scaleIO configMap、secret、downwardAPI 一一用于将 k8s 部分资源和集群信息公开给 pod 的特殊类型的卷 persistentVolumeClaim：一种使用预置或者动态配置的持久存储类型  emptyDir 卷从一个空目录开始,运行在 pod 内的应用程序可以写入它需要的任何文件。当删除 pod 时,卷的内容就会丢失。
一个 emptyDir 卷对于在同一个 pod 中运行的容器之间共享文件特别有用。但是它也可以被单个容器用于将数据临时写入磁盘。
下面是个例子
1apiVersion:vl2kind:Pod3metadata:4name :fortune5spec:6containers:7- image:luksa/fortune8name:html-generator9volumeMounts:10- name:html11mountPath:/var/html/docs12- image:nginx:alpine13name:web-server14volumeMounts :15- name:html16mountPath:/usr/share/nginx/html17readOnly:true18ports:19- containerPort:8020protocol:TCP21volumes:22- name:html23emptyDir:{}medium属性可以指定存储介质。比如内存
1volumes:2name:html3emptyDir:4medium:Memory使用 Git 仓库作为存储卷 gitRepo 卷基本上也是 一 个 emptyDir 卷,它通过克隆 Git 仓库并在 pod 启动时(但在创建容器之前) 检出特定版本来填充数据</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (8) 服务、Endpoint、Ingress</title>
      <link>https://www.zengxi.net/2020/12/k8s_service/</link>
      <pubDate>Sun, 20 Dec 2020 21:17:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_service/</guid>
      <description>什么是服务 服务是一种为一组功能相同的 pod 提供单 一 不变的接入点的资源。当服务存在时,它的 IP 地址和端口不会改变
为什么需要服务 pod 的存在是短暂的,一个 pod 可能会在任何时候消失, 或许因为它所在节点发生故障, 或许因为有人删除了 pod, 或者因为 pod 被从一个健康的节点剔除了。 当其中任何一种情况发生时, 消失的 pod 将被ReplicationController 替换为新的 pod。 新的 pod 与替换它的 pod 具有不同的 IP 地址。
这就是需要服务的地方，解决不断变化的 pod IP 地址的问题, 以及在一个固定的IP和端口对上对外暴露多个 pod。当一个服务被创建时, 它会得到一个静态的 IP, 在服务的生命周期中这个 IP不会发生改变。 客户端应该 通过固定 IP 地址连接到服务, 而不是直接连接 pod。服务会确保其中一个pod 接收连接, 而不关心 pod 当前运行在哪里(以及它的 IP 地址 是什么)。
创建服务 通过 kubectl expose 创建服务
1kubectl expose pod valid-pod --port=444 --name=frontend 通过 YAML 描述文件来创建服务
1apiVersion:v12kind:Service3metadata:4name:kubia5spec:6ports:7- port:80# 该服务的可用端口8targetPort:8080# 转发到的容器端口9# 选择Pod10selector:11app:kubia服务的一些配置 会话的亲和性 如果多次执行同样的命令, 每次调用执行在随机的pod上。如果希望特定客户端产生的所有请求每次都指向同一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (默认值是None)。这种方式将会使服务代理将来自同 一 个 client IP 的所有请求转发至同一个pod上</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (7) DaemonSet、Job和CronJob</title>
      <link>https://www.zengxi.net/2020/12/k8s_daemonset_job/</link>
      <pubDate>Sun, 13 Dec 2020 19:52:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_daemonset_job/</guid>
      <description>DaemonSet DaemonSet 用于确保一个pod匹配它的选择器并在每个节点上运行。因此，它并没有期望的副本数的概念。
如果节点下线, DaemonSet不会在其他地方重新创建pod。 但是, 当将一个新节 点添加到集群中时, DaemonSet会立刻部署一个新的pod实例。
使用场景的例子：
 pod执行系统级别的与基础结构相关的操作。例如, 希望在每个节点上运行日志收集器和资源监控器。 另一个典型的例子是Kubemetes 自己的kube-proxy进程, 它需要运行在所有节点上才能使服务工作  可以通过 pod 模板中的 nodeSelector 属性让 DaemonSet 只在特定的节点上运行 pod。
1apiVersion:apps/vlbeta22kind:DaemonSet3metadata:4name:ssd-monitor5spec:6selector:7matchLabels:8app:ssd-monitor9template:10metadata:11labels:12app:ssd-monitor13spec:14# pod模板包含 会选择有disk=ssd标签的节点个节点选择器,15nodeSelector:16disk:ssd 17containers:18- name:main19image:luksa/ssd-monitorJob Job允许运行一种 pod, 该 pod 在内部进程成功结束时, 不重启容器。
在发生节点故障时,该节点上由 Job 管理的 pod 将按照 ReplicationSet 的 pod 的方式,重新安排到其他节点。 如果进程本身异常退出(进程返回错误退出代码时), 可以将 Job 配置为重新启动容器。
Job 对于临时任务很有用, 关键是任务要以正确的方式结束。需要明确地将重启策略设置为OnFa辽ure或Never，防止容器在完成任务时重新启动
1apiVersion:batch/vl2kind:Job3metadata:4name:batch-job5spec:6template:7metadata:8labels:9app:batch-job10spec:11# Job 不能使用Always作为默认的重启策略12restartPolicy:OnFailure13containers:14- name:main15image:luksa/ssd-monitor作业可以配置为创建多个pod实例, 以并行或串行方式运行它们。这是通过在Job配置中设置 completions和paralletism属性来完成的。
如果需要一个Job顺序运行多次，则可以将completions设为希望运行的次数。Job将一个接一个地运行五个pod。它最初创建一个pod, 当pod的容器运行完成时,它创建第二个pod, 以此类推，直到五个pod成功完成。如果其中 一 个pod发生故障，工作会创建 一个新的pod, 所以Job总共可以创建五个以上的pod。
1apiVersion:batch/vl2kind:Job3metadata:4name:multi-completion-batch-job5spec:6completions:57template:8...通过paralletism Job配置属性,指定允许多少个pod并行执行
1apiVersion:batch/vl2kind:Job3metadata:4name:multi-completion-batch-job5spec:6completions:57paralletism:28template:9...可以在 Job 运行时更改 Job 的 parallelism 属性</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (6) ReplicationController和ReplicationSet</title>
      <link>https://www.zengxi.net/2020/12/k8s_replctl_replset/</link>
      <pubDate>Sun, 13 Dec 2020 10:16:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_replctl_replset/</guid>
      <description>托管的Pod 如果是直接创建Pod，当节点失效，这个Pod就会丢失。
如果是通过ReplicationController或者Deployment等资源来创建的，那就属于托管的资源。k8s集群会管理并检测它的运行状态，当一些意外情况发生的，k8s会自动采取应对措施。
ReplicationController ReplicationController是一种k8s资源，会持续监控正在运行的pod列表, 并保证相应类型的pod的数目与期望相符。
一个ReplicationController有三个主要部分：
 label selector (标签选择器), 用于确定ReplicationController作用域中有哪些pod replica count (副本个数), 指定应运行的pod 数量 pod template (pod模板), 用于创建新的pod 副本  使用 ReplicationController 的好处:
 确保一个 pod (或多个 pod 副本)持续运行, 方法是在现有 pod 丢失时启动一个新 pod 。 集群节点发生故障时, 它将为故障节点上运行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。 它能轻松实现 pod 的水平伸缩，手动和自动都可以  创建一个ReplicationController
1apiVersion:vl2kind:Replicationcontroller3metadata:4name:kubia5spec:6replicas:37selector:8app:kubia9template:10metadata:11labels:12app:kubia13spec:14containers:15- name:kubia16image:luksa/kubia17ports:18- containerPort:8080通过kubectl get命令显示的关于ReplicationController的信息
1kubectl get rc 2 3kubectl get replicationcontroller 通过kubectl describe查看附加信息
1kubectl describe rc kubia 通过更改pod的标签, 可以将它从ReplicationController的作用域中添加或删除，甚至移动到另外一个ReplicationController
ReplicationController 的 pod 模板可以随时修改，但是只会影响后面新建的 Pod。如果需要修改旧的Pod，要将Pod删除，ReplicationController会自动根据新的模板创建Pod来替代。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (5) Pod的生命周期与探针</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_lifecycle_probes/</link>
      <pubDate>Fri, 11 Dec 2020 12:30:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_lifecycle_probes/</guid>
      <description>Pod生命周期 Pod的phase是Pod生命周期中的简单宏观描述，定义在Pod的PodStatus对象的phase 字段中。
phase有以下几种值：
   状态值 说明     挂起（Pending） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间。   运行中（Running） 该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。   成功（Succeeded） Pod 中的所有容器都被成功终止，并且不会再重启。   失败（Failed） Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。   未知（Unknown） 因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。    容器状态 容器的状态有三种：Waiting（等待）、Running（运行中）和 Terminated（已终止）。
容器重启策略 Pod 的 spec 中包含一个 restartPolicy 字段，其可能取值包括 Always、OnFailure 和 Never。默认值是 Always。
restartPolicy 适用于 Pod 中的所有容器。restartPolicy 仅针对同一节点上 kubelet 的容器重启动作。当 Pod 中的容器退出时，kubelet 会按指数回退 方式计算重启的延迟（10s、20s、40s、.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (4) 标签、注解与命名空间</title>
      <link>https://www.zengxi.net/2020/12/k8s_label_annotation_namespace/</link>
      <pubDate>Thu, 10 Dec 2020 22:04:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_label_annotation_namespace/</guid>
      <description>标签 什么是标签 标签是可以附加到资源的任意键值对。通过标签选择器，可以筛选出具有该确切标签的资源。
使用标签和选择器来约束pod调度 默认情况下，Pod基本上是随机地调度到任意Node节点的。但是某些情况下，想要调度到特定的Node节点，比如SSD硬盘的节点。这个时候，可以通过节点标签和节点标签选择器完成。
1# 这个例子中通过nodeSelector选择部署到gpu=true的节点2apiVersion:vl3kind:Pod4metadata:5name:kubia-gpu6spec:7nodeSelector:8gpu=true9containers:10- image:luksa/kubia11name:kubia注解 除标签外,pod和其他对象还可以包含注解。注解也是键值对, 但与标签不同, 注解并不是为了保存标识信息而存在的。
使用注解可以为每个pod或其他API对象添加说明,以便每个使用该集群的人都可以快速查找有关每个单独对象的信息。
命名空间 作用 k8s的命名空间简单地为对象名称提供了一个作用域。这样就可以将包含大量组件的复杂系统拆分为更小的不同组，这些不同组也可以用于在多租户环境中分配资源，将资源分配为生产、开发和 QA 环境,或者以其他任何你需要的方式分配资源。资源名称只需在命名空间内保持唯一即可，因此两个不同的命名空间可以包含同名的资源。
创建命名空间及其资源 可以使用yaml文件来创建命名空间
1apiVersion:vl2kind:Namespace3metadata:4name：custom-namespace或者使用命令来创建命名空间
1kubectl create namespace custom-namespace 想要在创建的命名空间中创建资源, 可以选择在 metadata 宇段中添加一个 namespace: custom-namespace 属性,也可以在使用 kubectl create命令创建资源时指定命名空间:
1kubectl create -f kubia-manual.yaml -n custom-namespace 命名空间的切换 如果不指定命名空间, kubectl 将在当前上下文中配置的默认命名空间中执行操作。而当前上下文的命名空间和当前上下文本身都可以通过 kubectl config 命令进行更改。如果想要对其他命名空间中的对象进行操作, 需要给 kubectl 命令传递-- namespace (或 -n) 选项。
要想快速切换到不同的命名空间, 可以设置以下别名，然后,可以使用 kcd some-namespace 在命名空间之间进行切换 。
1alias kcd =’kubectl config set context $(kubectl config current-context) -- namespace’ 命名空间的隔离性 尽管命名空间将对象分隔到不同的组,只允许你对属于特定命名空间的对象进行操作, 但实际上命名空间之间并不提供对正在运行的对象的任何隔离 。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (3) Pod介绍</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_intro/</link>
      <pubDate>Thu, 03 Dec 2020 23:30:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_intro/</guid>
      <description>什么是Pod Pod是k8s的基本构建模块，包含一个或者多个容器。一个Pod中的所有容器都运行在同—个节点上，绝不跨越两个节点
为何需要Pod 多个容器比单个容器中包含多个进程要好 想象一个由多个进程组成的应用程序, 无论是通过ipc (进程间通信)还是本地存储文件进行通信, 都要求它们运行于同一 台机器上。 在k8s中, 我们经常在容器中运行进程, 由于每一个容器都非常像一台独立的机器, 此时你可能认为在单个容器中运行多个进程是合乎逻辑的, 然而在实践中这种做法并不合理。
容器被设计为每个容器只运行一个进程(除非进程本身产生子进程)。如果在单个容器中运行多个不相关的进程, 那么保持所有进程运行、 管理它们的日志等将会是我们的责任。例如, 我们需要包含一种在进程崩溃时能够自动重启的机制。同时这些进程都将记录到相同的标准输出中, 而此时我们将很难确定每个进程分别记录了什么。
综上所述, 我们需要让每个进程运行于自己的容器中, 而这就是Docker和k8s期望使用的方式。
引入Pod 由于不能将多个进程聚集在一个单独的容器中, 我们需要另一种更高级的结构来将容器绑定在一起,并将它们作为一个单元进行管理,这就是 Pod 背后的根本原理。
在包含容器的 Pod 下,我们可以同时运行一些密切相关的进程,并为它们提供几乎相同的环境, 此时这些进程就好像全部运行于单个容器中一样, 同时又保持着一定的隔离。这样一来, 我们便能全面地利用容器所提供的特性, 同时对这些进程来说它们就像运行在一起一 样, 实现两全其美。
Pod的一些特征 同一Pod中容器之间的部分隔离 Pod内部的容器共享部分资源（不是全部），没有完全隔离。这些容器共享相同的 Linux 命名空间, 而不是每个容器都有自己的一组命名空间。比如，它们有相同的 network 和 UTS 命名空间，所以它们都共享相同的主机名和网络接口。
但当涉及文件系统时, 情况就有所不同。 由于大多数容器的文件系统来自容器镜像, 因此默认情况下, 每个容器的文件系统与其他容器完全隔离。但是，可以使用名为 Volume 的 k8s 资源来共享文件目录。
Pod内部容器共享相同的IP和端口空间 由于一个pod中的容器运行于相同的 Network 命名空间中, 因此它们共享相同的 IP 地址和端口空间。这意味着在同一 pod 中的容器运行的多个进程需要注意不能绑定到相同的端口号, 否则会导致端口冲突, 但这只涉及同一pod 中的容器。
由于每个 pod 都有独立的端口空间, 对于不同 pod 中的容器来说则永远不会遇到端口冲突。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (2) k8s集群架构</title>
      <link>https://www.zengxi.net/2020/12/k8s_cluster_structure/</link>
      <pubDate>Thu, 03 Dec 2020 13:45:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_cluster_structure/</guid>
      <description>集群架构 k8s集群由很多节点组成，被分成两种类型：Master节点与Node节点。
Master节点 承载着控制和管理整个集群系统的 Control Panel。包含下面组件：
 API Server  一个api服务器，所有外部与k8s集群的交互都需要经过它 可水平扩展   Scheduler  将pod调度到具体的Node节点上 一个master集群中只会有一个节点处于激活状态，由etcd选举产生   Control Manager  执行集群级别的功能，通过apiserver监控集群状态做出相应的处理，如复制组件、持续跟踪工作节点 、处理节点失败等 一个master集群中只会有一个节点处于激活状态，由etcd选举产生   etcd  一个可靠的分布式数据存储,它能持久化存储集群配置    k8s依赖etcd所以不存在数据一致性的问题（把数据一致性压到了etcd上），所以k8s master不需要采取投票的机制来进行选举，而只需节点健康就可以成为leader。所以这边master并不要求奇数，偶数也是可以的。那么master高可用至少需要2个节点，失败容忍度是(n/0)+1，也就是只要有一个是健康的k8s master集群就属于可用状态。（这边需要注意的是master依赖etcd，如果etcd不可用那么master也将不可用）
etcd的失败容忍度：最小可用节点数：(n/2)+1
Node 节点 无高可用一说。
主要的几个组件：
 Container Runtime  每个节点都需要一个容器运行时来执行容器，比如Docker。非pod启动。   kubelet  用于执行API server下达的命令，也可以重启启动失败的pod。   kube-proxy (Kubernetes Service Proxy)  通过修改iptables来达到网络代理、负载均衡的效果    使用Kubernetes的好处 简化应用程序部署 由于k8s将其所有工作节点公开为一个部署平台, 因此应用程序开发人员可以直接部署应用程序,不需要了解组成集群的服务器。
开发人员通常不关心应用程序运行在哪个服务器上,只要服务器能够为应用程序提供足够的系统资源即可。
有时开发人员需要指定应用程序应该运行在哪种硬件上，比如SSD，那只需要告诉k8s只在具有 SSD 的节点中进行选择即可。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (1) 容器技术介绍</title>
      <link>https://www.zengxi.net/2020/12/k8s_container_tech_intro/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_container_tech_intro/</guid>
      <description>容器允许你在同一台机器上运行多个服务, 不仅提供不同的环境给每个服务, 而且将它们互相隔离。
容器与虚拟机比较 轻量级 和虚拟机比较, 容器更加轻量级, 它允许在相同的硬件上运行更多数量的组件。主要是因为每个虚拟机需要运行自己的一组系统进程, 这就产生了除组件进程消耗以外的额外计算资源损耗。而一个容器仅仅是运行在宿主机上被隔离的单个进程, 仅消耗应用容器消耗的资源, 不会有其他进程的开销。
虚拟化 多个容器则会完全执行运行在宿主机上的同一个内核的系统调用, 此内核是唯一一个在宿主机操作系统上执行指令的内核。 CPU也不需要做任何对虚拟机能做那样的虚拟化。
隔离性 虚拟机的主要好处是它们提供完全隔离的环境, 因为每个虚拟机运行在它自己的Linux内核上, 而容器都是调用同一个内核, 这会有一定的安全隐患
容器实现隔离机制介绍 用 Linux 命名空间隔离进程 默认情况下, 每个 Linux 系统最初仅有一个命名空间。可以创建额外的命名空间, 以及在它们之间组织资源。
对于一个进程, 可以在其中一个命名空间中运行它。进程将只能看到同一个命名空间下的资源。 存在多种类型的多个命名空间, 所以一个进程不单单只属于某一个命名空间, 而属于每个类型的一个命名空间。存在以下类型的命名空间:
 Mount (mnt) Process ID (pid) Network (net) Inter-process communicaion (ipd) UTS (UNIX Time-Sharing) User ID (user)  每种命名空间被用来隔离一组特定的资源。例如, UTS 命名空间决定了运行在命名空间里的进程能看见哪些主机名和域名。通过分派两个不同的 UTS 命名空间给一对进程, 能使它们看见不同的本地主机名。换句话说, 这两个进程就好像正在两个不同的机器上运行一样(至少就主机名而言是这样的)。同样地, 一个进程属于什么 Network 命名空间决定了运行在进程里的应用程序能看见什么网络接口。每个网络接口属于一个命名空间, 但是可以从一个命名空间转移到另一个。 每个容器都使用它自己的网络命名空间, 因此每个容器仅能看见它自己的一组网络接口。
限制进程的可用资源 另外的隔离性就是限制容器能使用的系统资源。 这通过cgroups来实现。cgroups 是一个Linux 内核功能, 它被用来限制 一个进程或者一组进程的资源使用。一个进程的资源(CPU、 内存、 网络带宽等)使用量不能超出被分配的量。 这种方式下, 进程不能过分使用为其他进程保留的资源, 这和进程运行在不同的机器上是类似的。</description>
    </item>
    
  </channel>
</rss>

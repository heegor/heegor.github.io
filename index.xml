<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>保罗札记</title>
    <link>https://www.zengxi.net/</link>
    <description>Recent content on 保罗札记</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Tue, 01 Jun 2021 22:09:00 +0800</lastBuildDate><atom:link href="https://www.zengxi.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Java 8新特性 - (10)并行数组排序</title>
      <link>https://www.zengxi.net/2021/06/java8_parallel_sort/</link>
      <pubDate>Tue, 01 Jun 2021 22:09:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/06/java8_parallel_sort/</guid>
      <description>在Java 7中已经有了Arrays.sort()方法可对对象进行排序，而在Java 8中，引入了新的并行排序，它比前者的排序速度更快，且遵循了Java 7引入的Fork/Join框架，可以把排序任务分配给线程池中可用的多个线程。 Java 8在java.util.Arrays类中新增了并行排序功能，能够更充分地利用多线程机制，最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序
并行排序算法：
 将给定的数组划分为子数组，将子数组进一步划分为子数组，直到子数组达到最小粒度为止。 子数组由多个线程单独排序。并行排序使用 Fork / Join Framework 并行地对子数组进行排序。 已合并的已排序子数组。  1// 对原始数据类型进行并行排序 2// 输出：1 5 19 22 32 89 3int numbers[] = {22, 89, 1, 32, 19, 5}; 4Arrays.parallelSort(numbers); 5 6// 通过指定开始和结束索引进行并行排序。 7// 在这种情况下，从开始索引开始并在结束索引结束的子数组被排序，数组的其余部分被忽略并且不被排序。 8// 输出：22 1 19 32 89 5 9int numbers[] = {22, 89, 1, 32, 19, 5}; 10Arrays.parallelSort(numbers, 1, 5);  参考：
 https://www.jianshu.com/p/2f038115de06 https://www.yuque.com/apachecn/beginnersbook-zh/docs_java_69  </description>
    </item>
    
    <item>
      <title>Java 8新特性 - (9)DateTime API</title>
      <link>https://www.zengxi.net/2021/06/java8_datetime_api/</link>
      <pubDate>Tue, 01 Jun 2021 14:15:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/06/java8_datetime_api/</guid>
      <description>相关背景 Java对日期、日历及时间的处理一直以来都饱受诟病：
 java.util.Date和java.util.Calendar类易用性差，不支持时区，非线程安全 用于格式化日期的类DateFormat被放在java.text包中，它是一个抽象类，所以我们需要实例化一个SimpleDateFormat对象来处理日期格式化，并且DateFormat也是非线程安全，这意味着如果你在多线程程序中调用同一个DateFormat对象，会得到意想不到的结果。 对日期的计算方式繁琐，而且容易出错，因为月份是从0开始的，从Calendar中获取的月份需要加一才能表示当前月份。  由于以上这些问题，出现了一些三方的日期处理框架，例如Joda-Time，date4j等开源项目。但是，Java需要一套标准的用于处理时间和日期的框架，于是Java 8中引入了新的日期API。新的日期API是JSR-310规范的实现，Joda-Time框架的作者正是JSR-310的规范的倡导者，所以能从Java 8的日期API中看到很多Joda-Time的特性。
简介 新的API对时间日期的处理提供了更好的支持，清楚的定义了时间日期的一些概念，比如说，瞬时时间（Instant）,持续时间（duration），日期（date）,时间（time），时区（time-zone）以及时间段（Period）。
新的时间日期API核心位于java.time内，另外也在java.time.chrono，java.time.format，java.time.temporal和java.time.zone有相关的API，但使用频次较少。时间与日期API中的所有类都是线程安全的。
Java 8常用的日期和时间类主要包括包含：
 LocalDate：不包含时间的日期，比如2019-10-14。可以用来存储生日，周年纪念日，入职日期等。 LocalTime：与LocalDate想对照，它是不包含日期的时间。 LocalDateTime：包含了日期及时间，没有偏移信息（时区）。 ZonedDateTime：包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。 Instant：时间戳，与System.currentTimeMillis()类似。 Duration：表示一个时间段。 Period：用来表示以年月日来衡量一个时间段。  LocalDate LocalDate类内只包含日期，不包含具体时间。只需要表示日期而不包含时间，就可以使用它。
1// 只获取日期 2LocalDate today = LocalDate.now(); 3System.out.println(today); 4 5int year = today.getYear(); 6int month = today.getMonthValue(); 7int day = today.getDayOfMonth(); 8 9System.out.printf(&amp;#34;Year : %d Month : %d day : %d \t %n&amp;#34;, year, month, day); 同时，还可以通过LocalDate获取日期是月份的第几天、周的第几天，月份的天数，是否为闰年等。看下面的代码是不是非常方便。
1LocalDate today = LocalDate.now(); 2// 月份中的第几天 3int dayOfMonth = today.</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (8)方法参数反射</title>
      <link>https://www.zengxi.net/2021/05/java8_method_parameter_reflection/</link>
      <pubDate>Fri, 28 May 2021 18:45:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/05/java8_method_parameter_reflection/</guid>
      <description>方法的参数名，在很多时候我们是需要反射得到的。但是在java8之前，代码编译为class文件后，方法参数的类型是固定的，但参数名称却丢失了，这和动态语言严重依赖参数名称形成了鲜明对比。（java是静态语言，所以入参名称叫什么其实无所谓的）。虽然名称无所谓，但很多时候，我们需要此名称来做更好的安排.
比如mybatis的Dao层接口方法，需要特意用个注解@Param来显示标识出参数名。所以java8来了，带来的新特性解决了这一问题。
获取方法参数名称有3种方法：
采用javassit包获取 很麻烦，参考其他网上文章
通过spring的LocalVariableTableParameterNameDiscoverer 1public static void main(String[] args) { 2 List&amp;lt;String&amp;gt; paramterNames = getParamterName(StaffMark.class, &amp;#34;fun1&amp;#34;); 3 paramterNames.forEach((x) -&amp;gt; System.out.println(x)); 4} 5 6public static void fun1(String aaa, Integer bbb) { 7 8} 9 10public static List&amp;lt;String&amp;gt; getParamterName(Class clazz, String methodName) { 11 LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); 12 Method[] methods = clazz.getDeclaredMethods(); 13 for (Method method : methods) { 14 if (methodName.equals(method.getName())) { 15 //获取到该方法的参数们 16 String[] params = u.</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (7)泛型的类型推断</title>
      <link>https://www.zengxi.net/2021/05/java8_type_inference/</link>
      <pubDate>Fri, 28 May 2021 18:05:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/05/java8_type_inference/</guid>
      <description>泛型简介 泛型由Java 1.5引入，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。通俗点将就是“类型的变量”。这种类型变量可以用在类、接口和方法的创建中。理解Java泛型最简单的方法是把它看成一种便捷语法，能节省某些Java类型转换(casting)上的操作.
泛型的最大优点是提供了程序的类型安全同时可以向后兼容，但也有尴尬的地方，就是每次定义时都要写明泛型的类型，这样显示指定不仅感觉有些冗长。Java 7中对泛型做了改进，编译器会根据变量声明时的泛型类型自动推断.
1// Java 7之前的写法 2Map&amp;lt;String, String&amp;gt; myMap = new HashMap&amp;lt;String, String&amp;gt;(); 3 4// Java 7及之后的写法 5Map&amp;lt;String, String&amp;gt; myMap = new HashMap&amp;lt;&amp;gt;(); //注意后面的&amp;#34;&amp;lt;&amp;gt;&amp;#34; 但是，Java 7在创建泛型实例时的类型推断是有限制的：只有构造器的参数化类型在上下文中被显著的声明了，才可以使用类型推断，否则不行。例如：下面的例子在java 7无法正确编译（但在java8里面可以编译，因为根据方法参数来自动推断泛型的类型）：
1List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); 2list.add(&amp;#34;A&amp;#34;); 3// 由于addAll期望获得Collection&amp;lt;? extends String&amp;gt;类型的参数，因此下面的语句在Java 7中无法编译无法通过 4list.addAll(new ArrayList&amp;lt;&amp;gt;()); Java 8的泛型类型推断改进 java 8里面泛型的目标类型推断主要2个：
 支持通过方法上下文推断泛型目标类型 支持在方法调用链路当中，泛型类型推断传递到最后一个方法  看看官网的例子：
1class List&amp;lt;E&amp;gt; { 2 static &amp;lt;Z&amp;gt; List&amp;lt;Z&amp;gt; nil() { ... }; 3 static &amp;lt;Z&amp;gt; List&amp;lt;Z&amp;gt; cons(Z head, List&amp;lt;Z&amp;gt; tail) { .</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (6)类型注解</title>
      <link>https://www.zengxi.net/2021/05/java8_type_annotation/</link>
      <pubDate>Fri, 28 May 2021 12:48:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/05/java8_type_annotation/</guid>
      <description>什么是类型注解 在java 8之前，注解只能是在声明的地方所使用，比如类，方法，属性；从java 8开始，注解可以应用在任何地方。但是需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。换句话说，仅提供定义这些类型的注释的功能，然后由框架和工具开发者来实际上使用它们。
主要的场景：
 创建类实例：  1new @Interned MyObject(); 类型定义：  1@NotNull String str1 = ... 2@Email String str2 = ... 类型转换：  1myString = (@NonNull String) str; 泛型  1List&amp;lt;@Email String&amp;gt; emails = ... 包括参数边界和通配符边界  1class Folder&amp;lt;F extends @Existing File&amp;gt; { ... } 2Collection&amp;lt;? super @Existing File&amp;gt; c = ... 3List&amp;lt;@Immutable ? extends Comparable&amp;lt;T&amp;gt;&amp;gt; unchangeable = ... instanceof 语句  1boolean isNonNull = myString instanceof @NonNull String; 2boolean isNonBlankEmail = myString instanceof @NotBlank @Email String; 继承  1class UnmodifiableList&amp;lt;T&amp;gt; implements @Readonly List&amp;lt;@Readonly T&amp;gt; { .</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (5)重复注解</title>
      <link>https://www.zengxi.net/2021/05/java8_repeating_annotations/</link>
      <pubDate>Thu, 27 May 2021 10:30:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/05/java8_repeating_annotations/</guid>
      <description>在JDK8之前，不能使用重复注解的，即某个位置相同注解只能出现一次。
如果想编写一个定时任务的注解，使用者可以配置在每天哪一小时触发，而且允许用户配置多个时间。传统做法是：
1@Target(ElementType.TYPE) 2@Retention(RetentionPolicy.RUNTIME) 3public @interface TraditionalAnnoSchedule { 4 int[] hour() default {0}; 5} 6 7@TraditionalAnnoSchedule(hour = {0, 8, 12}) 8public class Target { 9 public static void main(String[] args) { 10 TraditionalAnnoSchedule[] annotations = Target.class.getAnnotationsByType(TraditionalAnnoSchedule.class); 11 for (TraditionalAnnoSchedule each : annotations) { 12 System.out.println(Arrays.toString(each.hour())); 13 } 14 } 15} 使用JDK8的重复注解特性改造一下。
1@Target(ElementType.TYPE) 2@Retention(RetentionPolicy.RUNTIME) 3public @interface Schedules { 4 Schedule[] value(); 5} 6 7// JDK8新增的@Repeatable 8@Repeatable(Schedules.class) 9public @interface Schedule { 10 int hour() default 0; 11} 12 13@Schedule(hour = 0) 14@Schedule(hour = 8) 15@Schedule(hour = 12) 16public class Target { 17 public static void main(String[] args) { 18 // 推荐的方式 19 Schedule[] annotations = Target.</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (4)默认方法</title>
      <link>https://www.zengxi.net/2021/05/java8_default_method/</link>
      <pubDate>Wed, 26 May 2021 22:40:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/05/java8_default_method/</guid>
      <description>什么是默认方法 简单说，就是接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字即可。
为什么要有默认方法 首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。
简单的例子: 一个接口A，Clazz类实现了接口A。
1public interface A { 2 default void foo(){ 3 System.out.println(&amp;#34;Calling A.foo()&amp;#34;); 4 } 5} 6 7public class Clazz implements A { 8 public static void main(String[] args){ 9 Clazz clazz = new Clazz(); 10 clazz.foo();//调用A.foo() 11 } 12} 代码是可以编译的，即使Clazz类并没有实现foo()方法。在接口A中提供了foo()方法的默认实现。
java 8抽象类与接口对比 相同点  都是抽象类型； 都可以有实现方法（以前接口不行）； 都可以不需要实现类或者继承者去实现所有方法，（以前不行，现在接口中默认方法不需要实现者实现）  不同点  抽象类不可以多重继承，接口可以（无论是多重类型继承还是多重行为继承）； 抽象类和接口所反映出的设计理念不同。其实抽象类表示的是&amp;quot;is-a&amp;quot;关系，接口表示的是&amp;quot;like-a&amp;quot;关系； 接口中定义的变量默认是public static final 型，且必须给其初值，所以实现类中不能改变其值；抽象类中的变量默认是 friendly 型，其值可以在子类中重新定义，也可以重新赋值。  多重继承的冲突 观察以下代码，会出现编译错误：
 java: class InterfaceC inherits unrelated defaults for f() from types InterfaceA and InterfaceB</description>
    </item>
    
    <item>
      <title>Java各版本特性</title>
      <link>https://www.zengxi.net/links/java_feature/</link>
      <pubDate>Tue, 25 May 2021 15:00:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/links/java_feature/</guid>
      <description>Java 7 Java语法特性:
 二进制前缀0b或者0B。整型（byte, short, int, long）可以直接用二进制表示 字面常量数字的下划线。用下划线连接整数提升其可读性，自身无含义，不可用在数字的起始和末尾。 switch 支持String类型。 泛型实例化类型自动推断。 try-with-resources语句。 单个catch中捕获多个异常类型（用| 分割）并通过改进的类型检查重新抛出异常。  Java 8  Lamda表达式(Lambda Expressions)。 方法引用（Method references）。方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与Lambda联合使用，可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法（Default methods）。默认方法允许将新功能添加到库的接口中，并确保兼容实现老版本接口的旧有代码。 重复注解（Repeating Annotations）。重复注解提供了在同一声明或类型中多次应用相同注解类型的能力。 类型注解（Type Annotation）。在任何地方都能使用注解，而不仅仅在声明的地方。 类型推断增强。 方法参数反射（Method Parameter Reflection）。 Stream API 。新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。Stream API集成到了Collections API里。 HashMap改进，在键值哈希冲突时能有更好表现。 Date Time API。加强对日期和时间的处理。 java.util 包下的改进，提供了几个实用的工具类：   并行数组排序。 标准的Base64编解码。 支持无符号运算。  java.util.concurrent 包下增加了新的类和方法。   java.util.concurrent.ConcurrentHashMap 类添加了新的方法以支持新的StreamApi和lambada表达式。 java.util.concurrent.atomic 包下新增了类以支持可伸缩可更新的变量。 java.util.concurrent.ForkJoinPool类新增了方法以支持 common pool。  新增了java.util.concurrent.locks.StampedLock类，为控制读/写访问提供了一个基于性能的锁，且有三种模式可供选择。 HotSpot   删除了永久代（PermGen）. 方法调用的字节码指令支持默认方法。   参考：</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (3)方法引用</title>
      <link>https://www.zengxi.net/2021/04/java8_method_references/</link>
      <pubDate>Wed, 07 Apr 2021 13:01:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/04/java8_method_references/</guid>
      <description>方法引用（Method references）。方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，可以使语言的构造更紧凑简洁，减少冗余代码。
方法引用使用到的操作符“::”，这个操作符把方法引用分成两边，左边是类名或者某个对象的引用，右边是方法名。引用方法有下面几种方式：
 对象引用::实例方法名 类名::静态方法名 类名::实例方法名 类名::new 类型[]::new  对象引用::实例方法名 创建了一个PersonCompare对象，调用了其内部的compareByName实例方法。
1public class PersonCompare { 2 public int compareByName(Person a, Person b) { 3 return a.getName().compareTo(b.getName()); 4 } 5 public int compareByAge(Person a, Person b) { 6 return a.getBirthday().compareTo(b.getBirthday()); 7 } 8 @Test 9 public void test(){ 10 Person[] pArr = new Person[]{ 11 new Person(&amp;#34;1&amp;#34;, LocalDate.of(2019, 12, 1)), 12 new Person(&amp;#34;2&amp;#34;, LocalDate.of(2019, 12, 2)), 13 new Person(&amp;#34;3&amp;#34;, LocalDate.</description>
    </item>
    
    <item>
      <title>在Fiddler中使用脚本来修改Response数据</title>
      <link>https://www.zengxi.net/2021/03/update_response_via_fiddler/</link>
      <pubDate>Tue, 30 Mar 2021 12:47:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/update_response_via_fiddler/</guid>
      <description>使用Fiddler抓包工具，通过修改CustomRules.js脚本达到修改Http请求的Response中Body信息（如JSON串）。
常用于在Server开发未完全Ready而前端或客户端开发需要Server数据时，修改请求的返回数据，达到Debug和测试的目的，较添加BreakPoint的方法更加便捷。
本例Demo中会为JSON添加一个字段和修改一个字段，如下所示：
1// 原JSON串 V1.0 2{ 3 &amp;#34;music&amp;#34;: &amp;#34;big big world&amp;#34;, 4 &amp;#34;singer&amp;#34;: &amp;#34;Emilia Rydberg&amp;#34; 5} 6 7// 新JSON串 V1.1 8{ 9 &amp;#34;music&amp;#34;: &amp;#34;big big world&amp;#34;, 10 &amp;#34;singer&amp;#34;: &amp;#34;艾密莉亚·怀得堡&amp;#34;, // 修改该字段(英文名改为中文名显示) 11 &amp;#34;similar song&amp;#34;: [ // 添加该字段(相似歌曲列表) 12 { 13 &amp;#34;music&amp;#34;: &amp;#34;dying in the sun&amp;#34;, 14 &amp;#34;singer&amp;#34;: &amp;#34;The Cranberries&amp;#34; 15 }, 16 { 17 &amp;#34;music&amp;#34;: &amp;#34;seasons in sun&amp;#34;, 18 &amp;#34;singer&amp;#34;: &amp;#34;WestLife&amp;#34; 19 } 20 ] 21} 基本流程 基本步骤（简单） 打开并编辑Customize Rule文件，在方法 OnBeforeResponse 中插入修改代码，重启Fiddler重新加载Rule，运行。</description>
    </item>
    
    <item>
      <title>CXF记录WebService的soap日志</title>
      <link>https://www.zengxi.net/2021/03/cxf_ws_log/</link>
      <pubDate>Mon, 29 Mar 2021 11:55:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/cxf_ws_log/</guid>
      <description>cxf本身就支持日志功能，能打印传入传出的soap报文，但是需要配置一下。
这里配置的是cxf结合spring做的WebService，配置步骤如下：
 在spring配置文件中的jaxws:endpoint节点下配置日志拦截器  1&amp;lt;import resource=&amp;#34;classpath:META-INF/cxf/cxf.xml&amp;#34; /&amp;gt; 2&amp;lt;import resource=&amp;#34;classpath:META-INF/cxf/cxf-extension-soap.xml&amp;#34; /&amp;gt; 3&amp;lt;import resource=&amp;#34;classpath:META-INF/cxf/cxf-servlet.xml&amp;#34; /&amp;gt; 4 5&amp;lt;!-- 配置的cxf web service的地址 --&amp;gt; 6&amp;lt;jaxws:endpoint id=&amp;#34;searchReq11&amp;#34; implementor=&amp;#34;com.iflytek.server.HelloImpl&amp;#34; 7 address=&amp;#34;/SearchReqService.asmx&amp;#34;&amp;gt; 8 &amp;lt;jaxws:inInterceptors&amp;gt; 9 &amp;lt;bean class=&amp;#34;org.apache.cxf.interceptor.LoggingInInterceptor&amp;#34; /&amp;gt; 10 &amp;lt;/jaxws:inInterceptors&amp;gt; 11 &amp;lt;jaxws:outInterceptors&amp;gt; 12 &amp;lt;bean class=&amp;#34;org.apache.cxf.interceptor.LoggingOutInterceptor&amp;#34; /&amp;gt; 13 &amp;lt;/jaxws:outInterceptors&amp;gt; 14&amp;lt;/jaxws:endpoint&amp;gt; 具体的日志输出目录（3种方式）。需要注意,下面的3种方式优先级从低到高：   什么也不配置，使用java原生的java.util.logging.Logger记录日志。日志文件为Tomcat的logs/catalina.xxxx-xx-xx.log 配置使用slf4j+log4j。cxf默认为使用slf4j记录日志。所以在项目中引入slf4j的jar包即可。如果同时引入log4j则使用log4j记录日志，如果同时引入jcl则使用jcl记录日志。 直接使用log4j记录日志。在项目的类加载路径下创建目录META-INF/cxf/，然后在目录下新建文件“org.apache.cxf.Logger”，在文件中写入：org.apache.cxf.common.logging.Log4jLogger即可。特别要注意，(1)上述目录要放在classes目录下；(2)要引入log4j的jar包。   参考：
 http://ajita.iteye.com/blog/1745845  </description>
    </item>
    
    <item>
      <title>设置周日为一个星期的第一天</title>
      <link>https://www.zengxi.net/2021/03/linux_set_sunday_as_first_day_of_week/</link>
      <pubDate>Mon, 29 Mar 2021 11:49:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/linux_set_sunday_as_first_day_of_week/</guid>
      <description>用 “locale”命令检查当前的区域，例如我的机器运行结果是：
1ls@ls-laptop:~$ locale 2 3LANG=zh_CN.UTF-8 4LANGUAGE=zh_CN.UTF-8 5LC_CTYPE=&amp;#34;zh_CN.UTF-8&amp;#34; 6LC_NUMERIC=&amp;#34;zh_CN.UTF-8&amp;#34; 7LC_TIME=&amp;#34;zh_CN.UTF-8&amp;#34; 8LC_COLLATE=&amp;#34;zh_CN.UTF-8&amp;#34; 9LC_MONETARY=&amp;#34;zh_CN.UTF-8&amp;#34; 10LC_MESSAGES=&amp;#34;zh_CN.UTF-8&amp;#34; 11LC_PAPER=&amp;#34;zh_CN.UTF-8&amp;#34; 12LC_NAME=&amp;#34;zh_CN.UTF-8&amp;#34; 13LC_ADDRESS=&amp;#34;zh_CN.UTF-8&amp;#34; 14LC_TELEPHONE=&amp;#34;zh_CN.UTF-8&amp;#34; 15LC_MEASUREMENT=&amp;#34;zh_CN.UTF-8&amp;#34; 16LC_IDENTIFICATION=&amp;#34;zh_CN.UTF-8&amp;#34; 17LC_ALL= 执行下面命令
1sudo gedit /usr/share/i18n/locales/zh_CN 找到 “first_weekday 2” 这一行，将2改成1，周日就是每周的第一天了
执行下面的命令重新生成 locale 信息
1sudo locale-gen 重新启动
 参考原文：
 http://ubuntuforums.org/archive/index.php/t-26409.html  </description>
    </item>
    
    <item>
      <title>删除Jetty中session ID的node名称</title>
      <link>https://www.zengxi.net/2021/03/jetty_session_remove_node_name/</link>
      <pubDate>Mon, 29 Mar 2021 11:47:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/jetty_session_remove_node_name/</guid>
      <description>jetty 9.4 版本对session id的生成做了升级. 他会自动在session id后面加个节点的名字(workName配置项). jetty 9.3 以及之前的版本没有这个问题.
可以通过修改配置文件来去除session id后缀:
1# 执行下面命令来启用sessions模块，这样就会在start.d目录下面自动生成sessions.ini配置文件 2java -jar &amp;#34;/usr/local/jetty/start.jar&amp;#34; --add-to-startd=sessions 3 4# 修改sessions.ini配置，把下面配置项的值为空 5jetty.sessionIdManager.workerName= </description>
    </item>
    
    <item>
      <title>配置Nginx支持长轮询</title>
      <link>https://www.zengxi.net/2021/03/nginx_cfg_for_long_polling/</link>
      <pubDate>Thu, 25 Mar 2021 13:20:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/nginx_cfg_for_long_polling/</guid>
      <description>某些web应用需要使用到长轮询，在Nginx中需要添加配置来支持。比如说vaadin界面，如果没有做一些额外的配置，使用nginx做反向代理，会出现页面一直在加载的问题
首先需要在http中添加map块
1map $http_upgrade $connection_upgrade { 2 default Upgrade; 3 &amp;#39;&amp;#39; close; 4} 然后在location中添加下面的配置，使用刚才定义的内容
1location /chat { 2 proxy_pass https://192.168.67.100:8443/chatapi; 3 proxy_http_version 1.1; 4 proxy_set_header Upgrade $http_upgrade; 5 proxy_set_header Connection $connection_upgrade; 6 proxy_buffering off; 7 proxy_ignore_client_abort off; 8 break; 9} </description>
    </item>
    
    <item>
      <title>基于alpine构建docker镜像修改时区</title>
      <link>https://www.zengxi.net/2021/03/update_docker_image_timezone/</link>
      <pubDate>Thu, 25 Mar 2021 13:18:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/update_docker_image_timezone/</guid>
      <description>默认apline镜像没有安装时区, 即使把宿主机的/etc/localtime 挂在到镜像中也无法把时区改成 GMT+8的.
这个就只能在构建镜像的时候,安装并设置一下时区
1RUN apk add tzdata \ 2&amp;amp;&amp;amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ 3&amp;amp;&amp;amp; echo &amp;#34;Asia/Shanghai&amp;#34; &amp;gt; /etc/timezone </description>
    </item>
    
    <item>
      <title>Manjaro升级后打印服务不可用</title>
      <link>https://www.zengxi.net/2021/03/manjaro_printer_service_not_available/</link>
      <pubDate>Tue, 16 Mar 2021 09:40:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/manjaro_printer_service_not_available/</guid>
      <description>Manjaro升级到某个版本后，在系统设置中，查看打印机，显示“打印机服务不可用，错误的文件描述符“。
其中一个原因是CUPS（Common UNIX Printing System）打印管理服务未启动。可以用下面的方法来解决：
1# 启动服务，保证本次登录打印机可用 2sudo systemctl start cups.service 3 4# 设置开启启动 5sudo systemctl enable cups.service </description>
    </item>
    
    <item>
      <title>Java 8新特性 - (2)Stream API</title>
      <link>https://www.zengxi.net/2021/03/java8_stream_api/</link>
      <pubDate>Fri, 05 Mar 2021 12:56:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/03/java8_stream_api/</guid>
      <description>什么是Stream API Stream API让开发者能够以一种声明的方式处理数据源（集合、数组等），它专注于对数据源进行各种高效的聚合操作（aggregate operation）和大批量数据操作 (bulk data operation)。
Stream API将处理的数据源看做一种Stream（流），Stream（流）在Pipeline（管道）中传输和运算，支持的运算包含筛选、排序、聚合等，当到达终点后便得到最终的处理结果。如果说集合讲的的数据，那么流讲的就是计算！
几个关键概念：
 元素: Stream是一个来自数据源的元素队列，Stream本身并不存储元素。 数据源: 即Stream的来源, 包含集合、数组、I/O channel、generator（发生器）等。 聚合操作: 类似SQL中的filter、map、find、match、sorted等操作 管道运算: Stream在Pipeline中运算后返回Stream对象本身，这样多个操作串联成一个Pipeline，并形成fluent风格的代码。这种方式可以优化操作，如延迟执行(laziness)和短路( short-circuiting)。 内部迭代: 不同于java 8以前对集合的遍历方式（外部迭代），Stream API采用访问者模式（Visitor）实现了内部迭代。 并行运算: Stream API支持串行（stream()）或并行（parallelStream()）的两种操作方式。  特点：
 Stream API的使用和同样是java8新特性的lambda表达式密不可分，可以大大提高编码效率和代码可读性。 Stream API提供串行和并行两种操作，其中并行操作能发挥多核处理器的优势，使用fork/join的方式进行并行操作以提高运行速度。 Stream API进行并行操作无需编写多线程代码即可写出高效的并发程序，且通常可避免多线程代码出错的问题。  注意：
 Stream 自己不会存储元素。 Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。 Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。  Stream操作的三个步骤  创建Stream：一个数据源（如： 集合、数组）， 获取一个流。 中间操作:一个中间操作链，对数据源的数据进行处理。 终止操作(终端操作):一个终止操作，执行中间操作链，并产生结果。  创建Stream (1) 获取Stream Java 8中Collection接口被扩展，提供两种获取流的方法:
 stream() 返回一个顺序流 parallelStream()返回一个并行流  1default Stream stream() // 返回一个顺序流 2 3default Stream parallelStream() // 返回一个并行流 1List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); 2 3// 顺序流 4Stream&amp;lt;String&amp;gt; stream1 = list.</description>
    </item>
    
    <item>
      <title>Java 8新特性 - (1)Lambda表达式</title>
      <link>https://www.zengxi.net/2021/02/java8_lambda/</link>
      <pubDate>Thu, 25 Feb 2021 13:15:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/02/java8_lambda/</guid>
      <description>为什么Java需要Lambda表达式? 在函数式编程语言中，函数是一等公民，它们可以独立存在，你可以将其赋值给一个变量，或将他们当做参数传给其他函数。JavaScript是最典型的函数式编程语言。函数式语言提供了一种强大的功能——闭包，相比于传统的编程方法有很多优势，闭包是一个可调用的对象，它记录了一些信息，这些信息来自于创建它的作用域。
Java现在提供的最接近闭包的概念便是Lambda表达式，虽然闭包与Lambda表达式之间存在显著差别，但至少Lambda表达式是闭包很好的替代者。
Lambda表达式为Java添加了缺失的函数式编程特点，它与闭包不同，但是又无限地接近闭包。在支持一类函数的语言中，Lambda 表达式的类型将是函数。但是，在Java中，Lambda表达式是对象，他们必须依附于一类特别的对象类型——函数式接口(functional interface)。
语法 Java中的Lambda表达式通常使用 (argument) -&amp;gt; (body) 语法书写，例如：
1(arg1, arg2...) -&amp;gt; { body } 2 3(type1 arg1, type2 arg2...) -&amp;gt; { body } 下面是一些例子:
1(int a, int b) -&amp;gt; { return a + b; } 2 3() -&amp;gt; System.out.println(&amp;#34;Hello World&amp;#34;); 4 5(String s) -&amp;gt; { System.out.println(s); } 6 7() -&amp;gt; 42 8 9() -&amp;gt; { return 3.1415 }; Lambda表达式的结构:
 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断。例如：(int a)与(a)效果相同 所有参数需包含在圆括号内，参数之间用逗号相隔。例如：(a, b) 或 (int a, int b) 或 (String a, int b, float c) 空圆括号代表参数集为空。例如：() -&amp;gt; 42 当只有一个参数，且其类型可推导时，圆括号（）可省略。例如：a -&amp;gt; return a*a Lambda 表达式的主体可包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号{}可省略。匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，则表达式必须包含在花括号{}中（形成代码块）。匿名函数的返回类型与代码块的返回类型一致，若没有返回则为空  函数式接口 在Java中，Marker（标记）类型的接口是一种没有方法或属性声明的接口，也就是空接口。相似地，函数式接口是只包含一个抽象方法声明的接口。比如java.</description>
    </item>
    
    <item>
      <title>Java 7新特性 - (1)Java语法特性</title>
      <link>https://www.zengxi.net/2021/02/java7_gramma_new_features/</link>
      <pubDate>Wed, 24 Feb 2021 13:33:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/02/java7_gramma_new_features/</guid>
      <description>二进制数字表达方式 在Java 7之前，支持十进制（123）、八进制（0123）、十六进制（0X12AB）的表示形式。Java 7中增加支持二进制的表示（0B11110001、0b11110001）
1int binary = 0b0001_1001; 2System.out.println(&amp;#34;binary is :&amp;#34; + binary); 输出
1binary is :25 使用下划线对数字进行分隔表达 Java 7中支持在数字中间增加&#39;_&#39;作为分隔符，分隔长int以及long（也支持double,float），显示更直观，如（12_123_456）。
下划线只能在数字中间，编译时编译器自动删除数字中的下划线。
1int intOne = 1_000_000; 2long longOne = 1_000_000; 3double doubleOne = 1_000_000; 4float floatOne = 1_000_000; switch 语句支持字符串变量 之前在switch中只能使用number或enum，Java 7开始支持string。
1String s = &amp;#34;a&amp;#34;; 2switch (s) { 3 case &amp;#34;a&amp;#34;: 4 System.out.println(&amp;#34;is a&amp;#34;); 5 break; 6 case &amp;#34;b&amp;#34;: 7 System.out.println(&amp;#34;is b&amp;#34;); 8 break; 9 default: 10 System.out.println(&amp;#34;is c&amp;#34;); 11 break; 12} 泛型实例创建的类型推断 运用泛型实例化类型自动推断，对通用实例创建(diamond)的type引用进行了改进，语法更加简洁</description>
    </item>
    
    <item>
      <title>订单ES查询性能优化</title>
      <link>https://www.zengxi.net/2021/02/es_search_improvement/</link>
      <pubDate>Sat, 20 Feb 2021 13:12:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/02/es_search_improvement/</guid>
      <description>背景 由于系统中的订单量大，一些查询语句需要级联多张表来查询，单纯靠数据库的索引已经无法满足查询速度与用户界面响应速度的要求，因此在5年前引入了ES来加快查询速度。但是，原先的方案中ES存放的是全量的订单数据，并且是存放在同一个数据库索引中，随着业务的发展与订单量的累积，ES查询的速度已经越来越慢。通过Grafana监控数据，可以看到单个索引的数据量已达到1.5TB，主要的性能指标越来越差。ES的CPU使用率不时地大于80%，甚至100%，导致极端情况下ES查询耗时十几秒。对于用户的直观感受就是，在界面上面查询数据，需要耗时很久才能看到数据。
解决方案 系统总是慢慢演变的，某个时间点的解决方案都是基于当前的一些情况，满足近3年内的需求就足够了。考虑到成本问题，尽可能在不增加硬件投入的情况下，找到节省时间的优化方案。
在原先的方案中，索引中有1.5TB的数据量。从1.5TB的数据集里面查找数据，会很耗时间。由于系统中大部分的操作都是根据公司来区分的，所以如果把ES里面的数据，按照公司来拆分成不同的索引，某个公司查询订单的时候，仅仅查询它自己公司的索引。拆分成若干个索引之后，最大的一个索引不到3GB，小的一些索引就100多MB。由于单个公司索引的数据量很小，查询速度自然就比原先快了。
系统中也存在一些查询，需要跨公司来查数据，但是这些查询有个特点，它们仅仅需要查最近一定时间范围内的数据，比如半年之内。对于这些数据，可以再专门建一个ES索引来存放，同时有个后台的Job，定期删除过期的数据。这样，就可以控制该索引的总数据量在一定的范围之内，不会因为数据量多大的原因导致查询变慢。
当然，在写代码实现的时候还需要考虑很多具体的问题，比如：
 修改原先ES数据实时同步方案，支持根据公司ID写入到不同的索引 修改原先ES数据全量加载方案，支持根据公司ID写入到不同的索引 修改原先ES数据查询方案，支持根据公司ID从不同的索引读取数据 修改ES查询相关设置参数的实现逻辑，比如某个公司是否开启ES，开启ES的走ES查询，不开启ES的走数据库查询。 需要考虑到将来的扩展性，如何更合理的接口 原先的java ES库的某些操作不支持显式指定index名称，需要继承该库中的一些类并重写方法 在过渡阶段，让系统支持新旧两种的查询方式，不需要重启服务，仅通过修改配置就可以实现无缝切换。这样的话，如果由于新方案中，代码有bug，可以直接通过修改配置切换到旧的方式，bug修复后再切换成新的。等到新方案的上线一定的时间，稳定之后，再移除旧方案的代码  优化前后的性能对比 通过Grafana的监控数据，可以很明显地看出优化的效果。
切换新旧方案的瞬间 切换新旧方案的瞬间，可以看到查询耗时断崖式减少
平峰时期CPU使用率对比 优化前平均40%左右
优化后平均5%
高峰时期CPU使用率对比 优化前平均82%，最高98%
优化后平均15%
平峰时期查询耗时对比 优化前平均3.2s
优化后9ms
高峰时期查询耗时对比 优化前平均7.8s，最高13.24s
优化后平均32ms</description>
    </item>
    
    <item>
      <title>用Python读取sitemap并调用百度接口推送URL</title>
      <link>https://www.zengxi.net/2021/02/python_push_url_to_baidu/</link>
      <pubDate>Mon, 01 Feb 2021 18:06:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/02/python_push_url_to_baidu/</guid>
      <description>SEO对于网站的推广很重要，大多数搜索引擎都提供了一些API用于给站长主动提交URL，加快网页被收录的速度。
百度提供了快速收录的API接口，下面这个Python脚本可以用来读取本地磁盘中的sitemap.xml文件，并调用接口提交URL至百度。
仅需要修改下面的参数：
 lastUpdateTimeStr - 上次推送的时间。会与sitemap.xml中的时间做比较，仅推送在该时间之后更新的URL siteMapPath - sitemap.xml在本地磁盘上的存放路径 siteUrl - 网站地址 baiduApiToken - Baidu API的token tmpFile - 临时文件的保存地址 ignorePathPrefixes - 需要忽略的URL的前缀  1#!/usr/bin/env python3 2# coding: utf-8 3 4import xml.etree.ElementTree as ET 5from datetime import datetime 6import os 7 8 9### Methods ######### 10def stripNs(el): 11 # Recursively search this element tree, removing namespaces. 12 if el.tag.startswith(&amp;#34;{&amp;#34;): 13 el.tag = el.tag.split(&amp;#39;}&amp;#39;, 1)[1] # strip namespace 14 for k in el.</description>
    </item>
    
    <item>
      <title>使用Python在两个Postgres数据库直接复制数据</title>
      <link>https://www.zengxi.net/2021/01/python_copy_data_between_two_postgres/</link>
      <pubDate>Tue, 26 Jan 2021 17:17:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/python_copy_data_between_two_postgres/</guid>
      <description>在python脚本中，通过 psycopg2 库的copy_expert，可以很方便地在两个Postgres数据库之间复制数据
1s = StringIO() 2 3# Export into memory buffer 4sql = &amp;#34;&amp;#34;&amp;#34; 5COPY (select * from foo) TO STDOUT WITH CSV HEADER ENCODING &amp;#39;UTF8&amp;#39;; 6&amp;#34;&amp;#34;&amp;#34; 7 8sourceCursor = sourceConn.cursor() 9sourceCursor.copy_expert(sql, s) 10 11# Import from memory buffer to destination database 12sql = &amp;#34;&amp;#34;&amp;#34; 13COPY bar from STDIN WITH CSV HEADER ENCODING &amp;#39;UTF8&amp;#39;; 14&amp;#34;&amp;#34;&amp;#34; 15destinationCursor = destinationConn.cursor() 16destinationCursor.copy_expert(sql, s)  参考：
 https://www.psycopg.org/docs/cursor.html#cursor.copy_expert  </description>
    </item>
    
    <item>
      <title>Postgres通过SQL语句复制表结构</title>
      <link>https://www.zengxi.net/2021/01/postgres_copy_table_schema/</link>
      <pubDate>Tue, 26 Jan 2021 17:06:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/postgres_copy_table_schema/</guid>
      <description>在创建临时数据表的时候会有用</description>
    </item>
    
    <item>
      <title>MyBatis查询中动态指定schema</title>
      <link>https://www.zengxi.net/2021/01/mybatis_set_schema/</link>
      <pubDate>Mon, 25 Jan 2021 13:59:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/mybatis_set_schema/</guid>
      <description>由于业务的需要，在查询的时候，需要动态地在SQL语句中指定schema。在mybatis的的查询语句中，可以使用 ${schemaName}。注意，必须要用$, 而不是#</description>
    </item>
    
    <item>
      <title>Manjaro设置默认Java版本</title>
      <link>https://www.zengxi.net/2021/01/manjaro_set_default_java_version/</link>
      <pubDate>Wed, 20 Jan 2021 14:15:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/manjaro_set_default_java_version/</guid>
      <description>如果本机装了多个java版本，会有一个默认的java版本。随着java版本的不断升级，一些新的工具会要求高版本的java，否则无法运行。这个时候，就需要修改默认的java版本。
查看当前的java版本
1$ java -version 2openjdk version &amp;#34;11.0.10&amp;#34; 2021-01-19 3OpenJDK Runtime Environment (build 11.0.10+8) 4OpenJDK 64-Bit Server VM (build 11.0.10+8, mixed mode) 命令查看已安装的java版本
1$ archlinux-java status 2 3Available Java environments: 4 java-11-openjdk (default) 5 java-15-openjdk 6 java-8-openjdk 设置新的默认版本
1sudo archlinux-java set java-15-openjdk 再次查看当前的java版本，可以发现已经变更
1$ java -version 2openjdk version &amp;#34;15.0.1&amp;#34; 2020-10-20 3OpenJDK Runtime Environment (build 15.0.1+9) 4OpenJDK 64-Bit Server VM (build 15.0.1+9, mixed mode) </description>
    </item>
    
    <item>
      <title>国内常用镜像地址</title>
      <link>https://www.zengxi.net/links/mirror/</link>
      <pubDate>Thu, 14 Jan 2021 15:00:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/links/mirror/</guid>
      <description>最近更新日期：2021-02-24
Docker Hub 镜像列表 无需登录：
 Azure 中国镜像 - https://dockerhub.azk8s.cn 科大镜像站 - https://docker.mirrors.ustc.edu.cn 七牛云 - https://reg-mirror.qiniu.com 网易云 - https://hub-mirror.c.163.com 腾讯云 - https://mirror.ccs.tencentyun.com  需登录：
 DaoCloud - http://&amp;lt;your_code&amp;gt;.m.daocloud.io 阿里云 - https://&amp;lt;your_code&amp;gt;.mirror.aliyuncs.com  本地配置 创建或编辑 /etc/docker/daemon.json：
1{ 2 &amp;#34;registry-mirrors&amp;#34;: [ 3 &amp;#34;https://docker.mirrors.ustc.edu.cn&amp;#34;, 4 &amp;#34;https://reg-mirror.qiniu.com&amp;#34; 5 ] 6} 执行下面命令
1sudo systemctl daemon-reload 2sudo systemctl restart docker quay.io 镜像列表  quay-mirror.qiniu.com (七牛云, 推荐, 但没有找到长期支持的声明) quay.mirrors.ustc.edu.cn (中科大, 经常不可用, 不推荐)  本地配置 将镜像中的 quay.io 替换成国内镜像地址，例如：</description>
    </item>
    
    <item>
      <title>在线学习资源</title>
      <link>https://www.zengxi.net/links/learning_material/</link>
      <pubDate>Thu, 14 Jan 2021 15:00:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/links/learning_material/</guid>
      <description>Ansible  Ansible中文权威指南 - https://ansible-tran.readthedocs.io/en/latest/  Kubernetes  k8s官方文档 - https://kubernetes.io/zh/docs/home/  </description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (18) 高级调度：污点、容忍度和亲缘性</title>
      <link>https://www.zengxi.net/2021/01/k8s_advanced_scheduling/</link>
      <pubDate>Tue, 05 Jan 2021 23:00:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/k8s_advanced_scheduling/</guid>
      <description>使用污点和容忍度阻止节点调度到特定节点 污点和容忍度 污点是在不修改已有pod信息的前提下,通过在节点上添加污点信息,来拒绝pod在某些节点上的部署。
只有当一个pod容忍某个节点的污点, 这个pod才能被调度到该节点。
可以通过kubectl describe node查看节点的污点信息，在返回结果的Taints字段值中；可以通过kubectl describe po查看pod的污点容忍度，在返回结果的Tolerations字段值中。
每一个污点都可以关联一个效果, 效果包含了以下三种:
 NoSchedule：表示如果pod没有容忍这些污点, pod则不能被调度到包含这些污点的节点上。 PreferNoSchedule：它是NoSchedule的一个宽松的版本,表示尽量阻止pod被调度到这个节点上,但是如果没有其他节点可以调度, pod依然会被调度到这个节点上。 NoExecute：不同于NoSchedule以及PreferNoSchedule,后两者只在调度期间起作用, 而NoExecute也会影响正在节点上运行着的pod。如果在一个节点上添加了NoExecute污点,那些在该节点上运行着的pod,如果没有容忍这个NoExecute污点,将会从这个节点去除。  添加污点与容忍度 在节点上添加自定义污点 假设有一个单独的 Kubernetes 集群,上面同时有生产环境和非生产环境的流量。其中最重要的一点是,非生产环境的pod不能运行在生产环境的节点上。可以通过在生产环境的节点上添加污点来满足这个要求:
1# 这个命令添加了一个taint,其中key为node-type,value为production,效果为NoSchedule 2kubectl taint node nodel.k8s node-type=production:NoSchedule 在pod上添加污点容忍度 1apiVersion:extensions/vlbetal2kind:Deployment3metadata:4name:prod5spec:6replicas:57template:8spec:9tolerations:10# 此处的污点容忍度允许pod被调度到生产环境节点上11- key:node-type12operator:Equal13value:production14effect:NoSchedule污点和污点容忍度的使用场景 节点可以拥有多个污点信息,而pod也可以有多个污点容忍度。
污点可以只有一个key和一个效果,而不必设置value。污点容忍度可以通过设置Equal操作符Equal操作符来指定匹配的value(默认情况下的操作符)，或者也可以通过设置Exists操作符来匹配污点的key。
在调度时使用污点和容忍度 污点可以用来组织新pod的调度(使用 NoSchedule效果),或者定义非优先调度的节点(使用PreferNoSchedule效果), 甚至是将已有的pod从当前节点剔除。
可以用任何觉得合适的方式去设置污点和容忍度。例如,可以将一个集群分成多个部分,只允许开发团队将pod调度到他们特定的节点上。 当部分节点提供了某种特殊硬件, 并且只有部分pod需要使用到这些硬件的时候, 也可以通过设置污点和容忍度的方式来实现。
配置节点失效之后的pod重新调度最长等待时间 也可以配置一个容忍度, 用于当某个pod运行所在的节点变成unready或者unreachable状态时,k8s可以等待该pod被调度到其他节点的最长等待时间
1$ kubectl get po prod-350605-lphSh -o yaml 2... 3 tolerations: 4 - effect: NoExecute 5 key: node.alpha.kubernetes.io/notReady 6 operator: Exists 7 tolerationSeconds: 300 8 - effect: NoExecute 9 key: node.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (17) 自动横向伸缩pod与集群节点</title>
      <link>https://www.zengxi.net/2021/01/k8s_pod_auto_scaling/</link>
      <pubDate>Mon, 04 Jan 2021 22:49:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/k8s_pod_auto_scaling/</guid>
      <description>注意：Kubernetes的自动伸缩特性在1.6与1.7版本之间经历了一次重写, 因此网上关于此方面的内容有可能已经过时了。
pod的横向自动伸缩 自动伸缩步骤 横向pod自动伸缩是指由控制器管理的pod副本数量的自动伸缩。它由Horizontal控制器执行, 通过创建一个HorizontalpodAutoscaler(HPA)资源来启用和配置Horizontal控制器。该控制器周期性检查pod度量,计算满足HPA资源所配置的目标数值所需的副本数量, 进而调整目标资源(如Deployment、ReplicaSet、 ReplicationController、 StatefulSet等)的replicas字段。
自动伸缩的过程可以分为三个步骤:
 获取被伸缩资源对象所管理的所有pod度量。 计算使度量数值到达(或接近)所指定目标数值所需的pod数量。 更新被伸缩资源的replicas字段。  获取pod度量 pod与节点度量数据是由运行在每个节点的kubelet之上, 名为cAdvisor的agent采集的;这些数据将由集群级的组件Heapster聚合。
Autoscaler本身并不负责采集pod度量数据，HPA控制器向Heapster发起REST调用来获取所有pod度量数据。
关于Autoscaler采集度量数据方式的改变 在Kubernetes 1.6版本之前,HPA直接从Heapster采集度量。在1.8版本中,如果用--horizontal-pod-autoscaler-use-rest-clients=true参数启动ControllerManager, Autoscaler就能通过聚合版的资源度量API拉取度量了。该行为从1.9版本开始将变为默认。核心API服务器本身并不会向外界暴露度量数据。从1.7版本开始,k8s允许注册多个API服务器并使它们对外呈现为单个API服务器。这允许k8s通过这些底层API服务器之一来对外暴露度量数据。
集群管理员负责选择集群中使用何种度量采集器。通常需要一层简单的转换组件将度量数据以正确的格式暴露在正确的API路径下。
计算所需的pod数量 一旦Autoscaler获得了它所调整的资源(Deployment、 ReplicaSet、ReplicationController或StatefulSet)所辖pod的全部度量, 它便可以利用这些度量计算出所需的副本数量。它需要计算出一个合适的副本数量, 以使所有副本上度量的平均值尽量接近配置的目标值。该计算的输入是一组pod度量(每个pod可能有多个), 输出则是一个整数(pod副本数量)。
更新被伸缩资源的副本数 自动伸缩操作的最后一步是更新被伸缩资源对象(比如ReplicaSet)上的副本数字段, 然后让ReplicaSet控制器负责启动更多pod或者删除多余的pod。
Autoscaler控制器通过Scale子资源来修改被伸缩资源的replicas字段，这样Autoscaler不必了解它所管理资源的细节。
目前暴露了Scale子资源的资源有:
 Deployment ReplicaSet ReplicationController StatefulSet  基于CPU使用率进行自动伸缩 因为CPU使用通常是不稳定的, 比较靠谱的做法是在CPU被压垮之前就横向扩容。
注意：一定把目标CPU使用率设置得远远低于100%预留充分空间给突发的流量洪峰。
Autoscaler对比pod的实际CPU使用与它的请求, 这意味着需要给被伸缩的pod设置CPU请求,不管是直接设置还是通过LimitRange对象间接设置，这样Autoscaler才能确定CPU使用率。
基于CPU使用率创建HPA 先创建一个Deployment
1apiVersion:extensions/v1beta12kind:Deployment3metadata:4name:kubia5spec:6replicas:37template:8metadata:9name:kubia10label:11app:kubia12spec:13containers:14- image:luksa:kubia:v115name:nodejs16resources:17# 需要设定CPU请求量18requests:19cpu:100m为了给pod启用横向自动伸缩, 需要创建一个HorizontalpodAutoscaler (HPA)对象, 并把它指向该Deployment。
可以使用kubectl autoscale命令, 这个相对简单点
1kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5 或者使用YAML文件
1apiVersion:autoscaling/v2beta12kind:HorizontalPodAutoscaler3metadata:4name:kubia5spec:6maxReplicas:57metrics:8- resource:9name:cpu10targetAverageUtilization:3011type:Resource12minReplicas:113scaleTargetRef:14apiVersion:extensions/v1beta115kind:Deployment16metadata:17name:kubia注意：一定要确保自动伸缩的目标是Deployment而不是底层的ReplicaSet。这样才能确保预期的副本数量在应用更新后继续保持(记着Deployment会给每个应用版本创建一个新的ReplicaSet)。手动伸缩也是同样的道理。
伸缩操作的最大速率 Autoscaler 两次扩容操作之间的时间间隔有限制。目前,只有当3分钟内没有任何伸缩操作时才会触发扩容,缩容操作频率更低,为5分钟</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (16) 计算资源管理</title>
      <link>https://www.zengxi.net/2021/01/k8s_computing_resource_management/</link>
      <pubDate>Sun, 03 Jan 2021 19:22:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/k8s_computing_resource_management/</guid>
      <description>为pod中的容器申请资源 创建一个pod时,可以指定容器对 CPU 和内存的资源请求量(即requests),以及资源限制量(即limits)。它是针对每个容器单独指定，pod对资源的请求量和限制量是所包含的所有容器的请求量和限制量之和。
1apiVersion:v12kind:Pod3metadata:4name:requests-pod5spec:6containers:7- image:busybox8command:[&amp;#34;dd&amp;#34;,&amp;#34;if=/dev/zero&amp;#34;,&amp;#34;of=/dev/null&amp;#34;]9name:main10resources:11requests:12cpu:200m # 申请200毫核，即一个CPU核心的1/5时间13memory:10Mi # 申请50MB内存资源requests对调度的影响 资源requests指定了pod对资源需求的最小值。调度器在调度时只考虑那些未分配资源量满足pod需求量的节点。如果节点的未分配资源量小于pod需求量,这时节点没有能力提供pod对资源需求的最小量,因此k8s不会将该pod调度到这个节点。
调度器在调度时并不关注各类资源在当前时刻的实际使用量,而只关心节点上部署的所有pod的资源申请量之和。尽管现有所有pod的资源实际使用量可能小于它的申请量,但如果使用基于实际资源消耗量的调度算法将打破系统为这些已部署成功的pod提供足够资源的保证。
调度器如何利用pod requests为其选择最佳节点 调度器首先会对节点列表进行过滤，排除那些不满足需求的节点, 然后根据预先配置的优先级函数对其余节点进行排序。其中有两个基于资源请求量的优先级排序函数:
 LeastRequestedPriority：优先将pod调度到请求量少的节点上，也就是拥有更多未分配资源的节点 MostRequestedPriority：优先调度到请求量多的节点，拥有更少未分配资源的节点。  它们都只考虑资源请求量, 而不关注实际使用资源量。
调度器只能配置一种优先级函数。
配置调度器使用MostRequestedPriority函数, 可以在为每个pod提供足量CPU与内存资源的同时, 确保k8s使用尽可能少的节点。通过使pod紧凑地编排,一些节点可以保持空闲并可随时从集群中移除。
查看节点资源总量 查看节点资源总量
1$ kubectl describe nodes 2Name: minikube 3... 4# 节点的资源总量 5Capacity: 6 cpu: 2 7 memory: 2048484Ki 8 pods: 110 9# 可分配给pod的资源量 10Allocatable: 11 cpu: 2 12 memory: 1946084Ki 13 pods: 110 14... 通过kubectl describe node命令的输出结果，可以检查节点已经分配的资源，找出为什么pod没有成功调度
1kubectl describe node CPU requests对CPU时间分配的影响 CPU requests不仅仅在调度时起作用,它还决定着剩余(未使用) 的CPU时间如何在pod之间分配。假设第一个pod请求了200毫核,另一个请求了1000毫核，那么未使用的CPU将按照1:5的比例来划分给这两个pod。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (15) 节点与网络安全</title>
      <link>https://www.zengxi.net/2021/01/k8s_node_security/</link>
      <pubDate>Sun, 03 Jan 2021 13:02:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2021/01/k8s_node_security/</guid>
      <description>在pod中使用宿主节点的Linux命名空间 pod中的容器通常在分开的Linux命名空间中运行。 这些命名空间将容器中的进程与其他容器中,或者宿主机默认命名空间中的进程隔离开来。
使用宿主节点的网络命名空间 部分pod(特别是系统pod)需要在宿主节点的默认命名空间中运行,以允许它们看到和操作节点级别的资源和设备。例如,某个pod可能需要使用宿主节点上的网络适配器,而不是自己的虚拟网络设备。这可以通过将pod spec中的hostNetwork设置为true实现。
在这种情况下,这个pod可以使用宿主节点的网络接口,而不是拥有自己独立的网络。这意味着这个pod没有自己的IP地址;如果这个pod中的一某进程绑定了某个端口,那么该进程将被绑定到宿主节点的端口上。
绑定宿主节点上的端口而不使用宿主节点的网络命名空间 这个功能可以让 pod 在拥有自己的网络命名空间的同时,将端口绑定到宿主节点的端口上。可以通过配置 pod 的spec.containers.ports字段中某个容器某一端口的 hostPort 属性来实现。
不要混淆使用 hostPort 的 pod 和通过 Node Port 服务暴露的 pod。如果一个 pod 绑定了宿主节点上的一个特定端口,每个宿主节点只能调度-个这样的 pod 实例,因为两个进程不能绑定宿主机上的同一个端口。调度器在调度 pod 时会考虑这一点, 所以它不会把两个这样的 pod 调度到同一个节点上,
使用宿主节点的 PID 与 IPC 命名空间 pod spec 中的 hostPID 和 host IPC 选项与 hostNetwork 相似。当它们被设 置为 true 时, pod 中的容器会使用宿主节点的 PID 和 IPC 命名空间,分别允许它们看到宿主机上的全部进程,或通过 IPC 机制与它们通信。
配置节点的安全上下文 除了让 pod 使用宿主节点的 Linux 命名空间,还可以在 pod 或其所属容器的描 述中通过 security-Context 选项配置其他与安全性相关的特性。这个选项可以 运用于整个 pod ,或者每个 pod 中单独的容器。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (14) API Server服务器的安全防护</title>
      <link>https://www.zengxi.net/2020/12/k8s_api_server_security/</link>
      <pubDate>Tue, 29 Dec 2020 22:38:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_api_server_security/</guid>
      <description>如果攻击者获得了访问API服务器的权限, 他们可以通过在容器镜像中打包自己的代码并在pod中运行来做任何事
认证机制 API 服务器可以配置一个认证插件列表。列表中的每个插件都可以检查这个请求和尝试确定谁在发送这个请求。当通过认证后，返回用户名、用户 ID 和组信息给 API 服务器，API服务器就会停止调用剩余的认证插件井继续进入授权阶段。
用户与组 k8s 区分了两种连接到 API 服务器的客户端 :
 用户（真实的人） pod (更准确地说是运行在 pod 中的应用)  用户应该被管理在外部系统中，例如单点登录系统。没有资源代表用户账户，这也就意味着不能通过 API 服务器来创建、更新或删除用户。
pod 使用一种称为 service accounts 的机制, 该机制被创建和存储在集群中作为 ServiceAccount 资源。
正常用户和 ServiceAccount 都可以属于一个或多个组。可以通过组对一批用户进行授权。
由插件返回的组仅仅是表示组名称的字符串,但是系统内置的组会有一些特殊的含义。
 system:unauthenticated 组用于所有认证插件都不会认证客户端身份的请求。 system:authenticated 组会自动分配给一个成功通过认证的用户。 system:serviceaccounts 组包含所有在系统中的 ServiceAccount 。 system:serviceaccounts:组包含了所有在特定命名空间中的ServiceAccount。  ServiceAccount ServiceAccount介绍 ServiceAccount就像Pod、 Secret、 ConfigMap等一样都是资源, 它们作用在单独的命名空间, 为每个命名空间自动创建一个默认的ServiceAccount
可以像其他资源那样查看ServiceAccount列表：
1kubectl get sa 在 pod 的 manifest 文件中, 可以用指定账户名称的方式将一个 ServiceAccount赋值给一个 pod。如果不显式地指定 ServiceAccount 的账户名称, pod 会使用在这个命名空间中的默认 ServiceAccount。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (13) Statefulset</title>
      <link>https://www.zengxi.net/2020/12/k8s_statefulset/</link>
      <pubDate>Tue, 29 Dec 2020 13:43:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_statefulset/</guid>
      <description>了解Statefulset 与ReplicaSet比较 Statefulset 保证了pod在重新调度后保留它们的标识和状态。
与ReplicaSet类似, Statefulset 也是依据Statefulset 的pod模板创建的，也会指定期望的副本个数。
不同的是, Statefulset创建的pod副本并不是完全一样的。每个pod都可以拥有一组独立的数据卷(持久化状态)。pod的名字都是规律的(固定的), 而不是每个新pod都随机获取一个名字。
提供稳定的网络标识 一个Statefulset创建的每个pod都有一个从零开始的顺序索引, 这个会体现在pod的名称和主机名上, 同样还会体现在pod对应的固定存储上。
与普通的pod不一样的是, 有状态的pod有时候需要通过其主机名来定位。无状态Pod都是一样的，所以访问的时候随便选择一个都可以；而有状态的pod是彼此不同的，通常希望操作的是其中特定的一个。
一个Statefulset 通常要求创建一个用来记录每个pod网络标记的headless Service。通过这个Service, 每个pod将拥有独立的DNS记录, 这样集群里它的伙伴或者客户端可以通过主机名方便地找到它。比如说, 一个属于default命名空间, 名为foo的控制服务, 它的一个pod名称为A-0, 那么可以通过下面的完整域名来访问它 : a-0.foo.default.svc.cluster.local
扩缩容 Statefulset 扩容一个Statefulset会使用下一个还没用到的顺序索引值创建一个新的pod实例。比如, 要把一个Statefulset从两个实例扩容到三个实例, 那么新实例的索引值就会是2 (现有实例使用的索引值为0和1)。
缩容一个Statefulset将会最先删除最高索引值的实例，所以缩容的结果是可预知的。作为对比, ReplicaSet 的缩容操作则不同,不知道哪个实例会被删除, 也不能指定先删除哪个实例
因为 Statefulset 缩容任何时候只会操作一个pod实例，所以有状态应用的缩容相对比较慢。举例来说, 一个分布式存储应用若同时下线多个节点, 则可能导致其数据丢失。比如说一个数据项副本数设置为2的数据存储应用,若同时有两个节点下线,一份数据如果它正好保存在这两个节点上记录就会丢失。若缩容是线性的, 则分布式存储应用就有时间把丢失的副本复制到其他节点,保证数据不会丢失。基于以上原因, Statefulset 在有实例不健康的情况下是不允许做缩容操作的 。若一个实例是不健康的, 而这时再缩容一个实例的话, 也就意味着你实际上同时失去了两个集群成员 。
为每个有状态实例提供稳定的专属存储 有状态的pod的存储必须是持久的,并且与pod解耦。必须设置成手动释放，否则数据丢失。
持久卷声明与持久卷是一对一的关系,所以每个Statefulset的 pod 都需要关联到不同的持久卷声明, 与独自的持久卷相对应。
缩容 Statefulset 时会保留持久卷声明, 所以在随后的扩容操作中, 新的pod实例会使用绑定在持久卷上的相同声明和其上的数据
Statefulset 的 at-most-one 的语义 一个 Statefulset 必须保证有状态的pod实例的αt-most-one语义。也就是说一个Statefulset必须在准确确认一个pod不再运行后,才会去创建它的替换pod
在 Statefulset 中发现伙伴节点 一个Statefulset中的成员需要很容易地找到其他的所有成员。当然它可以通过与API服务器通信来获取, 但是K8s的一个目标是设计功能来帮助应用完全感觉不到k8s的存在。因此让应用与API服务器通信的设计是不允许的</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (12) Deployment</title>
      <link>https://www.zengxi.net/2020/12/k8s_deployment/</link>
      <pubDate>Sun, 27 Dec 2020 23:08:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_deployment/</guid>
      <description>Deployment是一种更高阶资源, 用于部署应用程序并以声明的方式升级应用。
在使用 Deployment 时, 实际的 pod是由 Deployment 的 Replicaset 创建和管理的, 而不是由 Deployment 直接创建和管理的。
在升级应用过程中，部署新版本的应用时，会创建新的Replicaset用于管理版本的pod。升级过程中的某个时刻，就会存在新旧两个版本的Replicaset。因此，需要引入Deployment来协调。
与Replicaset类似，Deployment也是由标签选择器、期望副数和pod模板组成的。此外,它还包含另一个字段，用于指定一 个部署策略，表示在修改Deployment资源时应该如何执行更新。
创建Deployment 1appVersion:apps/v1beta12kind:Deployment 3metadata:4name:kubia5spec:6replicas:37template:8metadata:9name:kubia10labels:11app:kubia12spec:13containers:14- image:luksa/kubia:vl15name:nodejs创建一个Deployment
1# 确保在创建时使用了 --record 选项。 这个选项会记录历史版本号, 在之后的操作中非常有用 2kubectl create -f kubia-deployment-v1.yaml --record 查看 Deployment 的详细信息
1kubectl get deployment 2 3kubectl describe de­ployment 查看部署状态
1 kubectl rollout status deployment kubia 升级deployment 只需修改 Deployment 资源中定义的 pod 模板, k8s 会自动将实际的系统状态收敛为资源中定义的状态
不同的 Deployment 升级策略：
 RollingUpdate：执行滚动更新，默认值。如果应用能够支持多个版本同时对外提供服务, 则推荐使用这个策略来升级应用 Recreate：一次性删除所有旧版本的 pod, 然后创建新的 pod。如果应用程序不支持多个版本同时对外提供服务, 需要在启动新版本之前完全停用旧版本, 那么需要使用这种策略。但是会导致应用程序出现短暂的不可用。  下面是修改 Deployment 或其他资源的不同方式。这些方式在操作 Deployment 资源时效果都是一样的。 它们无非就是修改Deployment 的规格定义, 修改后会触发滚动升级过程。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (11) 从应用访问pod元数据及其他资源</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_meta_data/</link>
      <pubDate>Sat, 26 Dec 2020 14:53:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_meta_data/</guid>
      <description>通过Downward API传递元数据 对于pod调度、运行前预设的数据，可以通过环境变量或者configMap和secret卷向应用传递配置数据。但是对于那些不能预先知道的数据, 比如pod的IP、 主机名或者是通过ReplicaSet等控制生成的pod名称，该如何获取呢？这种类型的数据，可以通过使用Kubernetes Downward API解决。
Downward API可以给在pod中运行的进程暴露pod的元数据。目前可以给容器传递以下数据:
 pod的名称 pod的IP pod所在的命名空间 pod运行节点的名称 pod运行所归属的服务账户的名称 每个容器请求的CPU和内存的使用量 每个容器可以使用的CPU和内存的限制 pod的标签 pod的注解  通过环境变量暴露元数据 1env:2- name:POD_NAME3# 引用pod manifest中的元数据名称字段,而不是设定一个具体的值4valueFrom:5fieldRef:6fieldPath:metadata.name7- name:POD_NAMESPACE8valueFrom:9fieldRef:10fieldPath:metadata.namespace11- name:POD_IP12valueFrom:13fieldRef:14fieldPath:status.podIP15- name:NODE_NAME16valueFrom:17fieldRef:18fieldPath:spec.nodeName19- name:SERVICE_ACCOUNT20valueFrom:21fieldRef:22fieldPath:spec.serviceAccountName23- name:CONTAINER_CPU_REQUEST_MILLICORES24valueFrom:25# 容器请求的CPU和内存使用量是使用resourceFieldRef字段而不是feildRef字段26resourceFieldRef:27resource:requests.cpu28divisor:1m # 对于资源相关字段，定义一个基数单位，从而生成每一部分的值29- name:CONTAINER MEMORY LIMIT KIBIBYTES30valueFrom:31resourceFieldRef:32resource:limits.memory33divisor:1Ki34对于暴露资源请 和使用限制的环境变量, 我们会设定一个基数单位。实际的资源请求值和限制值除以这个基数单位, 所得的结果通过环境变量暴露出去。在上面的例子中, 我们设定 CPU 请求的基数为1m (即1 millicore, 也就是千分之一核CPU)。当我们设置资源请求为15m时, 环境变量CONTAINER_CPU_REQUEST_MILLICORES的值就是15
在完成创建pod后, 我们可以使用kubectl exec命令来查看容器中的所有环境变量
1kubectl exec downward env 通过卷传递元数据 可以定义一个downwardAPI卷，并以文件的方式挂载在容器中。
1apiVersion:v12kind:Pod3metadata:4# 后面会添加定义，通过downwardAPI卷来暴露这些标签5name:downward6labels:7foo:bar8annotations:9key1:value110key2:|11multi 12line 13value14spec:15containers:16- name:main17image:busybox18command:[&amp;#34;sleep&amp;#34;,&amp;#34;9999999&amp;#34;]19resources:20requests:21cpu:15m22memory:l00Ki23limits:24cpu:100m25memory:4Mi26volumeMounts:27# 挂载卷28- name:downward29mountPath:/etc/downward30volumes:31# 定义一个名字为downward的downwardAPI卷32- name:downward33downwardAPI:34items:35# Pod名称（来自manifest文件中的metadata.name字段）将被写入podName这个文件36- path:&amp;#34;podName&amp;#34;37fieldRef:38fieldPath:metadata.name39- path:&amp;#34;podNamespace&amp;#34;40fieldRef:41fieldPath:metadata.namespace42- path:&amp;#34;labels&amp;#34;43fieldRef:44fieldPath:metadata.labels45- path:&amp;#34;annotations&amp;#34;46fieldRef:47fieldPath:metadata.annotations48- path:&amp;#34;containerCpuRequestMilliCores&amp;#34;49resourceFieldRef:50containerName:main51resource:requests.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (10) 使用ConfigMap与Secret传递应用配置</title>
      <link>https://www.zengxi.net/2020/12/k8s_config_map_secret/</link>
      <pubDate>Fri, 25 Dec 2020 16:14:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_config_map_secret/</guid>
      <description>向容器传递应用程序的配置参数 方法：
 向容器传递命令行参数 为每个容器设置自定义环境变量 通过特殊类型的卷将配置文件挂载到容器中  向容器传递命令行参数 在Docker中定义命令与参数 容器中运行的完整指令由两部分组成:命令与参数。Dockerfile中的两种指令分别定义命令与参数这两个部分：
 ENTRYPOINT: 定义容器启动时被调用的可执行程序 CMD: 指定传递给ENTRYPOINT的参数。  尽管可以直接使用CMD指令指定镜像运行时想要执行的命令, 正确的做法依旧 是借助ENTRYPOINT指令, 仅仅用CMD指定所需的默认参数。 这样, 镜像可以直 接运行, 无须添加任何参数
1docker run &amp;lt;image&amp;gt; 或者是添加一些参数, 覆盖Dockerile中任何由CMD指定的默认参数值:
1docker run &amp;lt;image&amp;gt; &amp;lt;arguments&amp;gt; shell与exec的区别 上述两条指令均支持以下两种形式。两者的区别在于指定的命令是否是在shell中被调用。
 shell形式。如ENTRYPOINT node app.js。 exec形式。如ENTRYPOINT [&amp;quot;node&amp;quot;, &amp;quot;app.js&amp;quot;]。  下面用例子来看他们的区别
1# exec形式 2# 从返回的进程列表看出:这里是直接运行node进程,而并非在shell中执行。 3$ docker exec 4675d ps x 4PID TTY STAT TIME COMMAND 51 ? Ssl 0:00 node app.Js 612 ? Rs 0:00 ps x 7 8# shell形式 9# 可以看出,主进程(PID 1)是shell进程而非node进程,node进程(PID 7)于shell中启动。  10$ docker exec -it e4bad ps x 11PID TTY STAT TIME COMMAND 121 ?</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (9) 卷</title>
      <link>https://www.zengxi.net/2020/12/k8s_volume/</link>
      <pubDate>Tue, 22 Dec 2020 22:16:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_volume/</guid>
      <description>卷 卷是 pod 的一个组成部分，不是独立的 Kubernetes 对象, 不能单独创建或删除。 pod 中的所有容器都可以使用卷, 但必须先将它挂载在每个需要访问它的容器中。
卷类型 主要类型：
 emptyDir:用于存储临时数据的简单空目录。 hostPath: 用于将目录从工作节点的文件系统挂载到pod中 gitRepo: 通过检出Git仓库的内容来初始化的卷 nfs: 挂载到pod中的NFS共享卷 用于挂载云服务商提供的特定存储类型。比如，gcePersistentDi sk (Google 高效能型存储磁盘卷)、 awsElasticBlockStore (AmazonWeb 服务弹性块存储卷)、 azureDisk (Microsoft Azure 磁盘卷) 用于挂载其他类型的网络存储。比如，cinder、cephfs、iscsi、flocker、glusterfs、quobyte、rbd、flexVolume、vsphere-Volume、photonPersistentDisk 、scaleIO configMap、secret、downwardAPI 一一用于将 k8s 部分资源和集群信息公开给 pod 的特殊类型的卷 persistentVolumeClaim：一种使用预置或者动态配置的持久存储类型  emptyDir 卷从一个空目录开始,运行在 pod 内的应用程序可以写入它需要的任何文件。当删除 pod 时,卷的内容就会丢失。
一个 emptyDir 卷对于在同一个 pod 中运行的容器之间共享文件特别有用。但是它也可以被单个容器用于将数据临时写入磁盘。
下面是个例子
1apiVersion:vl2kind:Pod3metadata:4name :fortune5spec:6containers:7- image:luksa/fortune8name:html-generator9volumeMounts:10- name:html11mountPath:/var/html/docs12- image:nginx:alpine13name:web-server14volumeMounts :15- name:html16mountPath:/usr/share/nginx/html17readOnly:true18ports:19- containerPort:8020protocol:TCP21volumes:22- name:html23emptyDir:{}medium属性可以指定存储介质。比如内存
1volumes:2name:html3emptyDir:4medium:Memory使用 Git 仓库作为存储卷 gitRepo 卷基本上也是 一 个 emptyDir 卷,它通过克隆 Git 仓库并在 pod 启动时(但在创建容器之前) 检出特定版本来填充数据</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (8) 服务、Endpoint、Ingress</title>
      <link>https://www.zengxi.net/2020/12/k8s_service/</link>
      <pubDate>Sun, 20 Dec 2020 21:17:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_service/</guid>
      <description>什么是服务 服务是一种为一组功能相同的 pod 提供单 一 不变的接入点的资源。当服务存在时,它的 IP 地址和端口不会改变
为什么需要服务 pod 的存在是短暂的,一个 pod 可能会在任何时候消失, 或许因为它所在节点发生故障, 或许因为有人删除了 pod, 或者因为 pod 被从一个健康的节点剔除了。 当其中任何一种情况发生时, 消失的 pod 将被ReplicationController 替换为新的 pod。 新的 pod 与替换它的 pod 具有不同的 IP 地址。
这就是需要服务的地方，解决不断变化的 pod IP 地址的问题, 以及在一个固定的IP和端口对上对外暴露多个 pod。当一个服务被创建时, 它会得到一个静态的 IP, 在服务的生命周期中这个 IP不会发生改变。 客户端应该 通过固定 IP 地址连接到服务, 而不是直接连接 pod。服务会确保其中一个pod 接收连接, 而不关心 pod 当前运行在哪里(以及它的 IP 地址 是什么)。
创建服务 通过 kubectl expose 创建服务
1kubectl expose pod valid-pod --port=444 --name=frontend 通过 YAML 描述文件来创建服务
1apiVersion:v12kind:Service3metadata:4name:kubia5spec:6ports:7- port:80# 该服务的可用端口8targetPort:8080# 转发到的容器端口9# 选择Pod10selector:11app:kubia服务的一些配置 会话的亲和性 如果多次执行同样的命令, 每次调用执行在随机的pod上。如果希望特定客户端产生的所有请求每次都指向同一个 pod, 可以设置服务的 sessionAffinity 属性为 ClientIP (默认值是None)。这种方式将会使服务代理将来自同 一 个 client IP 的所有请求转发至同一个pod上</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (7) DaemonSet、Job和CronJob</title>
      <link>https://www.zengxi.net/2020/12/k8s_daemonset_job/</link>
      <pubDate>Sun, 13 Dec 2020 19:52:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_daemonset_job/</guid>
      <description>DaemonSet DaemonSet 用于确保一个pod匹配它的选择器并在每个节点上运行。因此，它并没有期望的副本数的概念。
如果节点下线, DaemonSet不会在其他地方重新创建pod。 但是, 当将一个新节 点添加到集群中时, DaemonSet会立刻部署一个新的pod实例。
使用场景的例子：
 pod执行系统级别的与基础结构相关的操作。例如, 希望在每个节点上运行日志收集器和资源监控器。 另一个典型的例子是Kubemetes 自己的kube-proxy进程, 它需要运行在所有节点上才能使服务工作  可以通过 pod 模板中的 nodeSelector 属性让 DaemonSet 只在特定的节点上运行 pod。
1apiVersion:apps/vlbeta22kind:DaemonSet3metadata:4name:ssd-monitor5spec:6selector:7matchLabels:8app:ssd-monitor9template:10metadata:11labels:12app:ssd-monitor13spec:14# pod模板包含 会选择有disk=ssd标签的节点个节点选择器,15nodeSelector:16disk:ssd 17containers:18- name:main19image:luksa/ssd-monitorJob Job允许运行一种 pod, 该 pod 在内部进程成功结束时, 不重启容器。
在发生节点故障时,该节点上由 Job 管理的 pod 将按照 ReplicationSet 的 pod 的方式,重新安排到其他节点。 如果进程本身异常退出(进程返回错误退出代码时), 可以将 Job 配置为重新启动容器。
Job 对于临时任务很有用, 关键是任务要以正确的方式结束。需要明确地将重启策略设置为OnFa辽ure或Never，防止容器在完成任务时重新启动
1apiVersion:batch/vl2kind:Job3metadata:4name:batch-job5spec:6template:7metadata:8labels:9app:batch-job10spec:11# Job 不能使用Always作为默认的重启策略12restartPolicy:OnFailure13containers:14- name:main15image:luksa/ssd-monitor作业可以配置为创建多个pod实例, 以并行或串行方式运行它们。这是通过在Job配置中设置 completions和paralletism属性来完成的。
如果需要一个Job顺序运行多次，则可以将completions设为希望运行的次数。Job将一个接一个地运行五个pod。它最初创建一个pod, 当pod的容器运行完成时,它创建第二个pod, 以此类推，直到五个pod成功完成。如果其中 一 个pod发生故障，工作会创建 一个新的pod, 所以Job总共可以创建五个以上的pod。
1apiVersion:batch/vl2kind:Job3metadata:4name:multi-completion-batch-job5spec:6completions:57template:8...通过paralletism Job配置属性,指定允许多少个pod并行执行
1apiVersion:batch/vl2kind:Job3metadata:4name:multi-completion-batch-job5spec:6completions:57paralletism:28template:9...可以在 Job 运行时更改 Job 的 parallelism 属性</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (6) ReplicationController和ReplicationSet</title>
      <link>https://www.zengxi.net/2020/12/k8s_replctl_replset/</link>
      <pubDate>Sun, 13 Dec 2020 10:16:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_replctl_replset/</guid>
      <description>托管的Pod 如果是直接创建Pod，当节点失效，这个Pod就会丢失。
如果是通过ReplicationController或者Deployment等资源来创建的，那就属于托管的资源。k8s集群会管理并检测它的运行状态，当一些意外情况发生的，k8s会自动采取应对措施。
ReplicationController ReplicationController是一种k8s资源，会持续监控正在运行的pod列表, 并保证相应类型的pod的数目与期望相符。
一个ReplicationController有三个主要部分：
 label selector (标签选择器), 用于确定ReplicationController作用域中有哪些pod replica count (副本个数), 指定应运行的pod 数量 pod template (pod模板), 用于创建新的pod 副本  使用 ReplicationController 的好处:
 确保一个 pod (或多个 pod 副本)持续运行, 方法是在现有 pod 丢失时启动一个新 pod 。 集群节点发生故障时, 它将为故障节点上运行的所有 pod (即受ReplicationController 控制的节点上的那些 pod) 创建替代副本。 它能轻松实现 pod 的水平伸缩，手动和自动都可以  创建一个ReplicationController
1apiVersion:vl2kind:Replicationcontroller3metadata:4name:kubia5spec:6replicas:37selector:8app:kubia9template:10metadata:11labels:12app:kubia13spec:14containers:15- name:kubia16image:luksa/kubia17ports:18- containerPort:8080通过kubectl get命令显示的关于ReplicationController的信息
1kubectl get rc 2 3kubectl get replicationcontroller 通过kubectl describe查看附加信息
1kubectl describe rc kubia 通过更改pod的标签, 可以将它从ReplicationController的作用域中添加或删除，甚至移动到另外一个ReplicationController
ReplicationController 的 pod 模板可以随时修改，但是只会影响后面新建的 Pod。如果需要修改旧的Pod，要将Pod删除，ReplicationController会自动根据新的模板创建Pod来替代。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (5) Pod的生命周期与探针</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_lifecycle_probes/</link>
      <pubDate>Fri, 11 Dec 2020 12:30:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_lifecycle_probes/</guid>
      <description>Pod生命周期 Pod的phase是Pod生命周期中的简单宏观描述，定义在Pod的PodStatus对象的phase 字段中。
phase有以下几种值：
   状态值 说明     挂起（Pending） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间。   运行中（Running） 该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。   成功（Succeeded） Pod 中的所有容器都被成功终止，并且不会再重启。   失败（Failed） Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。   未知（Unknown） 因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。    容器状态 容器的状态有三种：Waiting（等待）、Running（运行中）和 Terminated（已终止）。
容器重启策略 Pod 的 spec 中包含一个 restartPolicy 字段，其可能取值包括 Always、OnFailure 和 Never。默认值是 Always。
restartPolicy 适用于 Pod 中的所有容器。restartPolicy 仅针对同一节点上 kubelet 的容器重启动作。当 Pod 中的容器退出时，kubelet 会按指数回退 方式计算重启的延迟（10s、20s、40s、.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (4) 标签、注解与命名空间</title>
      <link>https://www.zengxi.net/2020/12/k8s_label_annotation_namespace/</link>
      <pubDate>Thu, 10 Dec 2020 22:04:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_label_annotation_namespace/</guid>
      <description>标签 什么是标签 标签是可以附加到资源的任意键值对。通过标签选择器，可以筛选出具有该确切标签的资源。
使用标签和选择器来约束pod调度 默认情况下，Pod基本上是随机地调度到任意Node节点的。但是某些情况下，想要调度到特定的Node节点，比如SSD硬盘的节点。这个时候，可以通过节点标签和节点标签选择器完成。
1# 这个例子中通过nodeSelector选择部署到gpu=true的节点2apiVersion:vl3kind:Pod4metadata:5name:kubia-gpu6spec:7nodeSelector:8gpu=true9containers:10- image:luksa/kubia11name:kubia注解 除标签外,pod和其他对象还可以包含注解。注解也是键值对, 但与标签不同, 注解并不是为了保存标识信息而存在的。
使用注解可以为每个pod或其他API对象添加说明,以便每个使用该集群的人都可以快速查找有关每个单独对象的信息。
命名空间 作用 k8s的命名空间简单地为对象名称提供了一个作用域。这样就可以将包含大量组件的复杂系统拆分为更小的不同组，这些不同组也可以用于在多租户环境中分配资源，将资源分配为生产、开发和 QA 环境,或者以其他任何你需要的方式分配资源。资源名称只需在命名空间内保持唯一即可，因此两个不同的命名空间可以包含同名的资源。
创建命名空间及其资源 可以使用yaml文件来创建命名空间
1apiVersion:vl2kind:Namespace3metadata:4name：custom-namespace或者使用命令来创建命名空间
1kubectl create namespace custom-namespace 想要在创建的命名空间中创建资源, 可以选择在 metadata 宇段中添加一个 namespace: custom-namespace 属性,也可以在使用 kubectl create命令创建资源时指定命名空间:
1kubectl create -f kubia-manual.yaml -n custom-namespace 命名空间的切换 如果不指定命名空间, kubectl 将在当前上下文中配置的默认命名空间中执行操作。而当前上下文的命名空间和当前上下文本身都可以通过 kubectl config 命令进行更改。如果想要对其他命名空间中的对象进行操作, 需要给 kubectl 命令传递-- namespace (或 -n) 选项。
要想快速切换到不同的命名空间, 可以设置以下别名，然后,可以使用 kcd some-namespace 在命名空间之间进行切换 。
1alias kcd =’kubectl config set context $(kubectl config current-context) -- namespace’ 命名空间的隔离性 尽管命名空间将对象分隔到不同的组,只允许你对属于特定命名空间的对象进行操作, 但实际上命名空间之间并不提供对正在运行的对象的任何隔离 。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (3) Pod介绍</title>
      <link>https://www.zengxi.net/2020/12/k8s_pod_intro/</link>
      <pubDate>Thu, 03 Dec 2020 23:30:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_pod_intro/</guid>
      <description>什么是Pod Pod是k8s的基本构建模块，包含一个或者多个容器。一个Pod中的所有容器都运行在同—个节点上，绝不跨越两个节点
为何需要Pod 多个容器比单个容器中包含多个进程要好 想象一个由多个进程组成的应用程序, 无论是通过ipc (进程间通信)还是本地存储文件进行通信, 都要求它们运行于同一 台机器上。 在k8s中, 我们经常在容器中运行进程, 由于每一个容器都非常像一台独立的机器, 此时你可能认为在单个容器中运行多个进程是合乎逻辑的, 然而在实践中这种做法并不合理。
容器被设计为每个容器只运行一个进程(除非进程本身产生子进程)。如果在单个容器中运行多个不相关的进程, 那么保持所有进程运行、 管理它们的日志等将会是我们的责任。例如, 我们需要包含一种在进程崩溃时能够自动重启的机制。同时这些进程都将记录到相同的标准输出中, 而此时我们将很难确定每个进程分别记录了什么。
综上所述, 我们需要让每个进程运行于自己的容器中, 而这就是Docker和k8s期望使用的方式。
引入Pod 由于不能将多个进程聚集在一个单独的容器中, 我们需要另一种更高级的结构来将容器绑定在一起,并将它们作为一个单元进行管理,这就是 Pod 背后的根本原理。
在包含容器的 Pod 下,我们可以同时运行一些密切相关的进程,并为它们提供几乎相同的环境, 此时这些进程就好像全部运行于单个容器中一样, 同时又保持着一定的隔离。这样一来, 我们便能全面地利用容器所提供的特性, 同时对这些进程来说它们就像运行在一起一 样, 实现两全其美。
Pod的一些特征 同一Pod中容器之间的部分隔离 Pod内部的容器共享部分资源（不是全部），没有完全隔离。这些容器共享相同的 Linux 命名空间, 而不是每个容器都有自己的一组命名空间。比如，它们有相同的 network 和 UTS 命名空间，所以它们都共享相同的主机名和网络接口。
但当涉及文件系统时, 情况就有所不同。 由于大多数容器的文件系统来自容器镜像, 因此默认情况下, 每个容器的文件系统与其他容器完全隔离。但是，可以使用名为 Volume 的 k8s 资源来共享文件目录。
Pod内部容器共享相同的IP和端口空间 由于一个pod中的容器运行于相同的 Network 命名空间中, 因此它们共享相同的 IP 地址和端口空间。这意味着在同一 pod 中的容器运行的多个进程需要注意不能绑定到相同的端口号, 否则会导致端口冲突, 但这只涉及同一pod 中的容器。
由于每个 pod 都有独立的端口空间, 对于不同 pod 中的容器来说则永远不会遇到端口冲突。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (2) k8s集群架构</title>
      <link>https://www.zengxi.net/2020/12/k8s_cluster_structure/</link>
      <pubDate>Thu, 03 Dec 2020 13:45:00 +0800</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_cluster_structure/</guid>
      <description>集群架构 k8s集群由很多节点组成，被分成两种类型：Master节点与Node节点。
Master节点 承载着控制和管理整个集群系统的 Control Panel。包含下面组件：
 API Server  一个api服务器，所有外部与k8s集群的交互都需要经过它 可水平扩展   Scheduler  将pod调度到具体的Node节点上 一个master集群中只会有一个节点处于激活状态，由etcd选举产生   Control Manager  执行集群级别的功能，通过apiserver监控集群状态做出相应的处理，如复制组件、持续跟踪工作节点 、处理节点失败等 一个master集群中只会有一个节点处于激活状态，由etcd选举产生   etcd  一个可靠的分布式数据存储,它能持久化存储集群配置。使用RAFT算法    k8s依赖etcd所以不存在数据一致性的问题（把数据一致性压到了etcd上），所以k8s master不需要采取投票的机制来进行选举，而只需节点健康就可以成为leader。所以这边master并不要求奇数，偶数也是可以的。那么master高可用至少需要2个节点，失败容忍度是(n/0)+1，也就是只要有一个是健康的k8s master集群就属于可用状态。（这边需要注意的是master依赖etcd，如果etcd不可用那么master也将不可用）
etcd的失败容忍度：最小可用节点数：(n/2)+1。通常是奇数节点，防止脑裂
Node 节点 无高可用一说。
主要的几个组件：
 Container Runtime  每个节点都需要一个容器运行时来执行容器，比如Docker。非pod启动。   kubelet  用于执行API server下达的命令，也可以重启启动失败的pod。   kube-proxy (Kubernetes Service Proxy)  通过修改iptables来达到网络代理、负载均衡的效果    组件之间的通讯 系统组件间只能通过API服务器通信，它们之间不会直接通信。
唯一能直接和etcd通信的是 k8s 的API服务器。所有其他组件通过API服务器间接地读取、写入数据到etcd。这带来一些好处，其中之一就是增强乐观锁系统、验证系统的健壮性;并且,通过把实际存储机制从其他组件抽离,未来替换起来也更容易
使用Kubernetes的好处 简化应用程序部署 由于k8s将其所有工作节点公开为一个部署平台, 因此应用程序开发人员可以直接部署应用程序,不需要了解组成集群的服务器。</description>
    </item>
    
    <item>
      <title>Kubernetes in Action笔记 - (1) 容器技术介绍</title>
      <link>https://www.zengxi.net/2020/12/k8s_container_tech_intro/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/12/k8s_container_tech_intro/</guid>
      <description>容器允许你在同一台机器上运行多个服务, 不仅提供不同的环境给每个服务, 而且将它们互相隔离。
容器与虚拟机比较 轻量级 和虚拟机比较, 容器更加轻量级, 它允许在相同的硬件上运行更多数量的组件。主要是因为每个虚拟机需要运行自己的一组系统进程, 这就产生了除组件进程消耗以外的额外计算资源损耗。而一个容器仅仅是运行在宿主机上被隔离的单个进程, 仅消耗应用容器消耗的资源, 不会有其他进程的开销。
虚拟化 多个容器则会完全执行运行在宿主机上的同一个内核的系统调用, 此内核是唯一一个在宿主机操作系统上执行指令的内核。 CPU也不需要做任何对虚拟机能做那样的虚拟化。
隔离性 虚拟机的主要好处是它们提供完全隔离的环境, 因为每个虚拟机运行在它自己的Linux内核上, 而容器都是调用同一个内核, 这会有一定的安全隐患
容器实现隔离机制介绍 用 Linux 命名空间隔离进程 默认情况下, 每个 Linux 系统最初仅有一个命名空间。可以创建额外的命名空间, 以及在它们之间组织资源。
对于一个进程, 可以在其中一个命名空间中运行它。进程将只能看到同一个命名空间下的资源。 存在多种类型的多个命名空间, 所以一个进程不单单只属于某一个命名空间, 而属于每个类型的一个命名空间。存在以下类型的命名空间:
 Mount (mnt) Process ID (pid) Network (net) Inter-process communicaion (ipd) UTS (UNIX Time-Sharing) User ID (user)  每种命名空间被用来隔离一组特定的资源。例如, UTS 命名空间决定了运行在命名空间里的进程能看见哪些主机名和域名。通过分派两个不同的 UTS 命名空间给一对进程, 能使它们看见不同的本地主机名。换句话说, 这两个进程就好像正在两个不同的机器上运行一样(至少就主机名而言是这样的)。同样地, 一个进程属于什么 Network 命名空间决定了运行在进程里的应用程序能看见什么网络接口。每个网络接口属于一个命名空间, 但是可以从一个命名空间转移到另一个。 每个容器都使用它自己的网络命名空间, 因此每个容器仅能看见它自己的一组网络接口。
限制进程的可用资源 另外的隔离性就是限制容器能使用的系统资源。 这通过cgroups来实现。cgroups 是一个Linux 内核功能, 它被用来限制 一个进程或者一组进程的资源使用。一个进程的资源(CPU、 内存、 网络带宽等)使用量不能超出被分配的量。 这种方式下, 进程不能过分使用为其他进程保留的资源, 这和进程运行在不同的机器上是类似的。</description>
    </item>
    
    <item>
      <title>Nginx服务器安全加固</title>
      <link>https://www.zengxi.net/2020/11/nginx_security/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/11/nginx_security/</guid>
      <description>基础知识 常用配置 顶部配置
1#定义 Nginx 运行的用户和用户组 2user nginx; 3 4#进程文件 5pid /var/run/nginx.pid; 6 7#错误日志位置和级别，debug、info、notice、warn、error、crit 8error_log /var/log/nginx/error.log warn; 9 10#Nginx worker 的进程数，一般可设置为可用的CPU内核数。 11worker_processes 8; 12 13#每个 worker 打开文件描述符的最大数量限制。理论值应该是最多打开文件数（系统的值ulimit -n） 14#与 nginx 进程数相除，但是 nginx 分配请求并不均匀，所以建议与ulimit -n的值保持一致。 15worker_rlimit_nofile 65535; Events 模块
1events { 2 #设置一个worker进程同时打开的最大连接数 3 worker_connections 2048; 4 5 #告诉nginx收到一个新连接通知后接受尽可能多的连接 6 multi_accept on; 7 8 #设置用于复用客户端线程的轮询方法。如果你使用Linux 2.6+，你应该使用epoll。 9 # 如果你使用*BSD，你应该使用kqueue。 10 use epoll; 11} HTTP 模块
1http { 2 #隐藏 Nginx 的版本号，提高安全性。 3 server_tokens off; 4 5 #开启高效文件传输模式，sendfile 指令指定 Nginx 是否调用sendfile 函数来输出文件， 6 #对于普通应用设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平 7 #衡磁盘与网络 I/O 处理速度，降低系统的负载。 8 sendfile on; 9 10 #是否开启目录列表访问，默认关闭。 11 autoindex off; 12 13 #告诉 Nginx 在一个数据包里发送所有头文件，而不一个接一个的发送 14 tcp_nopush on; 15 16 #告诉 Nginx 不要缓存数据，而是一段一段的发送--当需要及时发送数据时，就应该给应用设置 17 #这个属性，这样发送一小块数据信息时就不能立即得到返回值。Nginx 默认会始终工作在 tcp  18 #nopush 状态下。但是当开启前面的 sendfile on; 时，它的工作特点是 nopush 的最后一 19 #个包会自动转转换到 nopush off。为了减小那200ms的延迟，开启 nodelay on; 将其很快 20 #传送出去。结论就是 sendfile on; 开启时，tcp_nopush 和 tcp_nodelay 都是on 是可以的。 21 tcp_nodelay on; 22 23 #日志格式设定 24 log_format main &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#34;$request&amp;#34; &amp;#39; 25 &amp;#39;$status $body_bytes_sent &amp;#34;$http_referer&amp;#34; &amp;#39; 26 &amp;#39;&amp;#34;$http_user_agent&amp;#34; &amp;#34;$http_x_forwarded_for&amp;#34;&amp;#39;; 27 #定义访问日志，设置为 off 可以关闭日志，提高性能 28 access_log /var/log/nginx/access.</description>
    </item>
    
    <item>
      <title>Elastic Search vm.max_map_count too low 错误</title>
      <link>https://www.zengxi.net/2020/11/es_max_map_count_error/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/11/es_max_map_count_error/</guid>
      <description>在启动elastic search的时候，在启动日志看到下面的错误提示
1Max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决这个问题，有两个办法：
 临时的，仅当前会话窗口有效 执行下面命令  1sysctl -w vm.max_map_count=262144 然后启动elastic search
永久生效  编辑/etc/sysctl.conf, 添加或者修改下面参数：
1vm.max_map_count=262144 重启系统，或者执行下面命令加载参数：
1sysctl --system </description>
    </item>
    
    <item>
      <title>利用frp与nginx实现公网访问NAS</title>
      <link>https://www.zengxi.net/2020/11/nas_frp_nginx/</link>
      <pubDate>Sat, 14 Nov 2020 11:45:39 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/11/nas_frp_nginx/</guid>
      <description>能够在远程访问存储NAS上面的资料，才能真正发挥NAS的作用。但是对于没有公网IP的内网用户，如何实现在公网上面访问NAS，是一个需要事先解决的问题。
如果拥有一个有公网IP的VPS，可以通过 frp + Nginx 来实现内网穿透解决这个问题。另外，从安全角度考虑，如果有可能的话，整个链路上面的都使用 https 协议通讯更加安全。
下面大致描绘了访问的链路图：
 浏览器通过https协议与 VPS 通讯。浏览器的请求先发到nginx上，ngnix再将请求转发的至frps。在frps前面加上nginx做反向代理的好处是，如果这个VPS上面有其他请求转发的需求（比如这个VPS部署了个人网站或者博客），那在访问所有这些服务的时候，都可以使用同一个端口（比如443）。使用默认端口的话，在访问的时候，端口号都可以不用输入 frps与部署在NAS内网的frpc通讯，frpc将请求转发至内网的NAS。  1(( browser )) ---https---&amp;gt; (( nginx --&amp;gt; frps )) ---https---&amp;gt;&amp;gt; (( frpc --&amp;gt; NAS )) VPS上的配置 配置frps 从 https://github.com/fatedier/frp/releases 上找到最新的版本并下载。解压后，修改frps.ini:
1[common] 2bind_port = 7000 3vhost_https_port = 7443 4# 使用kcp加速 5kcp_bind_port = 7001 6 7# auth 8authentication_method = token 9token = 12345678 10 11# log 12log_file = /var/log/frps.log 13log_level = info 14log_max_days = 3 15 下面注册frps为系统服务。如果是ubuntu系统，按如下格式创建一个新的文件 /etc/systemd/system/frps.</description>
    </item>
    
    <item>
      <title>Cloudflare开启HTTPS加密后，请求转发到源站报522错误</title>
      <link>https://www.zengxi.net/2020/11/cloudflare_https_redirect_522_error/</link>
      <pubDate>Fri, 13 Nov 2020 08:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/11/cloudflare_https_redirect_522_error/</guid>
      <description>笔者使用Cloudflare做DNS，同时使用Cloudflare的SSL证书服务。整个链路如下图:
1|----------| |-----------| |---------------| 2| Brower | ------&amp;gt; | Cloudfare | ------&amp;gt; | Origin Server | 3|----------| |-----------| |---------------| 4 笔者想要做整个链路的https，但是在配置完之后，打开页面是看到522的错误。这个错误表示连接上源站点，但是请求超时。可以参考这个页面来找到可能的原因： https://support.cloudflare.com/hc/en-us/articles/115003011431-Error-522-Connection-timed-out#522error
Cloudfare在配置https的时候有4个选项：
 Off (not secure): 不开启 Flexible: 仅在浏览器与Cloudflare之间用https加密传输, Cloudflare到源站之间不加密 Full: 整个链路的端到端加密, 源站可使用自签名的证书 Full (strict)：整个链路的端到端加密，但是源站必须使用可信任的CA证书或者Cloudflare Origin CA证书。Cloudflare Origin CA证书是用于Cloudfare与源站之间的加密通讯，需要在Cloudflare控制台配置  如果选择不恰当的选项，可能会导致访问错误。比如，如果源网站用的是自签名的证书，但是选择Full (strict)选项，会报证书错误。
笔者遇到522的问题，是由于iptables规则的设置问题。把cloudflare的ip段添加到iptables的允许列表中就可以了。ip列表见： https://www.cloudflare.com/zh-cn/ips
1iptables -A INPUT -p tcp -s 173.245.48.0/20 -j ACCEPT 2iptables -A INPUT -p tcp -s 103.21.244.0/22 -j ACCEPT 3iptables -A INPUT -p tcp -s 103.22.200.0/22 -j ACCEPT 4iptables -A INPUT -p tcp -s 103.</description>
    </item>
    
    <item>
      <title>Linux查看某个端口是否被占用</title>
      <link>https://www.zengxi.net/2020/11/ubuntu_install_postgresql/</link>
      <pubDate>Mon, 09 Nov 2020 08:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/11/ubuntu_install_postgresql/</guid>
      <description> 使用lsof  1lsof -i 2 3lsof -i:80 使用netstat  1netstat -anp | grep 80 </description>
    </item>
    
    <item>
      <title>Ubuntu安装Postgres</title>
      <link>https://www.zengxi.net/2020/10/ubuntu_install_postgresql/</link>
      <pubDate>Tue, 27 Oct 2020 08:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/10/ubuntu_install_postgresql/</guid>
      <description>ubuntu自带的软件仓库可能没有最新的postgres，这就需要自己手动添加安装源，再安装
1# 添加安装源 2sudo sh -c &amp;#39;echo &amp;#34;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&amp;#34; &amp;gt; /etc/apt/sources.list.d/pgdg.list&amp;#39; 3 4# 导入key 5wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - 6 7# 更新软件列表 8sudo apt-get update 9 10# 查找相关的软件包 11sudo apt-cache search postgres 12 13# 安装 14sudo apt install &amp;lt;对应的软件名称&amp;gt;  参考：
 https://www.postgresql.org/download/linux/ubuntu/  </description>
    </item>
    
    <item>
      <title>利用n来切换Nodejs版本</title>
      <link>https://www.zengxi.net/2020/10/nodejs_switch_version/</link>
      <pubDate>Tue, 20 Oct 2020 08:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/10/nodejs_switch_version/</guid>
      <description>安装n
1sudo npm install n -g 安装完后，可以使用命令 sudo n &amp;lt;NODEJS 版本号&amp;gt; 来安装对应的nodejs版本
需要切换版本时，执行下面的命令。然后用键盘上面的上下方向键即可切换
1sudo n 切换完后，执行下面命令来验证当前版本号
1node -v </description>
    </item>
    
    <item>
      <title>个人简介</title>
      <link>https://www.zengxi.net/about/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/about/</guid>
      <description>Paul Zeng
 毕业于211大学计算机专业，现居住于上海 团队主管，带团队从事互联网分布式平台开发、架构与运维。 熟悉主流的分布式系统框架，熟悉高并发高可用的系统设计、监控与运维 熟悉软件开发流程, 熟悉从软件开发、测试、CI/CD 到线上监控的一整套体系  技术栈：
 Java, Python, C#, C, VB Spring Boot, Spring Cloud Spring, Hibernate, Mybatis RabbitMQ, Kafka, Redis, Zookeeper, Duboo PostgreSQL, Elastic Search Kubernetes, Docker Ansible, Terrform, AliCloud  </description>
    </item>
    
    <item>
      <title>Postgres启动时遇到只读文件系统的错误</title>
      <link>https://www.zengxi.net/2020/09/postgres_startup_readonly_file_error/</link>
      <pubDate>Sun, 20 Sep 2020 20:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/09/postgres_startup_readonly_file_error/</guid>
      <description>问题与解决方法 公司内部私有云由于断电，机器没有正常关机，结果导致 Postgres 服务器启动时，报错
12020-09-09 07:22:15.296 UTC [3876] FATAL: could not remove old lock file &amp;#34;postmaster.pid&amp;#34;: Read-only file system 22020-09-09 07:22:15.296 UTC [3876] HINT: The file seems accidentally left over, but it could not be removed. Please remove the file by hand and try again. 3pg_ctl: could not start server 尝试执行下面命令去重新挂载磁盘目录
1mount -o remount -w /var/lib/postgresql/ 但是报错
1mount: /dev/vdb is write-protected but explicit `-w&amp;#39; flag given 尝试另外一个命令
1umount /dev/vdb 但是还是报错</description>
    </item>
    
    <item>
      <title>Manjaro安装deb包</title>
      <link>https://www.zengxi.net/2020/08/manjaro_debtap/</link>
      <pubDate>Thu, 13 Aug 2020 12:23:45 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/08/manjaro_debtap/</guid>
      <description>安装debtap
1yay -S debtap 替换源，解决国内debtap同步仓库执行超慢的问题。打开 /usr/bin/debtap，更换 debtap 内容：
 将 http://ftp.debian.org/debian/dists 替换成 https://mirrors.ustc.edu.cn/debian/dists 将 http://archive.ubuntu.com/ubuntu/dists 替换成 https://mirrors.ustc.edu.cn/ubuntu/dists  升级debtap数据库
1sudo debtap -u 转换deb包。注意： 转换过程中会提示输入包名，以及license。包名随意，license可以填GPL。上述操作完成后会在deb包同级目录生成xxx.tar.xz文件
1sudo debtap xxxx.deb 2 3# -q 可以略过除了编辑元数据之外的所有问题 4sudo debtap -q xxx.deb 5 6# 略过所有的问题（不推荐） 7sudo debtap -Q xxx.deb 安装转换好的本地包
1sudo pacman -U xxx.tar.xz 2  参考：
 https://www.jianshu.com/p/900dc8a0ecff  </description>
    </item>
    
    <item>
      <title>Manjaro笔记本启动时自动设置屏幕亮度</title>
      <link>https://www.zengxi.net/2020/08/linux_auto_set_brightness/</link>
      <pubDate>Mon, 10 Aug 2020 10:33:42 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/08/linux_auto_set_brightness/</guid>
      <description>笔记本在manjaro在启动的时候，屏幕可能会默认设置为最大亮度。可以通过设置开机启动脚本，来设置启动时候的亮度。
1. 创建一个启动service脚本 执行下面的命令
1sudo vim /etc/systemd/system/rc-local.service 输入下面的内容
1[Unit] 2Description=&amp;#34;/etc/rc.local Compatibility&amp;#34; 3 4[Service] 5Type=oneshot 6ExecStart=/etc/rc.local start 7TimeoutSec=0 8StandardInput=tty 9RemainAfterExit=yes 10SysVStartPriority=99 11 12[Install] 13WantedBy=multi-user.target 2. 创建 /etc/rc.local 文件 执行下面的命令
1sudo vim /etc/rc.local 输入下面的内容
1#!/bin/sh 2# /etc/rc.local 3if test -d /etc/rc.local.d; then 4 for rcscript in /etc/rc.local.d/*.sh; do 5 test -r &amp;#34;${rcscript}&amp;#34; &amp;amp;&amp;amp; sh ${rcscript} 6 done 7 unset rcscript 8fi 3. 添加执行权限 1sudo a+x /etc/rc.local 4. 添加/etc/rc.local.d文件夹 1sudo mkdir /etc/rc.local.d 5. 设置开机自启 1systemctl enable rc-local.</description>
    </item>
    
    <item>
      <title>gitbook因为nodejs版本不匹配导致安装报错</title>
      <link>https://www.zengxi.net/2020/08/gitbook_installation_error/</link>
      <pubDate>Sat, 01 Aug 2020 09:21:02 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/08/gitbook_installation_error/</guid>
      <description>如果nodejs使用的不是10.x版本，就会报错
1Installing GitBook 3.2.3 2/usr/local/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 3 if (cb) cb.apply(this, arguments) 4 ^ 5 6TypeError: cb.apply is not a function 7 at /usr/local/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 8 at FSReqCallback.oncomplete (fs.js:177:5)  参考：
 https://www.bilibili.com/read/cv6932054/  </description>
    </item>
    
    <item>
      <title>zookeeper服务器文件清理</title>
      <link>https://www.zengxi.net/2020/07/zookeeper_purge_file/</link>
      <pubDate>Wed, 29 Jul 2020 10:32:19 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/zookeeper_purge_file/</guid>
      <description>zookeeper主要存放了三类文件，他们都可以在配置文件中指定存储路径：
 snapshot： 内存数据的快照，配置项为dataDir 事务日志：所有与修改数据相关的操作记录，配置项为dataLogDir。在没有dataLogDir配置项的时候，zookeeper默认将事务日志文件和快照日志文件都存储在dataDir对应的目录下。 log4j日志：记录zookeeper集群服务器运行日志。日志的配置地址在conf/目录下的log4j.properties文件中，该文件中有一个配置项为&amp;quot;zookeeper.log.dir=.&amp;quot;  正常运行过程中，zookeeper会不断地把快照数据和日志输出到这些目录。如果没有专门做配置或者人为清理，日志文件不会自动清理，磁盘会越占越多。
主要的清理方法有下面几种。
(1) 写脚本删除 写一个删除日志脚本，每天定时执行
1#!/bin/bash 2#snapshot file dir  3dataDir=/home/yinshi.nc/test/zk_data/version-2 4#tran log dir  5dataLogDir=/home/yinshi.nc/test/zk_log/version-2 6#zk log dir  7logDir=/home/yinshi.nc/test/logs 8#Keep 66 files  9count=66 10count=$[$count+1] 11 12ls -t $dataLogDir/log.* | tail -n +$count | xargs rm -f 13ls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -f 14ls -t $logDir/zookeeper.log.* | tail -n +$count | xargs rm -f 写到crontab中，设置为每天凌晨2点执行一次就可以了
1crontab -e 22 2 * * * /bin/bash /root/clean_zook_log.</description>
    </item>
    
    <item>
      <title>查看zookeeper版本</title>
      <link>https://www.zengxi.net/2020/07/check_zookeeper_version/</link>
      <pubDate>Tue, 28 Jul 2020 13:22:06 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/check_zookeeper_version/</guid>
      <description>在控制台下面命令
1echo stat|nc localhost 2181 返回结果示例
1Zookeeper version: 3.4.8-1--1, built on Fri, 26 Feb 2016 14:51:43 +0100 2Clients: 3 /10.30.1.186:33824[1](queued=0,recved=203121,sent=203148) 4 /10.30.1.116:39374[1](queued=0,recved=56774,sent=56790) 5 /10.30.1.171:37240[1](queued=0,recved=20793,sent=20793) 6 7Latency min/avg/max: 0/0/10748 8Received: 855235993 9Sent: 856603574 10Connections: 36 11Outstanding: 0 12Zxid: 0x125c07103 13Mode: leader 14Node count: 6047 </description>
    </item>
    
    <item>
      <title>terraform中阿里云ECS ssh key变化问题</title>
      <link>https://www.zengxi.net/2020/07/terraform_aliyun_ecs_ssh_key/</link>
      <pubDate>Thu, 23 Jul 2020 06:05:31 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/terraform_aliyun_ecs_ssh_key/</guid>
      <description>目前的terraform脚本中，在新建阿里云ECS的时候，会通过 user_data 属性值来设定初始的ssh key。但是这个就存在一个隐患，如果将来想要改变初始的ssh key，再用terraform来推机器的时候，terraform发现user_data属性值发生变化，会删除现有的ECS并重建。
解决的方法是，修改ECS的lifecycle，将user_data添加到忽略列表中。这样terraform就可以忽略掉该属性值的变化。
1{ 2 resource &amp;#34;alicloud_instance&amp;#34; &amp;#34;test_instance&amp;#34; { 3 ... 4 5 lifecycle { 6 ignore_changes = [&amp;#34;user_data&amp;#34;] 7 } 8 } 9} </description>
    </item>
    
    <item>
      <title>解决terraform与远程云服务器资源状态不一致的问题</title>
      <link>https://www.zengxi.net/2020/07/terraform_state_consistent/</link>
      <pubDate>Wed, 22 Jul 2020 14:37:54 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/terraform_state_consistent/</guid>
      <description>概述 在运维过程中遇到了下面的情况：长期使用terraform管理资源，但是通过terraform以外的工具对云资源做过属性变更（比如通过网页上的控制台对云资源做属性变更）。此时，云资源的属性与terraform state的信息已经不一致，跑terraform plan就会发现，它会删除现有的，然后重建一个。但是这个是我们不希望看到的，我们希望可以保留原有实例并且把本地的terraform state更新成最新的属性。
解决方案 要想解决这个问题，可以利用 terraform import 命令。也就是重新导入云资源的实例，然后同步成最新的信息。
下面以阿里云ECS为例子。
(1)删除 state 中的现有资源 如果该资源受 terraform 管理，则需要先把它删除。执行下面的命令
1# 基于当前的tf文件，初始化 state 文件 2terraform init 3 4# 列出当前的state文件所有管理的项目清单 5terraform state list 6 7# 根据上面的输出，找到对应的项目的名称。通过rm删除, 下面假设项目名称是 alicloud_instance.testecs 8terraform state rm alicloud_instance.testecs (2)在阿里云控制台获取实例ID 登录阿里云网页上的控制台，获取所要导入的实例 ID
(3)tf 文件中添加实例的定义 保证本地的tf文件中有该实例资源的相关定义。如果没有，则可以用下面的方式在文件中新增内容。
如果是以resource模式定义，则添加下面内容，直接留空即可，其余的数据在后续步骤中可以补全
1resource &amp;#34;alicloud_instance&amp;#34; &amp;#34;testecs&amp;#34; {} 如果是以模块方式来定义，则添加下面内容，其余的数据在后续步骤中可以补全
1module &amp;#34;testmodule&amp;#34; { 2 source = &amp;#34;../modules/instance&amp;#34; 3 environment = &amp;#34;xxx&amp;#34; 4 vswitch_info = &amp;#34;xxxx&amp;#34; 5 vpc_id = &amp;#34;xxxx&amp;#34; 6 instance_type = &amp;#34;xxxx&amp;#34; 7 security_groups = &amp;#34;xxxx&amp;#34; 8 service = &amp;#34;xxxx&amp;#34; 9 instance_count = &amp;#34;xxxxx&amp;#34; 10 system_disk_size = &amp;#34;xxxxx&amp;#34; 11 system_disk_category = &amp;#34;xxxxx&amp;#34; 12 alicloud_availability_zones = &amp;#34;xxxxx&amp;#34; 13} ​</description>
    </item>
    
    <item>
      <title>grep 返回 Binary file (standard input) matches</title>
      <link>https://www.zengxi.net/2020/07/grep_binary_file_match/</link>
      <pubDate>Mon, 20 Jul 2020 11:31:49 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/grep_binary_file_match/</guid>
      <description>grep &amp;quot;keyword&amp;quot; xxx.log时输出: Binary file (standard input) matches
这个是因为grep命令认为它是一个二进制文件。解决方案是，加上一个参数 -a：
1grep -a &amp;#34;keyword&amp;#34; xxx.log 该参数的解释：
1-a, --text equivalent to --binary-files=text </description>
    </item>
    
    <item>
      <title>清除chrome中 HTTPS 证书缓存</title>
      <link>https://www.zengxi.net/2020/07/clear_chrome_https_cert_cache/</link>
      <pubDate>Wed, 15 Jul 2020 09:21:02 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/clear_chrome_https_cert_cache/</guid>
      <description>在地址栏输入 chrome://net-internals/#hsts ， 找到 “Delete domain security policies”， 输入对应的域名，点击 Delete 按钮</description>
    </item>
    
    <item>
      <title>jetty临时目录下的资源文件被删导致js等资源找不到</title>
      <link>https://www.zengxi.net/2020/07/jetty_tmp_dir/</link>
      <pubDate>Tue, 14 Jul 2020 22:03:51 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/jetty_tmp_dir/</guid>
      <description>生产环境上jetty运行一段时间后，在打开某个网页的时候发现有js、css文件找不到，但是重启之后问题会解决。后来发现是设定了tmpwatch后台任务，定时会清理一次系统的tmp目录。
默认情况下，如果没有指定jetty的临时目录，默认会使用系统的临时目录。解决方案就是，修改jetty的临时文件存放目录，不要放在 /tmp 目录下面。主要有下面几个方法：
 设置basetempdir值  1&amp;lt;Configure class=&amp;#34;org.eclipse.jetty.webapp.WebAppContext&amp;#34;&amp;gt; 2 3 &amp;lt;Set name=&amp;#34;contextPath&amp;#34;&amp;gt;/test&amp;lt;/Set&amp;gt; 4 &amp;lt;Set name=&amp;#34;war&amp;#34;&amp;gt;foo.war&amp;lt;/Set&amp;gt; 5 6 &amp;lt;Call name=&amp;#34;setAttribute&amp;#34;&amp;gt; 7 &amp;lt;Arg&amp;gt;org.eclipse.jetty.webapp.basetempdir&amp;lt;/Arg&amp;gt; 8 &amp;lt;Arg&amp;gt;/home/my/foo&amp;lt;/Arg&amp;gt; 9 &amp;lt;/Call&amp;gt; 10&amp;lt;/Configure&amp;gt;  设置tempDirectory值  1&amp;lt;Configure class=&amp;#34;org.eclipse.jetty.webapp.WebAppContext&amp;#34;&amp;gt; 2 3 &amp;lt;Set name=&amp;#34;contextPath&amp;#34;&amp;gt;/test&amp;lt;/Set&amp;gt; 4 &amp;lt;Set name=&amp;#34;war&amp;#34;&amp;gt;foo.war&amp;lt;/Set&amp;gt; 5 6 &amp;lt;Set name=&amp;#34;tempDirectory&amp;#34;&amp;gt;/some/dir/foo&amp;lt;/Set&amp;gt; 7&amp;lt;/Configure&amp;gt;  设置 javax.servlet.context.tempdir 属性  1&amp;lt;Configure class=&amp;#34;org.eclipse.jetty.webapp.WebAppContext&amp;#34;&amp;gt; 2 3 &amp;lt;Set name=&amp;#34;contextPath&amp;#34;&amp;gt;/test&amp;lt;/Set&amp;gt; 4 &amp;lt;Set name=&amp;#34;war&amp;#34;&amp;gt;foo.war&amp;lt;/Set&amp;gt; 5 6 &amp;lt;Call name=&amp;#34;setAttribute&amp;#34;&amp;gt; 7 &amp;lt;Arg&amp;gt;javax.servlet.context.tempdir&amp;lt;/Arg&amp;gt; 8 &amp;lt;Arg&amp;gt;/some/dir/foo&amp;lt;/Arg&amp;gt; 9 &amp;lt;/Call&amp;gt; 10 11&amp;lt;/Configure&amp;gt;  在启动参数里面修改  1java -jar .</description>
    </item>
    
    <item>
      <title>Linux下面使用dd命令烧录U盘并查看执行进度</title>
      <link>https://www.zengxi.net/2020/07/linux_dd_cmd_write_usb_disk/</link>
      <pubDate>Mon, 13 Jul 2020 10:36:12 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/07/linux_dd_cmd_write_usb_disk/</guid>
      <description>烧录U盘 先用fdisk来查看U盘的盘符
1sudo fdisk -l 再用dd命令来写数据到U盘
1sudo dd if=/home/paul/Downloads/test.iso of=/dev/sdc bs=1M count=10000 查看执行进度 假定需要每5秒输出dd的进度，可以使用下面几种方法。新开一个命令行窗口，执行下面的命令，注意命令上面可能需要加上sudo
方法一：
1watch -n 5 pkill -USR1 ^dd$ 方法二：
1watch -n 5 killall -USR1 dd 方法三：
1while killall -USR1 dd; do sleep 5; done 方法四：
1while (ps auxww |grep &amp;#34; dd &amp;#34; |grep -v grep |awk &amp;#39;{print $2}&amp;#39; |while read pid; do kill -USR1 $pid; done) ; do sleep 5; done 上述四种方法中使用三个命令：pkill、killall、kill向dd命令发送SIGUSR1信息，dd命令进程接收到信号之后就打印出自己当前的进度。
看到的效果类似：
1772+0 records in 2772+0 records out 3809500672 bytes (810 MB, 772 MiB) copied, 117.</description>
    </item>
    
    <item>
      <title>rsyslog内存占用高导致服务不可用</title>
      <link>https://www.zengxi.net/2020/06/rsyslog_high_memory_usage/</link>
      <pubDate>Mon, 22 Jun 2020 09:29:31 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/06/rsyslog_high_memory_usage/</guid>
      <description>这几天生产环境中某个服务内存不时地被撑爆，原先以为是应用的问题，但是近来没有上过新的代码。该服务的总内存是8G，启动参数关于内存的配置大致是：-Xmx=6.4G，-Xms=4G 左右。看了Grafana上面的监控记录，JVM 老年代使用最多也就到4G左右，在GC的日志中发现也仅仅用到4G左右，并没有到达最高的内存值。这两个结果可以看出来，应该不是应用程序导致内存占用过大。
后来用top命令看了一下，发现rsyslog进程使用了将近40%的内存。再查一下日志文件，发现一些日志文件大小都达到2G以上。
rsyslog仅仅是用来同步日志，原则上讲，它仅仅是辅助的进程，不应该占用那么内存，即使它同步延迟较大甚至不工作，也不应该影响到应用程序的正常运行。那么，我们可以通过限制它的内存使用率来解决这个问题。
如果是Ubuntu系统，可以通过修改 /etc/systemd/system/rsyslog.service 文件，在Service项目下面修改或者添加以下参数。在其他的Linux系统下，路径可能不同。通常情况下rsyslogd大小只有5M，所以将内存上限设置为8M，绝对内存限制为80M。注意: $SYSLOGD_OPTIONS这个参数必须添加上去，否则限制可能不生效。
1[Service] 2ExecStart=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS 3MemoryAccounting=yes 4MemoryMax=80M 5MemoryHigh=8M 然后重启服务:
1systemctl daemon-reload 2systemctl restart rsyslog 几个参数的含义：
   名称 描述     MemoryAccounting 若设为”yes”则表示为此单元开启内存占用统计。 注意，这同时也隐含的开启了该单元 所属的 slice 以及父 slice 内所有单元的内存占用统计。 此选项的默认值由 DefaultMemoryAccounting= 决定   MemoryHigh 尽可能限制该单元中的进程最多可以使用多少内存。 虽然这是一个允许被突破的柔性限制，但是突破限制后，进程的运行速度将会大打折扣， 并且系统将会尽可能尽快回收超出的内存。此选项的目的在于柔性限制内存使用量。选项值可以是以字节为单位的绝对内存大小(可以使用以1024为基数的 K, M, G, T 后缀)， 也可以是以百分比表示的相对内存大小(相对于系统的全部物理内存)， 还可以设为特殊值 “infinity” 表示不作限制。   MemoryMax 绝对刚性的限制该单元中的进程最多可以使用多少内存。 这是一个不允许突破的刚性限制，触碰此限制会导致进程由于内存不足而被强制杀死。 建议将 MemoryHigh= 用作主要的内存限制手段， 而将 MemoryMax= 用作不可突破的底线。选项值可以是以字节为单位的绝对大小(可以使用以1024为基数的 K, M, G, T 后缀)， 也可以是以百分比表示的相对大小(相对于系统的全部物理内存)， 还可以设为特殊值 “infinity” 表示不作限制。     参考链接：</description>
    </item>
    
    <item>
      <title>转: postgresql 查看单个表大小</title>
      <link>https://www.zengxi.net/2020/06/pg_check_table_size/</link>
      <pubDate>Mon, 15 Jun 2020 10:35:08 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/06/pg_check_table_size/</guid>
      <description>原文链接：https://blog.csdn.net/kmust20093211/article/details/47616345
方法一 ，查某个表
1selectpg_size_pretty(pg_relation_size(&amp;#39;table_name&amp;#39;));方法二 ，查出所有表并按大小排序
1SELECT2table_schema||&amp;#39;.&amp;#39;||table_name3AStable_full_name,pg_size_pretty(pg_total_relation_size(&amp;#39;&amp;#34;&amp;#39;||table_schema||&amp;#39;&amp;#34;.&amp;#34;&amp;#39;||table_name||&amp;#39;&amp;#34;&amp;#39;))ASsize4FROM5information_schema.tables6ORDERBY7pg_total_relation_size(&amp;#39;&amp;#34;&amp;#39;||table_schema||&amp;#39;&amp;#34;.&amp;#34;&amp;#39;||table_name||&amp;#39;&amp;#34;&amp;#39;)8DESClimit20;方法三，查出所有表按大小排序并分离data与index</description>
    </item>
    
    <item>
      <title>postgres增量备份工具：wal-e</title>
      <link>https://www.zengxi.net/2020/06/pg_wale_continuous_archiving/</link>
      <pubDate>Tue, 09 Jun 2020 12:31:50 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/06/pg_wale_continuous_archiving/</guid>
      <description>wal-e这个工具可以用来给postgres数据库做基础备份与增量备份，这个对数据库容灾很有帮助。目前它支持将备份存储到AWS S3，Azure Blob Store与Google Storage等。
一些基本概念 Base Backup 也称为热备份，它不会中断PostgreSQL中任何事务。一旦启动了basebackup，它将等待一个checkpoint。如果到达了checkpoint，那么它将把整个数据目录复制到一个文件中。这些备份将会是replication或POINT IN TIME恢复的起点。通常，basebackup是不一致的，可能包含已经损坏的数据。这时，就需要用到WAL文件
WAL 通过WAL文件可以获得数据库内所有数据的变更。这些变更首先写入WAL文件，然后再对数据库进行实际性地写入 。因此被称作Write Ahead Log。
Consitent Backup Consitent Backup(一致性备份) = Base backup + WAL backup
WAL日志文件必须在还原基础备份之后再还原。还原WAL文件的相关命令，必须在recovery.conf的restore_command中设置
WAL-E中的一些命令  backup-push - 做基础备份 backup-fetch - 做还原基础备份 wal-push - 备份wal文件 wal-fetch - 还原wal文件  用法 大致的用法就是：
 主库  安装wal-e，在配置目录中指定备份需要存储的地址以及身份认证 新建crontab，调用backup-push定时做基础备份 修改postgres配置目录下的postgresql.conf中的配置，开启archive并指定archive命令备份wal文件   备库  安装wal-e，在配置目录中指定获取备份的地址以及身份认证 用backup-fetch还原一次基础备份 在postgres的数据目录下面，新增recovery.conf配置文件，里面指定了还原wal备份的命令    更多详细内容与配置，可以参考它的github项目：https://github.com/wal-e/wal-e/
 参考链接：
 https://github.com/wal-e/wal-e/ https://dba.stackexchange.com/questions/211416/postgresql-how-to-take-incremental-backup-with-wal-e/211422  </description>
    </item>
    
    <item>
      <title>用string adapter来解决系统接口对接中发现的空值验证问题</title>
      <link>https://www.zengxi.net/2020/06/string_adapter/</link>
      <pubDate>Mon, 01 Jun 2020 13:44:01 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/06/string_adapter/</guid>
      <description>客户用的是很旧版本的ERP系统，在与客户系统做接口对接的时候发现了一个问题。假设接口请求需要的body是xml格式的，共有三个字段：name, mobile, email。由于客户ERP系统比较老，如果某个字段没有值，传的是空字符串，而不是将该字段在请求消息体中隐藏。客户发的请求类似下面的例子：
1&amp;lt;xml&amp;gt; 2 &amp;lt;name&amp;gt;John&amp;lt;/name&amp;gt; 3 &amp;lt;mobile&amp;gt;13800138000&amp;lt;/mobile&amp;gt; 4 &amp;lt;email&amp;gt;&amp;lt;/email&amp;gt; 5&amp;lt;/xml&amp;gt; 由于历史遗留问题，我方系统里在字段上面加了 javax.validation.constraints.Pattern 注解使用正则表达式来对传入的请求值做验证。当传入值为空字符串的时候，正则表达式验证就无法通过。
与客户做过沟通，对于空值的字段，他们也没有办法在请求中隐藏字段，只能传空字符串。那就只能在我方系统这边看看是否可以通过修改代码来解决。一种方案是修改正则表达式，来兼容空字符串，但是由于这些都是传统代码，不确定把空字符串设置在这个字段上面会对后面的处理会有什么影响。如果有更合适的、代价更小的方案，那么就最好不选择这种。
1@XmlType 2@XmlAccessorType(XmlAccessType.FIELD) 3public class TestRequest implements Serializable { 4 @XmlElement(required = true) 5 private String name; 6 7 @XmlElement(required = false) 8 @Pattern(regexp = Constants.regexpMobile, message = &amp;#34;invalidMobile&amp;#34;) 9 private String mobile; 10 11 @XmlElement(required = false) 12 @Pattern(regexp = Constants.regexpEmail, message = &amp;#34;invalidEmail&amp;#34;) 13 private String email; 14 15 // getter / setter 16 .</description>
    </item>
    
    <item>
      <title>Spring Quartz 指定Scheduler Name</title>
      <link>https://www.zengxi.net/2020/05/spring_quartz_customize_scheduler_name/</link>
      <pubDate>Sun, 31 May 2020 15:43:31 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/05/spring_quartz_customize_scheduler_name/</guid>
      <description>当前项目使用quartz与spring来做基于数据库的集群化任务调度，但是在实际使用过程发现同一个scheduler中，不同group之间任务调度可能会相互跑串。当前项目中使用的 quartz-scheduler 版本 2.3.1， spring 版本 3.2.18.RELEASE。
举个例子，配置是这样的, 下面示例中隐去不重要的配置
1&amp;lt;bean id=&amp;#34;my-cluster-scheduler&amp;#34; 2 class=&amp;#34;org.springframework.scheduling.quartz.SchedulerFactoryBean&amp;#34; 3 lazy-init=&amp;#34;false&amp;#34;&amp;gt; 4 ... 5 &amp;lt;property name=&amp;#34;quartzProperties&amp;#34;&amp;gt; 6 &amp;lt;props&amp;gt; 7 &amp;lt;prop key=&amp;#34;org.quartz.jobStore.isClustered&amp;#34;&amp;gt;true&amp;lt;/prop&amp;gt; 8 &amp;lt;prop key=&amp;#34;org.quartz.jobStore.class&amp;#34;&amp;gt;org.quartz.impl.jdbcjobstore.JobStoreCMT&amp;lt;/prop&amp;gt; 9 &amp;lt;/props&amp;gt; 10 ... 11 &amp;lt;/property&amp;gt; 12 &amp;lt;property name=&amp;#34;jobDetails&amp;#34;&amp;gt; 13 &amp;lt;list&amp;gt; 14 &amp;lt;ref bean=&amp;#34;myTestJobDetailBean&amp;#34;/&amp;gt; 15 &amp;lt;/list&amp;gt; 16 &amp;lt;/property&amp;gt; 17 &amp;lt;property name=&amp;#34;triggers&amp;#34;&amp;gt; 18 &amp;lt;list&amp;gt; 19 &amp;lt;ref bean=&amp;#34;myTestJobTrigger&amp;#34;/&amp;gt; 20 &amp;lt;/list&amp;gt; 21 &amp;lt;/property&amp;gt; 22&amp;lt;/bean&amp;gt; 23 24&amp;lt;bean id=&amp;#34;myTestJobTrigger&amp;#34; class=&amp;#34;org.springframework.scheduling.quartz.CronTriggerFactoryBean&amp;#34;&amp;gt; 25 &amp;lt;property name=&amp;#34;jobDetail&amp;#34; ref=&amp;#34;myTestJobDetailBean&amp;#34;/&amp;gt; 26 &amp;lt;property name=&amp;#34;cronExpression&amp;#34; value=&amp;#34;${my.</description>
    </item>
    
    <item>
      <title>Manjaro安装VMware Workstation</title>
      <link>https://www.zengxi.net/2020/05/manjaro_install_vmware/</link>
      <pubDate>Tue, 26 May 2020 14:23:31 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/05/manjaro_install_vmware/</guid>
      <description>安装VMware workstation
1yay -S vmware-workstation 启动时候如果报错：Please make sure that the kernel module `vmmon’ is loaded. 则需要重新安装一下linux-headers，加载一下vmmon模块
1# 先查看内核。返回值版本号格式为: A.B.C-D-MANJARO。示例： 5.2.8-1-MANJARO， 2uname -r 3 4# 安装 linux-headers。根据上面的内核版本来选择安装包，安装包名字为：linuxAB-headers 5sudo pacman -S linux52-headers 6 7# 加载vmmon模块 8sudo modprobe -a vmw_vmci vmmon 如果需要虚拟机要访问网络，则需要执行下面命令来启动服务
1systemctl start vmware-networks 2 3# 或者，设置开机启动 4sudo systemctl enable --now vmware-networks.service 如果需要虚拟机要支持USB接口，则需要执行下面命令来启动服务
1systemctl start vmware-usbarbitrator 2 3# 或者，设置开机启动 4sudo systemctl enable --now vmware-usbarbitrator.service 如果需要虚拟机要支持网络共享，则需要执行下面命令来启动服务
1systemctl start vmware-hostd 2 3# 或者，设置开机启动 4sudo systemctl enable --now vmware-hostd.</description>
    </item>
    
    <item>
      <title>Manjaro设置chrome为默认浏览器</title>
      <link>https://www.zengxi.net/2020/05/manjaro_chrome_default_browser/</link>
      <pubDate>Mon, 25 May 2020 14:01:11 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/05/manjaro_chrome_default_browser/</guid>
      <description>安装完 Manjaro，一般会自带 Firefox浏览器。如果自己想再安装 chrome，并且设置成默认浏览器，则需要两个步骤：
 在 Default Applications 中选择 Chrome 为默认的浏览器。除了这一步还不够，打开 chrome 依然有提示说“chrome 不是默认浏览器”，这就需要下面的第二步来解决。 在 File Association 中找到 html 项， 选择使用 Chrome 打开该类型的文件。  </description>
    </item>
    
    <item>
      <title>MacOS中通过ISO镜像制作U盘安装盘</title>
      <link>https://www.zengxi.net/2020/05/mac_write_iso_into_udisk/</link>
      <pubDate>Thu, 21 May 2020 10:10:07 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/05/mac_write_iso_into_udisk/</guid>
      <description>使用MacOS自带的dd命令，就可以将ISO镜像写入到U盘。这就可以利用这个命令来制作安装windows，Linux等系统用U盘
通过下面的命令，找出U盘挂载的路径
1diskutil list 将U盘取消挂载，在下面命令中将N替换为所对应的挂载盘：
1diskutil unmountDisk /dev/disk[N] 将内容写入U盘。下面的命令中 rdisk 的 r 可以加快写入速度
1sudo dd if=iso路径 of=/dev/rdisk[N] bs=1m 弹出磁盘
1diskutil eject /dev/disk[N] </description>
    </item>
    
    <item>
      <title>Postgres关闭某个数据库关联的session</title>
      <link>https://www.zengxi.net/2020/04/pg_close_session_remove_db/</link>
      <pubDate>Thu, 23 Apr 2020 10:10:07 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/04/pg_close_session_remove_db/</guid>
      <description>Postgres删除数据库的时候，报错：有其他用户正在使用该数据库，无法删除。这时，需要关闭这个数据库的相关的连接，然后再删除数据库
可以执行下面的命令来关闭连接：</description>
    </item>
    
    <item>
      <title>Docker Hub国内镜像加速</title>
      <link>https://www.zengxi.net/2020/04/docker-hub-mirror/</link>
      <pubDate>Wed, 22 Apr 2020 14:43:24 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/04/docker-hub-mirror/</guid>
      <description>国内访问Docker Hub速度比较感人，这个时候需要配置国内的镜像，来加速下载。由于镜像服务可能出现宕机，建议同时配置多个镜像。
Ubuntu 16.04+、Debian 8+、CentOS 7 新建或者修改 /etc/docker/daemon.json，写入如下内容
1{ 2 &amp;#34;registry-mirrors&amp;#34;: [ 3 &amp;#34;https://hub-mirror.c.163.com&amp;#34;, 4 &amp;#34;https://registry.docker-cn.com&amp;#34; 5 ] 6} 重启服务
1sudo systemctl daemon-reload 2sudo systemctl restart docker Windows 10 在任务栏托盘 Docker 图标内右键菜单选择 Settings，打开配置窗口后在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件，之后点击 Apply &amp;amp; Restart 保存后 Docker 就会重启并应用配置的镜像地址了。
1{ 2 &amp;#34;registry-mirrors&amp;#34;: [ 3 &amp;#34;https://hub-mirror.c.163.com&amp;#34;, 4 &amp;#34;https://registry.docker-cn.com&amp;#34; 5 ] 6} macOS 在任务栏点击 Docker Desktop 应用图标 -&amp;gt; Perferences，在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件。修改完成之后，点击 Apply &amp;amp; Restart 按钮，Docker 就会重启并应用配置的镜像地址了。</description>
    </item>
    
    <item>
      <title>修改Alpine镜像源</title>
      <link>https://www.zengxi.net/2020/04/modify-apine-mirror/</link>
      <pubDate>Tue, 21 Apr 2020 10:18:24 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/04/modify-apine-mirror/</guid>
      <description>docker使用alpine作为基础可以减少image的大小，但是如果编写的dockerfile中需要安装一些软件，在编译image过程中，可能速度会很慢甚至卡住。
Alpine 的源文件为/etc/apk/repositories。默认的配置类似：
1http://dl-cdn.alpinelinux.org/alpine/v3.11/main 2http://dl-cdn.alpinelinux.org/alpine/v3.11/community 这个时候就需要在dockerfile中添加下面的命令，将安装包路径指向国内的镜像。
1# 使用阿里云的镜像源 2sed -i &amp;#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&amp;#39; /etc/apk/repositories 国内的其他一些镜像源
1# 中国科技大学 2sed -i &amp;#39;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&amp;#39; /etc/apk/repositories 3 4# 清华大学 5sed -i &amp;#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g&amp;#39; /etc/apk/repositories </description>
    </item>
    
    <item>
      <title>转: Postgres数据库DBA常用命令</title>
      <link>https://www.zengxi.net/2020/01/postgres-frequently-used-commands/</link>
      <pubDate>Mon, 27 Jan 2020 21:22:07 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/01/postgres-frequently-used-commands/</guid>
      <description>原作者：廖学强 原文链接：点击这里   查看帮助命令
1DB=#help--总的帮助 23DB=#\h--SQL commands级的帮助 45DB=#\?--psql commands级的帮助 按列显示，类似mysql的\G
1DB=# \x 2 3Expanded display is on. 查看DB安装目录(最好root用户执行)
1find / -name initdb 查看有多少DB实例在运行(最好root用户执行)
1find / -name postgresql.conf 查看DB版本
1cat$PGDATA/PG_VERSION23psql--version 45DB=#showserver_version;67DB=#selectversion();查看DB实例运行状态
1pg_ctlstatus查看所有数据库
1psql–l--查看5432端口下面有多少个DB 23psql–pXX–l--查看XX端口下面有多少个DB 45DB=#\l67DB=#select*frompg_database;创建数据库
1createdbdatabase_name23DB=#\hcreatedatabase--创建数据库的帮助命令 45DB=#createdatabasedatabase_name进入某个数据库
1psql–ddbname23DB=#\cdbname查看当前数据库
1DB=#\c23DB=#selectcurrent_database();查看数据库文件目录
1DB=#showdata_directory;23cat$PGDATA/postgresql.conf|grepdata_directory45cat/etc/init.d/postgresql|grepPGDATA=67lsof|grep5432得出第二列的PID号再ps–ef|grepPID查看表空间
1select*frompg_tablespace;查看语言
1select*frompg_language;查询所有schema，必须到指定的数据库下执行
1select*frominformation_schema.schemata;23SELECTnspnameFROMpg_namespace;45\dnS查看表名
1DB=#\dt--只能查看到当前数据库下public的表名 23DB=#SELECTtablenameFROMpg_tablesWHEREtablenameNOTLIKE&amp;#39;pg%&amp;#39;ANDtablenameNOTLIKE&amp;#39;sql_%&amp;#39;ORDERBYtablename;45DB=#SELECT*FROMinformation_schema.tablesWHEREtable_name=&amp;#39;ff_v3_ff_basic_af&amp;#39;;查看表结构
1DB=#\dtablename23DB=#select*frominformation_schema.columnswheretable_schema=&amp;#39;public&amp;#39;andtable_name=&amp;#39;XX&amp;#39;;查看索引
1DB=#\di23DB=#select*frompg_index;查看视图
1DB=#\dv23DB=#select*frompg_viewswhereschemaname=&amp;#39;public&amp;#39;;45DB=#select*frominformation_schema.viewswheretable_schema=&amp;#39;public&amp;#39;;查看触发器
1DB=#select*frominformation_schema.triggers;查看序列
1DB=#select*frominformation_schema.sequenceswheresequence_schema=&amp;#39;public&amp;#39;;查看约束
1DB=#select*frompg_constraintwherecontype=&amp;#39;p&amp;#39;23DB=#selecta.relnameastable_name,b.connameasconstraint_name,b.contypeasconstraint_typefrompg_classa,pg_constraintbwherea.oid=b.conrelidanda.relname=&amp;#39;cc&amp;#39;;查看XX数据库的大小
1SELECTpg_size_pretty(pg_database_size(&amp;#39;XX&amp;#39;))Asfulldbsize;查看所有数据库的大小
1selectpg_database.datname,pg_size_pretty(pg_database_size(pg_database.datname))ASsizefrompg_database;查看各数据库数据创建时间：
1selectdatname,(pg_stat_file(format(&amp;#39;%s/%s/PG_VERSION&amp;#39;,casewhenspcname=&amp;#39;pg_default&amp;#39;then&amp;#39;base&amp;#39;else&amp;#39;pg_tblspc/&amp;#39;||t2.oid||&amp;#39;/PG_11_201804061/&amp;#39;end,t1.oid))).*frompg_databaset1,pg_tablespacet2wheret1.dattablespace=t2.oid;按占空间大小，顺序查看所有表的大小
1selectrelname,pg_size_pretty(pg_relation_size(relid))frompg_stat_user_tableswhereschemaname=&amp;#39;public&amp;#39;orderbypg_relation_size(relid)desc;按占空间大小，顺序查看索引大小
1selectindexrelname,pg_size_pretty(pg_relation_size(relid))frompg_stat_user_indexeswhereschemaname=&amp;#39;public&amp;#39;orderbypg_relation_size(relid)desc;查看参数文件
1DB=#showconfig_file;23DB=#showhba_file;45DB=#showident_file;查看当前会话的参数值
1DB=#showall;查看参数值
1select*frompg_file_settings查看某个参数值,比如参数work_mem
1DB=#showwork_mem修改某个参数值,比如参数work_mem
1DB=#altersystemsetwork_mem=&amp;#39;8MB&amp;#39;23--使用alter system命令将修改postgresql.auto.conf文件，而不是postgresql.conf，这样可以很好的保护postgresql.conf文件，加入你使用很多alter system命令后搞的一团糟，那么你只需要删除postgresql.auto.conf，再执行pg_ctl reload加载postgresql.conf文件即可实现参数的重新加载。 查看是否归档
1DB=#showarchive_mode;查看运行日志的相关配置，运行日志包括Error信息，定位慢查询SQL，数据库的启动关闭信息，checkpoint过于频繁等的告警信息。
1showlogging_collector;--启动日志收集 23showlog_directory;--日志输出路径 45showlog_filename;--日志文件名 67showlog_truncate_on_rotation;--当生成新的文件时如果文件名已存在，是否覆盖同名旧文件名 89showlog_statement;--设置日志记录内容 1011showlog_min_duration_statement;--运行XX毫秒的语句会被记录到日志中，-1表示禁用这个功能，0表示记录所有语句，类似mysql的慢查询配置 查看wal日志的配置，wal日志就是redo重做日志</description>
    </item>
    
    <item>
      <title>根据ID来管理分布式session - 新老界面session不一致导致强制登出问题的修复</title>
      <link>https://www.zengxi.net/2020/01/manage-distribution-session-by-id/</link>
      <pubDate>Sun, 26 Jan 2020 16:21:39 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/01/manage-distribution-session-by-id/</guid>
      <description>背景 由于历史原因，原先的界面是用vaadin框架来实现。但是这个框架不适合互联网的分布式系统，正在逐步用目前主流的前端框架重写各个模块，把旧的vaadin页面替换掉。在替换过程中，新老界面并存。
vaadin界面的servlet，每次都会判断请求中的session id值，如果在服务器中找不到对应这个id的session，就会重新生成一个。由于session id是在新界面登录的时候生成的，当点击链接从新界面跳转到vaadin界面的时候，vaadin服务会发现没有这个session id，就会重新生成一个新的session。换句话说，新老界面会有各自的session id。当然，分布式系统本来就有这个问题，可以采用分布式session的来解决。
原先开发人员的解决方案是:
 把session信息存入redis缓存，session id作为key 每次跳转到vaadin界面后，用新生成的session id替换掉旧的session id，同时在redis里面把session信息从旧的key，复制到新的key这边。  但是这种解决方案存在一个问题，主要是由上面解决方案的第2点引起的。由于每次从新界面跳转到vaadin界面都会生成新的session id，如果打开两个浏览器页面，分别跳转到新的界面，那么这个就会导致第一个跳转的那个浏览器页面中的session id被覆盖。vaadin框架是有状态的，它在客户端与服务器端保持一个长连接，并检测session id的有效性。session id的变化，导致长连接的登录信息失效，被弹回到登录界面。从用户体验上来讲，就是被强制登出。
从另外一个角度说，原先开发人员的解决方案是不合理的，它也不是一种标准的分布式session的解决方案。
如何解决 比较合适的解决方案是，vaadin界面不能自己生成session id，而是要复用在新界面登录之后所生成的session id。当vaadin界面有请求的时候，根据请求中的session id查询服务器上是否有对应的session，如果有则返回对应的session；如果没有，则新建一个以该session id为主键的session。换句话说，新老界面都应该要使用相同session id，一旦登录之后，在当前用户这次登录的有效生命周期内，session id保持不变。这样就不会存在上面说的，由于session id的变化而导致被强制登出的问题。
具体实现的关键是用到HttpServletRequesWrapper类，它能够快速提供HttpServletRequest的自定义实现。
 |----------------------| | (I) ServletRequest | |----------------------| | | ------------------------------------------- | | | | |--------------------------| |-----------------------------| | (I) HttpServletRequest | | (C) ServletRequestWrapper | |--------------------------| |-----------------------------| | | | | ------------------------------------------- | | |---------------------------------| | (C) HttpServletRequestWrapper | |---------------------------------|  如下的代码是从 Tomcat 抽取出来的，展现了HttpServletRequesWrapper类是如何运行的。</description>
    </item>
    
    <item>
      <title>Mac 检查附近wifi所使用的信道</title>
      <link>https://www.zengxi.net/2020/01/mac-check-nearby-wifi-channel/</link>
      <pubDate>Fri, 24 Jan 2020 12:53:21 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/01/mac-check-nearby-wifi-channel/</guid>
      <description>信道，也称作通道或频段，是以无线信号作为传输载体的数据信号传送通道。2.4G频段的工作频率为2.4-2.4835GHz，这83.5MHz频带划分为13个信道，各信道中心频率相差5MHz，向上向下分别扩展11MHz，信道带宽22MHz。中国采用欧洲/ETSI标准，使用1-13信道。
相近无线路由器采用相同或重叠信道会形成信道竞争关系，相互影响无线链路质量，为了有效避免信道重叠造成的相互干扰，相近无线路由器应选择互不重叠的信道工作。
早期无线路由器出厂时预设相同的信道（大多为6），因用户很少会修改信道，从而导致相互影响的情况。随着无线应用的迅速普及，无线路由器增加了信道自动选择功能，在设备启动时检测周围无线信道分布情况，选择最佳信道工作。
但是不要过分依赖路由器的自动选择，路由器没有那么智能。可以根据附近的wifi所使用的信道，手工选择一个不一样的。
在mac系统中，可以使用下面的命令来查看附近wifi使用信道的情况
1sudo /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport -s  参考：
 https://service.tp-link.com.cn/detail_article_3272.html http://www.voidcn.com/article/p-njamfbdk-dq.html  </description>
    </item>
    
    <item>
      <title>Mac下shell命令支持map</title>
      <link>https://www.zengxi.net/2020/01/mac-shell-support-map/</link>
      <pubDate>Sun, 19 Jan 2020 16:40:17 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/01/mac-shell-support-map/</guid>
      <description>Mac自带的bash是3.x版本的，shell中的declare命令不支持-A这个参数，会报下面的错误：
1declare: -A: invalid option 2declare: usage: declare [-afFirtx] [-p] [name[=value] ...] 这个参数从bash 4.x开始支持，需要升级至4.x以上的版本
1# 安装最新版本的bash 2brew install bash 3 4# 新版本的bash安装路径是 /usr/share/bin/bash, 而之前系统自带的是 /bin/bash 5# 需要把新版本的shell添加至信任列表中 6sudo bash -c &amp;#39;echo /usr/local/bin/bash &amp;gt;&amp;gt; /etc/shells&amp;#39; 7 8# 如果需要的话，修改默认shell为新版本的bash 9chsh -s /usr/local/bin/bash 需要注意的是，升级完之后，如果shell脚本需要用新版本的bash来执行，必须在相关的shell脚本开头的部分，将 #!/bin/bash 替换成 #!/usr/local/bin/bash， 否则还是用旧版本的bash来执行。
那为什么不执行类似下面的命令，删除原先的bash，并给新版本的bash建立一个链接呢？这个是由于MacOS有系统完整性保护机制（System Integrity Protection，SIP），它会阻止所有用户（包括root）修改 /bin 下面目录的内容。当然，也有办法绕过这保护机制，嫌麻烦的话，就不要去动它了。
1sudo rm /bin/bash 2sudo ln -s /usr/local/bin/bash /bin/bash  参考文章：
 https://itnext.io/upgrading-bash-on-macos-7138bd1066ba  </description>
    </item>
    
    <item>
      <title>Quartz job使用过程中的发现问题与改进</title>
      <link>https://www.zengxi.net/2020/01/quartz-job-issue-improvement/</link>
      <pubDate>Sun, 05 Jan 2020 18:22:24 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2020/01/quartz-job-issue-improvement/</guid>
      <description>遇到的问题与原因分析 生产环境中遇到的问题：
 服务在启动过程中，不时地卡住，后来发生的越来越频繁。看日志分析，卡在初始化quartz job store的时候 服务在运行过程中，不时地出现定时任务不被触发的情况  通过分析，得知问题产生的原因：
 目前代码中用的是Quartz scheduler 1.8.3版本，定时框架采用的是行锁，通过执行下面的SQL来锁住特定的记录。在分布式的系统的情况下，节点越多越容易发生锁等待，甚至死锁。Quartz scheduler 的 2.x 版本做了改进，在QRTZ_LOCKS表中多加了一个字段 SCHED_NAME。这有一个好处就是，可以给不同的应用分配不同的scheduler name，这样定时框架在调度的时候，不同的应用分别去尝试锁定不同的行，而不像之前锁的时同一个行，避免死锁的发生。  1SELECT*FROMQRTZ_LOCKSWHERELOCK_NAME=$1FORUPDATE; org.quartz.threadPool.threadCount 值设置太小。Quartz scheduler的线程池大小不足，这个也有可能导致定时任务在排队，无法被触发。  另外，在研究现有代码过程中，还发现另外3个问题：
 group未正确赋值。Quartz中实际上是把job name与group的组合作为一个唯一标识的key，用它来触发和调度一个任务。job name相同，group不同，被当做是不同的任务。如果同一个应用多个节点，需要分成不同的组来分别执行不同的定时任务（比如其中一个组仅统计某个时间段出国的旅游人数，另外一个组仅统计在国内的旅游人数），那就必须给不同的组赋予不同的group值。否则，可能导致其中的一个任务没有执行，因为他们被当做是同一个任务。 应用中的instanceId被写死在配置文件中。由于一个应用往往有多个节点，这个就导致集群中有多个节点的instanceId是相同。然而同一个Quartz scheduler的集群中，任意节点的instanceId必须保证唯一。 目前的系统有个需求，某个任务必须在某个服务的所有节点上执行，比如定时从数据库或者其他地方同步某些配置项到内存中。由于Quartz框架不支持这个功能，原先的代码对job detail等类进行扩展，添加了一个属性，用来表示该任务是在该应用的所有节点上或仅仅选择一台执行。为了支持这个功能，代码改动的比较多，甚至也有可能是因为这些改动，直接或者间接导致前面的那些问题。在网上搜索了一下，发现也有一些人有类似的需求，他们在某网站上面提问，使用Quartz框架时怎样才能支持任务在集群的所有节点上执行。后来仔细想想，Quartz框架支持集群模式与基于内存的RAMJobStore单机模式这两种，如果需要在所有节点上执行，其实使用基于内存的RAMJobStore单机模式就可以了，没有必要再通过扩展集群模式来支持这个功能。  解决方案 最终的解决方案，总结如下：
 升级所有应用的quartz scheduler库至2.3.1版本 不同的应用，分别赋予不同的scheduler name；同一个应用中，如果同时有集群模式与单机模式，需要使用不同的scheduler，并赋予不同的name值 对于同一个应用，某个任务仅需要任意一个节点执行的，使用JobStoreCMT的cluster模式。同时需要保证不同节点instanceId不同， 比如将org.quartz.scheduler.instanceId的值设置为AUTO 对于同一个应用，某个任务需要所有节点都执行的，使用基于内存的RAMJobStore org.quartz.threadPool.threadCount 设置成与任务数一致。避免因线程数不够，任务无法执行 job detail赋予正确的group名称 如果job不允许并发，则在job对应的类上添加@DisallowConcurrentExecution 注解 如果job对应的类上面有autowire的需求，可以自定义一个job factory，继承SpringBeanJobFactory，并调用AutowireCapableBeanFactory的autowireBean，来避免Job类里面@Autowired无法注入的问题。同时在配置文件中使用自定义的job factory  1&amp;lt;property name=&amp;#34;jobFactory&amp;#34; ref=&amp;#34;myCustomizedJobFactory&amp;#34; /&amp;gt; </description>
    </item>
    
    <item>
      <title>复盘 - 手机app上一行代码导致的生产事故</title>
      <link>https://www.zengxi.net/2019/12/incident-caused-by-app/</link>
      <pubDate>Tue, 10 Dec 2019 23:46:11 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2019/12/incident-caused-by-app/</guid>
      <description>过程 由于一些历史原因，以及与原先代码的兼容性，临时文件存储在minio中。
某天，生产环境突发事故，minio集群的CPU与内存爆了，只能重启集群。过了十来分钟，很多服务都不可用，健康检查都不通过。日志中的错误信息显示，这些服务都是数据库拿不到连接。需要事先处理数据库连接的问题，于是连接到数据库查死锁，终止导致死锁的sql进程，再重启来恢复这些服务。
由于前不久minio集群挂掉，很容易就想到是由于minio的原因。其他服务通过RPC调用一个文件存储服务来操作minio中的数据，当minio集群挂掉的时候，文件存储服务访问minio一直想访问minio直到超时。在这个期间，其他服务如果有事务调用文件存储服务来操作minio中文件，那么这个事务就不会被提交，一会占着数据库连接。
minio集群的硬件资源如果不升级，迟早CPU与内存还会再次爆掉。幸运的是，文件存储服务，当初做了兼容，支持两种临时文件存储方式，一个是本地磁盘，另外一个是minio，修改配置文件可以方便的切换。于是先切换成本地磁盘方式，然后升级minio集群的CPU与内存配置，重启minio集群。接着，修改文件存储服务的配置文件，切换回minio的方式。至此，所有的服务都慢慢恢复正常了。
接着，细究这个事故的根源，联想到几天前发现app上面的bug，会一直在后台不断地上传图片。当时由于app出了紧急修复的版本，就没有当回事了。没想到过了几天，问题彻底暴露出来了。未升级app到最新版本的用户，在这几天内依然不停地上传文件。访问量的增大，minio集群原先的配置已经扛不住了。幸运的是，之前app实现了一个版本强制升级更新的机制，可以直接在后台修改当前所支持的最小版本，这样就让用户强制更新到最新的版本，避免了继续不停地传文件。
这段时间大概几十万个文件，约200多G的大小。这些文件都上传到同一个bucket中，由于minio的内部实现是一个bucket采用文件夹形式保存，当一个bucket文件夹中的文件数量过多，已经无法列出某个文件夹下面的文件，总是超时。文件存储服务中的归档删除机制失效，导致空间无法释放，逐渐变小。如果没空间，又会导致服务不可用。幸运的是，有办法获取到具体的文件名，只能手动写脚本直接处理文件，释放空间。
时间线  网页上面发现关联了几千个图片，后来发现是app的bug，会不断地上传图片，修复app 过了几天，先是minio集群爆了，十几分钟后其他服务挂了 释放数据库死锁，其他服务恢复 升级minio集群配置，文件存储服务恢复 强制让app客户端升级到最新版本，文件存储服务压力减小 手动写脚本直接处理minio中的文件，释放minio空间。  总结 做的对的地方：
 文件存储服务做了兼容，支持多种方式，出了问题，有个备选方案 app版本可以控制最低支持的版本，有强制升级机制  需要改进的地方：
 发现app上面bug的时候，没有考虑周全，以为只是小问题，太疏忽 服务之间耦合性有点高，容错性不够。一个服务挂了，可能导致雪崩 minio存储的时候，需要指定子路径。不能放在同一个文件夹下面，要分散到多个子文件夹中。 没有服务降级机制，如果minio挂了，自动启用本地磁盘，不需要重启服务器 minio 当初建机器的时候，没有使用lv等方式，不方便扩展磁盘，如果存在磁盘不足的情况，那么扩容就不方便 配置文件的修改，需要重启服务，造成短时间内不可用  </description>
    </item>
    
    <item>
      <title>重建基于pglogical逻辑复制的从库</title>
      <link>https://www.zengxi.net/2019/12/pg-recreate-pglogical-slave/</link>
      <pubDate>Fri, 06 Dec 2019 21:48:18 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2019/12/pg-recreate-pglogical-slave/</guid>
      <description>《Postgres 9.x 升级至 10.x》一文中提到了使用pglogical逻辑复制升级。基于这种方式的升级有个缺点，就是主库的DDL发生改变的话，那么从库的复制就会有影响，可能需要重建从库来解决。
重建从库的步骤与之前创建逻辑复制有点类似，但是由于之前已经做过一些操作，所以相比之下，少了一些步骤。
从库中删除数据库，再创建一个空的数据库 由于表结构的改变，原先的数据都不能用了，需要重新同步。创建新的空数据库是最快的方式
从库中导入最新的表结构 在 provider 上导出结构数据
1sudo -iu postgres pg_dumpall --schema-only -f dump.sql 在 subscriber 上导入结构数据
1sudo -iu postgres psql -f dump.sql 从库上创建pglogical扩展 1mydb=#CREATEEXTENSIONpglogical;从库上创建逻辑复制节点 1-- host 填的是subscriber的IP 2mydb=#SELECTpglogical.create_node(node_name:=&amp;#39;subscriber&amp;#39;,dsn:=&amp;#39;host=10.1.10.22 port=5432 dbname=mydb&amp;#39;);从库上创建逻辑复制订阅端 1-- host 填的是provider的IP 2mydb=#SELECTpglogical.create_subscription(subscription_name:=&amp;#39;subscriber&amp;#39;,provider_dsn:=&amp;#39;host=10.1.10.6 port=5432 dbname=mydb&amp;#39;);在主库上检查复制状态 1select*frompg_stat_replication;</description>
    </item>
    
    <item>
      <title>Postgres 9.x 升级至 10.x</title>
      <link>https://www.zengxi.net/2019/12/pg-upgrade-version/</link>
      <pubDate>Sun, 01 Dec 2019 21:31:18 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2019/12/pg-upgrade-version/</guid>
      <description>目前主要有两种升级方式，它们分别使用于不同的场景。
   升级方式 优点 缺点     pglogical逻辑复制升级 停机时间短 需提前准备从库，并搭建replication，在replication期间，需考虑DDL语句带来的影响。   pg_upgrade升级 不需要提前准备replication 升级完成后需检查index是否正常，并执行vacuum analyze，对于数据量较大的库，这可能耗时较长    逻辑复制升级 前提条件 所有表都必须有主键 可以用下面的语句来检查
1SELECTtable_name2FROMinformation_schema.tables3WHERE(table_catalog,table_schema,table_name)NOTIN4(SELECTtable_catalog,table_schema,table_name5FROMinformation_schema.table_constraints6WHEREconstraint_type=&amp;#39;PRIMARY KEY&amp;#39;)7ANDtable_schemaIN(&amp;#39;myschema&amp;#39;)super user无密码访问provider和subscriber 修改配置文件
1# prodvider 上配置允许 super user 从 subscriber 上访问 replication。 2# 假如 subscriber IP 是 10.1.10.15，则 provider 的 pg_hba.conf 中应包含以下配置 3host all postgres 10.1.10.15/32 trust 4host replication postgres 10.1.10.15/32 trust 1# subscriber 上允许 super user 访问本地的 postgresql， 2# 假如 subscriber IP 是 10.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.zengxi.net/archives/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.zengxi.net/archives/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hibernate中用criteria builder处理日期与时间分开的字段</title>
      <link>https://www.zengxi.net/2018/12/hibernate-criteria-builder-time-range/</link>
      <pubDate>Thu, 06 Dec 2018 16:35:24 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/12/hibernate-criteria-builder-time-range/</guid>
      <description>现有系统中原先在设计数据库字段的时候，把日期与时间分别存入两个不同的字段，但是这两个字段在数据库中都是以timestamp类型来保存。这样的话，如果需要在where条件中把这两个字段与某个特定的时间做比较，则需要分别截取有效的信息。对于日期字段仅仅取出日期的值，把时间舍弃；对于时间字段仅仅取出时间的值，把日期舍弃。
举个例子，假设数据库中有两个字段：returnSlaDate存的是物品归还截止日期，returnSlaTime存的是物品归还截止时间。实际在保存的时候，数据库中returnSlaDate字段的值可能会是 2018-12-31 00:00:00 ，其中 00:00:00 是没有用的，在与特定时间做比较的时候，需要舍弃；returnSlaTime字段的值可能会是 1970-01-01 17:59:59 ，其中 1970-01-01 是没有用的，在与特定时间做比较的时候，需要舍弃。
假设数据库中有另外一个字段actualReturnDate，它表示物品实际归还时间（仅仅一个字段表示，包含有效的日期与时间）。如果现在有个需求，要在系统中查出来物品未按时归还的记录，需要怎么处理呢？直接用SQL写会相对简单，如果用hibernate的criteria builder则需要用as关键字做一下转换。下面是示例代码：
1// 转换截止日期字段成java.sql.Date类型，这样可以仅取出日期的值 2Expression returnSlaDate = pTimeSchedule.get(&amp;#34;returnSlaDate&amp;#34;).as(java.sql.Date.class); 3// 转换截止时间字段成java.sql.Time类型，这样可以仅取出时间的值 4Expression returnSlaTime = pTimeSchedule.get(&amp;#34;returnSlaTime&amp;#34;).as(java.sql.Time.class); 5 6// 对实际归还时间做与上面一样的处理 7Expression actualReturnDate = pTimeSchedule.get(&amp;#34;actualReturnDate&amp;#34;).as(java.sql.Date.class); 8Expression actualReturnTime = pTimeSchedule.get(&amp;#34;actualReturnDate&amp;#34;).as(java.sql.Time.class); 9 10// 在where语句中，筛选出实际归还日期大于截止日期，或者实际归还日期等于截止日期且归还时间大于截止时间 11orFilter.add(builder.or( 12 builder.greaterThan(actualReturnDate, returnSlaDate), 13 builder.and( 14 builder.equal(actualReturnDate, returnSlaDate), 15 builder.greaterThan(actualReturnTime, returnSlaTime) 16 ) 17)); 18 打出hibernate的日志，可以看到转换之后的SQL语句</description>
    </item>
    
    <item>
      <title>记一次打开Excel文件错误的排查</title>
      <link>https://www.zengxi.net/2018/12/excel-trouble-shooting-zip-file/</link>
      <pubDate>Wed, 05 Dec 2018 17:56:09 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/12/excel-trouble-shooting-zip-file/</guid>
      <description>在生产环境中，某个结果集导出的excel文件用Microsoft Excel无法打开，看到如下错误：
最开始怀疑是在生成文件的时候，文件损坏掉了，但是重新生成多次，得到的结果都是一样的。在相同的界面，导出其他结果集所生成的文件却都是可以成功打开的，这样就可以排除代码功能方面的问题。如果和代码无关，那么就可能和数据有关系。根据出错提示给出的文件地址“C:\Users\ZHANGZ~1\AppData\Local\Temp\error083200_01.xml”, 打开该临时文件，可以看到下面的信息
1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34; standalone=&amp;#34;true&amp;#34;?&amp;gt; 2@namespace html url(http://www.w3.org/1999/xhtml); :root { font:small Verdana; font-weight: bold; padding: 2em; padding-left:4em; } * { display: block; padding-left: 2em; } html|style { display: none; } html|span, html|a { display: inline; padding: 0; font-weight: normal; text-decoration: none; } html|span.block { display: block; } *[html|hidden], span.block[html|hidden] { display: none; } .expand { display: block; } .expand:before { content: &amp;#39;+&amp;#39;; color: red; position: absolute; left: -1em; } .</description>
    </item>
    
    <item>
      <title>配置Nginx支持长轮询</title>
      <link>https://www.zengxi.net/2018/11/nginx-setting-for-long-polling/</link>
      <pubDate>Wed, 21 Nov 2018 17:13:06 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/11/nginx-setting-for-long-polling/</guid>
      <description>对于需要用到长轮询的web项目，可以在Nginx做一些配置来支持请求转发。分别在http与server块中加入下面的配置：
1http { 2 map $http_upgrade $connection_upgrade { 3 default upgrade; 4 &amp;#39;&amp;#39; close; 5 } 6} 7 8server { 9 location /your-api-url/ { 10 proxy_pass http://127.0.0.1:9000/your-api-url/; 11 proxy_http_version 1.1; 12 proxy_set_header Upgrade $http_upgrade; 13 proxy_set_header Connection $connection_upgrade; 14 proxy_set_header Host $http_host; 15 proxy_set_header X-Forwarded-Host $host; 16 proxy_set_header X-Forwarded-Server $host; 17 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 18 proxy_buffering off; 19 proxy_ignore_client_abort off; 20 } 21} 22 </description>
    </item>
    
    <item>
      <title>shell中用tr命令转换字符大小写</title>
      <link>https://www.zengxi.net/2018/07/shell-translate-character/</link>
      <pubDate>Wed, 25 Jul 2018 21:40:22 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/07/shell-translate-character/</guid>
      <description>在写shell脚本的时候，可能需要将特定的英文字符转换大小写。可以借助tr命令来实现这个功能。
（1）tr的下面这个命令表示把string1替换成string2
 tr string1 string2  运行下面的命令
1echo &amp;#39;this is a pen&amp;#39; | tr &amp;#39;a&amp;#39; &amp;#39;A&amp;#39; 可以看到输出结果中把a换成了A
 this is A pen  （2）同时，tr命令也支持指定一个字符的范围，在这个范围内分别作替换
 tr &#39;c1-c2&#39; &#39;c3-c4&#39;  比如，如果只需要把从a到h的字符，替换成大写，那么可以用下面的命令
1tr &amp;#39;a-h&amp;#39; &amp;#39;A-H&amp;#39; 运行下面的命令
1echo &amp;#39;this is a pen&amp;#39; | tr &amp;#39;a-h&amp;#39; &amp;#39;A-H&amp;#39; 可以看到输出结果中把从a到h的字符全部换成了大写：
 tHis is A pEn  如果要把所有字符转成大写，那么只需要把范围指定成a-z即可。运行下面的命令
1echo &amp;#39;this is a pen&amp;#39; | tr &amp;#39;a-z&amp;#39; &amp;#39;A-Z&amp;#39; 可以看输出结果：
 THIS IS A PEN   </description>
    </item>
    
    <item>
      <title>Docker Compose创建minio集群</title>
      <link>https://www.zengxi.net/2018/07/docker-mino-cluster/</link>
      <pubDate>Wed, 18 Jul 2018 23:00:47 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/07/docker-mino-cluster/</guid>
      <description>Minio是一个简单易用的轻量级对象存储服务，同时它也支持集群环境。使用Minio的docker镜像可以快速地搭建集群环境。
下面是docker-compose.yml文件的示例。分布式的Minio服务至少需要4个节点，所以在docker-compose.yml文件中，至少要配置4个服务。每个服务的command配置必须一样，保证集群环境正常运行。
1version:&amp;#39;3&amp;#39;2services:3minio-node1:4image:minio/minio 5hostname:minio-node1 6ports:7- &amp;#34;29001:9000&amp;#34;8volumes:9- ./node1/data:/data10env_file:./key.env11command:server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data 12minio-node2:13image:minio/minio14hostname:minio-node215ports:16- &amp;#34;29002:9000&amp;#34;17volumes:18- ./node2/data:/data19env_file:./key.env20command:server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data21minio-node3:22image:minio/minio23hostname:minio-node324ports:25- &amp;#34;29003:9000&amp;#34;26volumes:27- ./node3/data:/data28env_file:./key.env29command:server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data30minio-node4:31image:minio/minio32hostname:minio-node433ports:34- &amp;#34;29004:9000&amp;#34;35volumes:36- ./node4/data:/data37env_file:./key.env38command:server http://minio-node1/data http://minio-node2/data http://minio-node3/data http://minio-node4/data上面的配置中env_file指定的加载环境变量文件key.env，这里是为了设置登录minio的用户名密码。下面的key.env示例：
1MINIO_ACCESS_KEY=testkey 2MINIO_SECRET_KEY=testpassword 通过上述的docker-compose.yml文件，就可以启动一个minio的集群环境。可以做一些测试，通过浏览器访问 http://localhost:29001 ，新建bucket并上传一个文件，然后在 http://localhost:29002 上面也可以正常访问。同时，可以特地停掉或者启用其中一些服务，用来测试minio集群环境的高可用性。
如果其中某一个节点服务不可用，这就意味着无法向该节点发起请求来操作对象。比如上述的节点1挂掉， 就无法通过浏览器来访问 http://localhost:29001。 从高可用和负载均衡角度来讲，必须通过负载均衡器来转发请求到各个节点，而不是直接访问某个节点的服务。可以在nginx上做个简单的配置来实现。
下面是nginx配置的示例。配置完重启nginx服务后，就可以使用 http://localhost:29000 来访问和操作对象
1upstream minio_servers { 2 server 127.0.0.1:29001; 3 server 127.0.0.1:29002; 4 server 127.0.0.1:29003; 5 server 127.0.0.1:29004; 6} 7 8server { 9 listen 29000; 10 server_name localhost; 11 12 location / { 13 proxy_set_header Host $http_host; 14 proxy_pass http://minio_servers; 15 } 16} 17 </description>
    </item>
    
    <item>
      <title>date命令按指定locale所对应的日期格式输出</title>
      <link>https://www.zengxi.net/2018/07/force-date-use-locale/</link>
      <pubDate>Wed, 04 Jul 2018 23:03:18 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/07/force-date-use-locale/</guid>
      <description>在Linux，Unix或者MacOS的命令行输入date命令，可以获取到当前的系统时间。默认情况下，date命令是按照当前系统的locale的时间格式来输出的。
比如下面的命令输出当前是星期几，在不同的locale中可以看到有不同的输出
1date +%a 下面是locale为zh_CN的输出：
 三  下面是locale为en_US的输出：
 Wed  如果当前系统的locale是zh_CN，但是想让date输出的星期几是英文而不是中文，有没有简单的办法呢？答案是有。可以通过指定locale临时环境变量来让date命令输出所期望的格式。这个临时环境变量的设置，仅对当前的命令有效，不会影响到其他地方的locale值
首先我们可以运行下面的命令来列出当前系统安装了哪些locale。这一步有一定的必要，因为在不同的系统下面，locale名称可能不同。比如，Ubuntu下面叫做zh_CN.utf8，而MacOS下面叫做zh_CN.UTF-8。如果locale名称没用对，那么看到的就不是所期望的结果。
1locale -a 知道locale的具体名称之后，可以用类似下面的命令来指定locale并按照指定格式输出。
1LC_ALL=zh_CN.UTF-8 date 2LC_ALL=zh_CN.UTF-8 date +%a 3 4LC_ALL=en_US.UTF-8 date 5LC_ALL=en_US.UTF-8 date +%a 上面的命令分别有如下的输出:
 2018年 7月 4日 星期三 20时33分41秒 CST 三 Wed Jul 4 20:33:41 CST 2018 Wed  </description>
    </item>
    
    <item>
      <title>排序算法 - （直接）插入排序 （Insertion Sort)</title>
      <link>https://www.zengxi.net/2018/07/insertion-sort/</link>
      <pubDate>Mon, 02 Jul 2018 22:23:07 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/07/insertion-sort/</guid>
      <description>基本思路 假设按照从小到大排列，总共有n个元素。
 整个数组从逻辑上会被分成两个部分，左边部分是有序的序列，右边部分是待排序的元素。当然，刚开始左边的有序序列仅有一个元素，即第一个元素 将右边待排序元素的第一个元素，与左边有序序列进行比较。比较的时候，是从有序序列的末端（即有序序列最大的一个数）开始进行比较，如果比它大或者与之相等则直接插在其后面，否则一直往前面找，直到找到该插入的位置。插入的时候，需要把所插入位置右边的所有元素往右移。 重复上面的步骤，直到所有待排序的元素处理完毕  性能 平均需要n2/4次比较， n2/4次交换；最差情况n2次比较，n2次交换；最好情况n-1次比较，0次交换
时间复杂度：平均O(n2)，最坏O(n2)，最好O(n)
空间复杂度: O(1)
示例代码 更多详情可点击链接参考示例代码
1private static int[] insertionSort(int[] unsortedArray) { 2 int insertIndex; 3 for (int splitter = 1; splitter &amp;lt; unsortedArray.length; splitter ++) { 4 // Should have N - 1 rounds 5 6 // Get the insert index 7 insertIndex = splitter; 8 for (int j = splitter -1; j &amp;gt;= 0; j --) { 9 if (unsortedArray[j] &amp;gt; unsortedArray[splitter]) { 10 insertIndex = j; 11 continue; 12 } else { 13 break; 14 } 15 } 16 17 // Move the item to right 18 int temp = unsortedArray[splitter]; 19 for (int mov = splitter; mov &amp;gt; insertIndex; mov --) { 20 unsortedArray[mov] = unsortedArray[mov - 1]; 21 } 22 unsortedArray[insertIndex] = temp; 23 } 24 25 return unsortedArray; 26} 用测试用例，有如下的输出。</description>
    </item>
    
    <item>
      <title>通过SSH和JMX远程监控Java服务</title>
      <link>https://www.zengxi.net/2018/06/connect-remote-jmx-with-ssh/</link>
      <pubDate>Thu, 28 Jun 2018 09:26:06 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/connect-remote-jmx-with-ssh/</guid>
      <description>在日常工作中，可以使用一些监控数据的图形展示工具（比如Grafana等）来查看服务器上面JVM的使用情况，比如内存或者CPU的占用情况。但是，在需要解决实际问题的时候，比如CPU或者内存占用过高，还是需要连接到远程的服务器，查看JVM的具体运行情况来分析问题产生的原因。
通常情况下，我们是通过开启远程服务器上的JMX，使用JVisualVM或JConsole客户端，远程连接到服务器上。然而，在实际的生产环境中，Java应用服务器并没有直接暴露在公网，必须通过跳板机来连接。
网上查了一些资料，多数比较麻烦，有些还需要借助第三方工具。后来找到一个简便的方法，在使用JVisualVM或JConsole客户端的时候，通过指定socks代理的方式来连接远程服务器。下面是具体的步骤。
Java应用开启JMX 在应用启动命令里面添加下面的参数。指定JMX端口为18888
 -Dcom.sun.management.jmxremote.port=18888 -Dcom.sun.management.jmxremote.rmi.port=18888 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
 指定本地socks代理的端口和跳板机 在命令行中执行下面的命令开启端口转发
1ssh -N -D 10099 my-bastion 注意：
 上述例子中的 my-bastion 是跳板机别名，在 ~/.ssh/config中配置。 10099 是绑定的本地端口号 ssh命令帮助文档中对两个参数的解释:   -N Do not execute a remote command. This is useful for just forwarding ports. -D [bind_address:]port Specifies a local “dynamic” application-level port forwarding.  用工具连接远程jvm JConsole客户端 如果使用jconsole客户端连接。可以直接指定需要连接的服务
1jconsole -J-DsocksProxyHost=localhost -J-DsocksProxyPort=10099 service:jmx:rmi:///jndi/rmi://10.10.3.11:18888/jmxrmi JVisualVM客户端 如果使用jvisualvm客户端连接，先启动指定代理服务器的参数来启动jvisualvm
1jvisualvm -J-DsocksProxyHost=localhost -J-DsocksProxyPort=10099 然后在jvm里面先添加remote host，再添加类似下面的JMX连接
 service:jmx:rmi:///jndi/rmi://10.10.3.11:18888/jmxrmi
 双击左边添加好的JMX连接，就可以连上服务器并监控JVM的实际状况了</description>
    </item>
    
    <item>
      <title>使用redis-cli与AOF迁移数据</title>
      <link>https://www.zengxi.net/2018/06/redis-data-migration/</link>
      <pubDate>Wed, 27 Jun 2018 08:57:29 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/redis-data-migration/</guid>
      <description>把一台Redis上的数据，迁移到另外一台Redis服务器上，有很多种方式。其中一个简便的方法是，利用Redis自带的命令行工具redis-cli，实现数据的无缝迁移。
在旧的Redis服务器上开启AOF 执行下面的命令，检查AOF是否开启。返回yes表示开启，no表示关闭
1redis-cli -h old_redis_ip -p old_redis_port config get appendonly 如果未开启，执行下面的命令开启AOF
1redis-cli -h old_redis_ip -p old_redis_port config set appendonly yes 复制AOF文件 默认生成的AOF文件名是appendonly.aof。到Redis数据目录可以看到appendonly.aof文件，复制该文件到新的Redis服务器上。
如果不知道Redis数据目录或者改过AOF的文件名，可以查看Redis的配置文件中的配置:
 # The name of the append only file (default: &#34;appendonly.aof&#34;) appendfilename &#34;appendonly.aof&#34; # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the &#39;dbfilename&#39; configuration directive. # # The Append Only File will also be created inside this directory.</description>
    </item>
    
    <item>
      <title>Ubuntu 16.04系统自带截屏工具快捷键</title>
      <link>https://www.zengxi.net/2018/06/ubuntu-screenshot-shortcut/</link>
      <pubDate>Mon, 25 Jun 2018 03:34:29 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/ubuntu-screenshot-shortcut/</guid>
      <description>Ubuntu 16.04系统自带了截屏工具，可以实现窗口截屏、区域截屏等。默认的快捷键是：
1 Print 全屏截图 2 Ctrl + Print 全屏截图并保存到剪贴板 3 4 Alt + Print 窗口截图 5 Ctrl + Alt + Print 窗口截图并保存到剪贴板 6 7 Shift + Print 区域截图 8 Ctrl + Shift + Print 区域截图并保存到剪贴板 9 10 Ctrl + Shift + Alt + R 录制屏幕短视频 </description>
    </item>
    
    <item>
      <title>排序算法 - （简单）选择排序 (Selection Sort）</title>
      <link>https://www.zengxi.net/2018/06/simple-selection-sort/</link>
      <pubDate>Wed, 20 Jun 2018 10:54:52 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/simple-selection-sort/</guid>
      <description>基本思路 假设按照从小到大排列，总共有n个元素
 第一轮，找出数组中最小的元素，与第一个元素交换 第二轮，找出剩余元素中最小的元素，与第二个元素交换 第三轮，找出剩余元素中最小的元素，与第三个元素交换 如此重复上述步骤，直至处理完所有元素  性能 时间复杂度：O(n2)
空间复杂度：O(1)
示例代码 更多详情可点击链接参考示例代码
1private static int[] selectionSort(int[] unsortedArray) { 2 int minIndex; 3 for (int round = 0; round &amp;lt; unsortedArray.length; round ++) { 4 // Should have N rounds 5 6 minIndex = round; 7 8 for (int j = round + 1; j &amp;lt; unsortedArray.length; j ++) { 9 if (unsortedArray[minIndex] &amp;gt; unsortedArray[j]) { 10 minIndex = j; 11 } 12 } 13 14 if (minIndex !</description>
    </item>
    
    <item>
      <title>如何控制grep命令显示在相关文本前后的行数</title>
      <link>https://www.zengxi.net/2018/06/grep-cmd-display-lines/</link>
      <pubDate>Tue, 19 Jun 2018 23:03:44 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/grep-cmd-display-lines/</guid>
      <description>在Linux/Unix系统中使用grep命令的时候，有时候我们想要把匹配文本的前后几行的信息也同时显示出来。这可以通过设置一些参数来达到目的。
grep的帮助文档中有这几个参数：
 -A num, --after-context=num Print num lines of trailing context after each match.
-B num, --before-context=num Print num lines of leading context before each match.
-C num, --context=num Print num lines of leading and trailing context surrounding each match.
 -A 表示同时输出匹配行的后面几行
1grep -A 5 word /home/test/a.log -B 表示同时输出匹配行的前面几行
1grep -B 5 word /home/test/a.log -C 表示同时输出匹配行的前面几行和后面几行
1grep -C5 word /home/test/a.log </description>
    </item>
    
    <item>
      <title>排序算法 - 冒泡排序(Bubble Sort)</title>
      <link>https://www.zengxi.net/2018/06/bubble-sort/</link>
      <pubDate>Sun, 17 Jun 2018 17:26:06 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/bubble-sort/</guid>
      <description>算法思路 基本思路 假设按照从小到大排列，总共有n个元素
 从第一个元素开始至第n-1个元素，依次比较当前元素与它后面相邻元素的大小，如果前面一个比后面一个大，交换两个元素的位置。第一遍处理之后，最后一个元素就是当前循环中最大的一个。 重复上面的步骤，第二遍处理第一至第n-2个元素，第三遍处理第一至第n-3个元素……直到仅剩一个元素。  改进后的思路 上面的基本思路中需要进行n-1轮的比较。但是存在一种可能，在其中的某一轮之后，该数组就已经是有序的了，也就意味着后面就不需要再进行额外的比较和交换。可以设置一个标志位，用来表示当前这一轮是否存在元素交换，如果没有的话，就结束整个排序过程
性能 时间复杂度：最好的情况O(n),最差的情况O(n2)， 平均O(n2)
空间复杂度：O(1)
示例代码 未改进的冒泡算法。更多详情可点击链接参考示例代码
1private static int[] bubbleSort(int[] unsortedArray) { 2 int temp; 3 for (int round = 0; round &amp;lt; unsortedArray.length - 1; round ++) { 4 // Should have N - 1 rounds 5 6 for (int j = 0; j &amp;lt; unsortedArray.length - 1 - round; j ++) { 7 if (unsortedArray[j] &amp;gt; unsortedArray[j + 1]) { 8 temp = unsortedArray[j]; 9 unsortedArray[j] = unsortedArray[j + 1]; 10 unsortedArray[j + 1] = temp; 11 } 12 } 13 } 14 15 return unsortedArray; 16} 用测试用例，有如下的输出。进行了10轮比较，即使后面几轮数组的顺序没有任何的改变</description>
    </item>
    
    <item>
      <title>设置Postgres数据库的默认schema</title>
      <link>https://www.zengxi.net/2018/06/set-postgres-default-schema/</link>
      <pubDate>Fri, 15 Jun 2018 10:26:05 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/set-postgres-default-schema/</guid>
      <description>查看当前的schema
1SHOWsearch_path;设置默认schema，仅对当前连接有效
1SETsearch_pathTOyour_schema;设置默认schema，数据库级别，修改之后的所有连接都有效</description>
    </item>
    
    <item>
      <title>实现InputStream的序列化</title>
      <link>https://www.zengxi.net/2018/06/inputstream-serialize/</link>
      <pubDate>Tue, 12 Jun 2018 10:57:35 +0000</pubDate>
      
      <guid>https://www.zengxi.net/2018/06/inputstream-serialize/</guid>
      <description>InputStream本身是不支持序列化的，但是在实际开发的过程中有时会需要将输入流通过socket传输，比如RMI的远程调用。
在Serializable的Java文档文档中有下面的描述：
 Classes that require special handling during the serialization and deserialization process must implement special methods with these exact signatures:
 private void writeObject(java.io.ObjectOutputStream out) throws IOException private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException; private void readObjectNoData() throws ObjectStreamException;  1 2对于这个场景，序列化的类只需实现writeObject与readObject这两个方法就足够了。readObjectNoData这个方法只是在特定的情况下才需要用，对于简单的应用场景来说，可以不用实现。 3 4为了实现输入流的序列化，需要新建一个继承于Serializable接口的实体类，序列化的时候将输入流转成字节数组（writeObject方法），反序列化则将字节流转成输入流（readObject方法）。值得注意的是，这里要用到transient关键字来修饰不可序列化的InputStream私有字段。 5 6示例代码： 7```java 8public class SerializableStream implements Serializable { 9 private final static int LENGTH = 1024; 10 private transient InputStream inputStream; 11 12 public SerializableStream(InputStream is) { 13 this.</description>
    </item>
    
  </channel>
</rss>
